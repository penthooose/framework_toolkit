{
  "1": {
    "path_input_model": "C:/Users/Paul/.cache/gguf_models/llama3_german_instruct_FT_stage1.gguf",
    "path_output_dir": "C:/Users/Paul/.cache/gguf_models",
    "quantization": "q8_0",
    "integrate_in_ollama": true
  },
  "2": {
    "path_input_model": "C:/Users/Paul/.cache/gguf_models/llama3_german_instruct_FT_stage_D.gguf",
    "path_output_dir": "C:/Users/Paul/.cache/gguf_models",
    "quantization": "q8_0",
    "integrate_in_ollama": true
  },
  "3": {
    "path_input_model": "C:/Users/Paul/.cache/gguf_models/llama3_german_V3.gguf",
    "path_output_dir": "C:/Users/Paul/.cache/gguf_models",
    "quantization": "q8_0",
    "integrate_in_ollama": false
  }
}
