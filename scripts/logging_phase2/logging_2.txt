2025-04-24 18:44:20,967 - INFO - INFO: File logger setup to write to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\logging.txt
2025-04-24 18:44:20,968 - INFO - Starting new training session
2025-04-24 18:44:20,968 - INFO - Starting unsupervised fine-tuning with parameters: {'mode': 'unsupervised', 'data_path': 'N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets', 'text_column': 'text', 'max_samples': None, 'pre_eval': False, 'eval_split': 0, 'model_path': 'C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1', 'output_dir': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2', 'logging_dir': None, 'use_flash_attention': True, 'max_length': 3000, 'chunk_size': None, 'quantization_config': {'load_in_8bit': True}, 'peft_config': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'inference_mode': False, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'down_proj', 'w2']}, 'training_config': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'warmup_steps': 100, 'warmup_ratio': 0.03, 'logging_steps': 10, 'save_steps': 200, 'save_total_limit': 3, 'eval_strategy': 'steps', 'eval_steps': 350, 'per_device_eval_batch_size': 1, 'eval_accumulation_steps': 4, 'fp16': True, 'lr_scheduler_type': 'cosine', 'weight_decay': 0.01, 'gradient_checkpointing': True, 'report_to': 'none', 'disable_tqdm': False, 'max_grad_norm': 0.3, 'dataloader_num_workers': 2}}
2025-04-24 18:44:20,968 - INFO - INFO: Loading datasets from individual JSONL files
2025-04-24 18:44:20,968 - INFO - Loading datasets from individual JSONL files
2025-04-24 18:44:21,020 - INFO - INFO: Loaded 8068 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\training_set.jsonl
2025-04-24 18:44:21,071 - INFO - INFO: Loaded 1864 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\validation_set.jsonl
2025-04-24 18:44:21,083 - INFO - INFO: Loaded separate validation set with 1864 examples
2025-04-24 18:44:21,083 - INFO - Loaded separate validation set with 1864 examples
2025-04-24 18:44:21,092 - INFO - INFO: Loaded 1298 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\test_set.jsonl
2025-04-24 18:44:21,101 - INFO - INFO: Loaded separate test set with 1298 examples
2025-04-24 18:44:21,101 - INFO - Loaded separate test set with 1298 examples
2025-04-24 18:44:21,609 - INFO - INFO: Tokenizer vocabulary size: 128256
2025-04-24 18:44:21,609 - INFO - INFO: Model max length: 1000000000000000019884624838656
2025-04-24 18:44:29,161 - INFO - INFO: Dataset prepared with 8068 examples
2025-04-24 18:44:30,892 - INFO - INFO: Dataset prepared with 1864 examples
2025-04-24 18:44:32,165 - INFO - INFO: Dataset prepared with 1298 examples
2025-04-24 18:44:32,182 - INFO - INFO: CUDA cache cleared
2025-04-24 18:44:32,308 - INFO - INFO: Garbage collector freed 70 objects
2025-04-24 18:44:40,668 - INFO - INFO: Model loaded from C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1
2025-04-24 18:44:40,684 - INFO - INFO: Model has 8030261248 parameters, 0 are trainable (0.00%)
2025-04-24 18:44:41,143 - INFO - INFO: Model has 41943040 trainable parameters after PEFT configuration
2025-04-24 18:44:41,196 - INFO - Starting model training with 8068 training examples
2025-04-24 18:44:41,196 - INFO - Using 1864 examples for validation during training
2025-04-24 18:44:41,196 - INFO - Using 1298 examples for pre/final evaluation
2025-04-24 18:44:41,207 - INFO - INFO: Starting training...
2025-04-24 18:44:41,207 - INFO - Starting training...
2025-04-24 18:44:41,207 - INFO - Starting training...
2025-04-24 18:44:41,390 - INFO - INFO: Starting epoch 0/3
2025-04-24 18:44:41,390 - INFO - Starting epoch 0/3
2025-04-24 18:44:41,390 - INFO - Starting epoch 0/3
2025-04-24 18:47:48,133 - INFO - INFO: Training progress: {'loss': 2.0385, 'grad_norm': 1.4510270357131958, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.00991571641051066}
2025-04-24 18:47:48,133 - INFO - Training progress: {'loss': 2.0385, 'grad_norm': 1.4510270357131958, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.00991571641051066}
2025-04-24 18:47:48,133 - INFO - Training metrics: {'loss': 2.0385, 'grad_norm': 1.4510270357131958, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.00991571641051066}
2025-04-24 18:50:48,527 - INFO - INFO: Training progress: {'loss': 1.8976, 'grad_norm': 0.8386403322219849, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01983143282102132}
2025-04-24 18:50:48,527 - INFO - Training progress: {'loss': 1.8976, 'grad_norm': 0.8386403322219849, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01983143282102132}
2025-04-24 18:50:48,527 - INFO - Training metrics: {'loss': 1.8976, 'grad_norm': 0.8386403322219849, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01983143282102132}
2025-04-24 18:53:49,706 - INFO - INFO: Training progress: {'loss': 1.8979, 'grad_norm': 0.9514005184173584, 'learning_rate': 6e-06, 'epoch': 0.029747149231531978}
2025-04-24 18:53:49,706 - INFO - Training progress: {'loss': 1.8979, 'grad_norm': 0.9514005184173584, 'learning_rate': 6e-06, 'epoch': 0.029747149231531978}
2025-04-24 18:53:49,706 - INFO - Training metrics: {'loss': 1.8979, 'grad_norm': 0.9514005184173584, 'learning_rate': 6e-06, 'epoch': 0.029747149231531978}
2025-04-24 18:56:51,696 - INFO - INFO: Training progress: {'loss': 1.8259, 'grad_norm': 1.5454238653182983, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03966286564204264}
2025-04-24 18:56:51,696 - INFO - Training progress: {'loss': 1.8259, 'grad_norm': 1.5454238653182983, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03966286564204264}
2025-04-24 18:56:51,696 - INFO - Training metrics: {'loss': 1.8259, 'grad_norm': 1.5454238653182983, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03966286564204264}
2025-04-24 18:59:55,655 - INFO - INFO: Training progress: {'loss': 1.8415, 'grad_norm': 0.8099966645240784, 'learning_rate': 1e-05, 'epoch': 0.0495785820525533}
2025-04-24 18:59:55,655 - INFO - Training progress: {'loss': 1.8415, 'grad_norm': 0.8099966645240784, 'learning_rate': 1e-05, 'epoch': 0.0495785820525533}
2025-04-24 18:59:55,655 - INFO - Training metrics: {'loss': 1.8415, 'grad_norm': 0.8099966645240784, 'learning_rate': 1e-05, 'epoch': 0.0495785820525533}
2025-04-24 19:03:02,378 - INFO - INFO: Training progress: {'loss': 1.8356, 'grad_norm': 1.790808081626892, 'learning_rate': 1.2e-05, 'epoch': 0.059494298463063956}
2025-04-24 19:03:02,378 - INFO - Training progress: {'loss': 1.8356, 'grad_norm': 1.790808081626892, 'learning_rate': 1.2e-05, 'epoch': 0.059494298463063956}
2025-04-24 19:03:02,378 - INFO - Training metrics: {'loss': 1.8356, 'grad_norm': 1.790808081626892, 'learning_rate': 1.2e-05, 'epoch': 0.059494298463063956}
2025-04-24 19:06:04,677 - INFO - INFO: Training progress: {'loss': 1.6658, 'grad_norm': 0.9054490923881531, 'learning_rate': 1.4e-05, 'epoch': 0.06941001487357462}
2025-04-24 19:06:04,677 - INFO - Training progress: {'loss': 1.6658, 'grad_norm': 0.9054490923881531, 'learning_rate': 1.4e-05, 'epoch': 0.06941001487357462}
2025-04-24 19:06:04,677 - INFO - Training metrics: {'loss': 1.6658, 'grad_norm': 0.9054490923881531, 'learning_rate': 1.4e-05, 'epoch': 0.06941001487357462}
2025-04-24 19:09:03,554 - INFO - INFO: Training progress: {'loss': 1.6222, 'grad_norm': 1.3671550750732422, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.07932573128408528}
2025-04-24 19:09:03,556 - INFO - Training progress: {'loss': 1.6222, 'grad_norm': 1.3671550750732422, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.07932573128408528}
2025-04-24 19:09:03,556 - INFO - Training metrics: {'loss': 1.6222, 'grad_norm': 1.3671550750732422, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.07932573128408528}
2025-04-24 19:12:01,535 - INFO - INFO: Training progress: {'loss': 1.5014, 'grad_norm': 0.9252927899360657, 'learning_rate': 1.8e-05, 'epoch': 0.08924144769459594}
2025-04-24 19:12:01,535 - INFO - Training progress: {'loss': 1.5014, 'grad_norm': 0.9252927899360657, 'learning_rate': 1.8e-05, 'epoch': 0.08924144769459594}
2025-04-24 19:12:01,535 - INFO - Training metrics: {'loss': 1.5014, 'grad_norm': 0.9252927899360657, 'learning_rate': 1.8e-05, 'epoch': 0.08924144769459594}
2025-04-24 19:14:58,944 - INFO - INFO: Training progress: {'loss': 1.4213, 'grad_norm': 1.2776182889938354, 'learning_rate': 2e-05, 'epoch': 0.0991571641051066}
2025-04-24 19:14:58,944 - INFO - Training progress: {'loss': 1.4213, 'grad_norm': 1.2776182889938354, 'learning_rate': 2e-05, 'epoch': 0.0991571641051066}
2025-04-24 19:14:58,944 - INFO - Training metrics: {'loss': 1.4213, 'grad_norm': 1.2776182889938354, 'learning_rate': 2e-05, 'epoch': 0.0991571641051066}
2025-04-24 19:17:56,445 - INFO - INFO: Training progress: {'loss': 1.3099, 'grad_norm': 1.3737943172454834, 'learning_rate': 1.999942282058277e-05, 'epoch': 0.10907288051561725}
2025-04-24 19:17:56,445 - INFO - Training progress: {'loss': 1.3099, 'grad_norm': 1.3737943172454834, 'learning_rate': 1.999942282058277e-05, 'epoch': 0.10907288051561725}
2025-04-24 19:17:56,445 - INFO - Training metrics: {'loss': 1.3099, 'grad_norm': 1.3737943172454834, 'learning_rate': 1.999942282058277e-05, 'epoch': 0.10907288051561725}
2025-04-24 19:20:53,946 - INFO - INFO: Training progress: {'loss': 1.1753, 'grad_norm': 2.0575034618377686, 'learning_rate': 1.9997691348958278e-05, 'epoch': 0.11898859692612791}
2025-04-24 19:20:53,946 - INFO - Training progress: {'loss': 1.1753, 'grad_norm': 2.0575034618377686, 'learning_rate': 1.9997691348958278e-05, 'epoch': 0.11898859692612791}
2025-04-24 19:20:53,946 - INFO - Training metrics: {'loss': 1.1753, 'grad_norm': 2.0575034618377686, 'learning_rate': 1.9997691348958278e-05, 'epoch': 0.11898859692612791}
2025-04-24 19:23:52,221 - INFO - INFO: Training progress: {'loss': 1.1398, 'grad_norm': 1.5157206058502197, 'learning_rate': 1.9994805785000493e-05, 'epoch': 0.12890431333663857}
2025-04-24 19:23:52,221 - INFO - Training progress: {'loss': 1.1398, 'grad_norm': 1.5157206058502197, 'learning_rate': 1.9994805785000493e-05, 'epoch': 0.12890431333663857}
2025-04-24 19:23:52,221 - INFO - Training metrics: {'loss': 1.1398, 'grad_norm': 1.5157206058502197, 'learning_rate': 1.9994805785000493e-05, 'epoch': 0.12890431333663857}
2025-04-24 19:26:50,945 - INFO - INFO: Training progress: {'loss': 1.0677, 'grad_norm': 0.9237755537033081, 'learning_rate': 1.9990766461807037e-05, 'epoch': 0.13882002974714924}
2025-04-24 19:26:50,945 - INFO - Training progress: {'loss': 1.0677, 'grad_norm': 0.9237755537033081, 'learning_rate': 1.9990766461807037e-05, 'epoch': 0.13882002974714924}
2025-04-24 19:26:50,945 - INFO - Training metrics: {'loss': 1.0677, 'grad_norm': 0.9237755537033081, 'learning_rate': 1.9990766461807037e-05, 'epoch': 0.13882002974714924}
2025-04-24 19:29:48,990 - INFO - INFO: Training progress: {'loss': 1.0868, 'grad_norm': 2.0866827964782715, 'learning_rate': 1.998557384566075e-05, 'epoch': 0.1487357461576599}
2025-04-24 19:29:48,990 - INFO - Training progress: {'loss': 1.0868, 'grad_norm': 2.0866827964782715, 'learning_rate': 1.998557384566075e-05, 'epoch': 0.1487357461576599}
2025-04-24 19:29:48,990 - INFO - Training metrics: {'loss': 1.0868, 'grad_norm': 2.0866827964782715, 'learning_rate': 1.998557384566075e-05, 'epoch': 0.1487357461576599}
2025-04-24 19:32:46,409 - INFO - INFO: Training progress: {'loss': 1.014, 'grad_norm': 1.5326366424560547, 'learning_rate': 1.9979228535975866e-05, 'epoch': 0.15865146256817056}
2025-04-24 19:32:46,409 - INFO - Training progress: {'loss': 1.014, 'grad_norm': 1.5326366424560547, 'learning_rate': 1.9979228535975866e-05, 'epoch': 0.15865146256817056}
2025-04-24 19:32:46,409 - INFO - Training metrics: {'loss': 1.014, 'grad_norm': 1.5326366424560547, 'learning_rate': 1.9979228535975866e-05, 'epoch': 0.15865146256817056}
2025-04-24 19:35:43,444 - INFO - INFO: Training progress: {'loss': 1.039, 'grad_norm': 2.9747536182403564, 'learning_rate': 1.9971731265228813e-05, 'epoch': 0.1685671789786812}
2025-04-24 19:35:43,444 - INFO - Training progress: {'loss': 1.039, 'grad_norm': 2.9747536182403564, 'learning_rate': 1.9971731265228813e-05, 'epoch': 0.1685671789786812}
2025-04-24 19:35:43,444 - INFO - Training metrics: {'loss': 1.039, 'grad_norm': 2.9747536182403564, 'learning_rate': 1.9971731265228813e-05, 'epoch': 0.1685671789786812}
2025-04-24 19:38:40,759 - INFO - INFO: Training progress: {'loss': 1.0021, 'grad_norm': 1.8676007986068726, 'learning_rate': 1.996308289887366e-05, 'epoch': 0.17848289538919188}
2025-04-24 19:38:40,759 - INFO - Training progress: {'loss': 1.0021, 'grad_norm': 1.8676007986068726, 'learning_rate': 1.996308289887366e-05, 'epoch': 0.17848289538919188}
2025-04-24 19:38:40,759 - INFO - Training metrics: {'loss': 1.0021, 'grad_norm': 1.8676007986068726, 'learning_rate': 1.996308289887366e-05, 'epoch': 0.17848289538919188}
2025-04-24 19:41:37,866 - INFO - INFO: Training progress: {'loss': 0.9976, 'grad_norm': 2.2294256687164307, 'learning_rate': 1.9953284435242222e-05, 'epoch': 0.18839861179970252}
2025-04-24 19:41:37,866 - INFO - Training progress: {'loss': 0.9976, 'grad_norm': 2.2294256687164307, 'learning_rate': 1.9953284435242222e-05, 'epoch': 0.18839861179970252}
2025-04-24 19:41:37,866 - INFO - Training metrics: {'loss': 0.9976, 'grad_norm': 2.2294256687164307, 'learning_rate': 1.9953284435242222e-05, 'epoch': 0.18839861179970252}
2025-04-24 19:44:35,332 - INFO - INFO: Training progress: {'loss': 1.0181, 'grad_norm': 1.071062684059143, 'learning_rate': 1.9942337005428805e-05, 'epoch': 0.1983143282102132}
2025-04-24 19:44:35,332 - INFO - Training progress: {'loss': 1.0181, 'grad_norm': 1.071062684059143, 'learning_rate': 1.9942337005428805e-05, 'epoch': 0.1983143282102132}
2025-04-24 19:44:35,332 - INFO - Training metrics: {'loss': 1.0181, 'grad_norm': 1.071062684059143, 'learning_rate': 1.9942337005428805e-05, 'epoch': 0.1983143282102132}
2025-04-24 19:44:36,006 - INFO - INFO: Saving checkpoint at step 200
2025-04-24 19:44:36,006 - INFO - Saving checkpoint at step 200
2025-04-24 19:44:36,006 - INFO - Saving checkpoint at step 200
2025-04-24 19:47:33,104 - INFO - INFO: Training progress: {'loss': 0.9822, 'grad_norm': 1.1863306760787964, 'learning_rate': 1.9930241873159638e-05, 'epoch': 0.20823004462072384}
2025-04-24 19:47:33,104 - INFO - Training progress: {'loss': 0.9822, 'grad_norm': 1.1863306760787964, 'learning_rate': 1.9930241873159638e-05, 'epoch': 0.20823004462072384}
2025-04-24 19:47:33,104 - INFO - Training metrics: {'loss': 0.9822, 'grad_norm': 1.1863306760787964, 'learning_rate': 1.9930241873159638e-05, 'epoch': 0.20823004462072384}
2025-04-24 19:50:29,974 - INFO - INFO: Training progress: {'loss': 0.9842, 'grad_norm': 2.8085415363311768, 'learning_rate': 1.9917000434647e-05, 'epoch': 0.2181457610312345}
2025-04-24 19:50:29,974 - INFO - Training progress: {'loss': 0.9842, 'grad_norm': 2.8085415363311768, 'learning_rate': 1.9917000434647e-05, 'epoch': 0.2181457610312345}
2025-04-24 19:50:29,974 - INFO - Training metrics: {'loss': 0.9842, 'grad_norm': 2.8085415363311768, 'learning_rate': 1.9917000434647e-05, 'epoch': 0.2181457610312345}
2025-04-24 19:53:27,113 - INFO - INFO: Training progress: {'loss': 0.9317, 'grad_norm': 1.8144018650054932, 'learning_rate': 1.990261421842805e-05, 'epoch': 0.22806147744174515}
2025-04-24 19:53:27,113 - INFO - Training progress: {'loss': 0.9317, 'grad_norm': 1.8144018650054932, 'learning_rate': 1.990261421842805e-05, 'epoch': 0.22806147744174515}
2025-04-24 19:53:27,113 - INFO - Training metrics: {'loss': 0.9317, 'grad_norm': 1.8144018650054932, 'learning_rate': 1.990261421842805e-05, 'epoch': 0.22806147744174515}
2025-04-24 19:56:24,157 - INFO - INFO: Training progress: {'loss': 0.9183, 'grad_norm': 1.4564182758331299, 'learning_rate': 1.9887084885188354e-05, 'epoch': 0.23797719385225583}
2025-04-24 19:56:24,157 - INFO - Training progress: {'loss': 0.9183, 'grad_norm': 1.4564182758331299, 'learning_rate': 1.9887084885188354e-05, 'epoch': 0.23797719385225583}
2025-04-24 19:56:24,157 - INFO - Training metrics: {'loss': 0.9183, 'grad_norm': 1.4564182758331299, 'learning_rate': 1.9887084885188354e-05, 'epoch': 0.23797719385225583}
2025-04-24 19:59:20,847 - INFO - INFO: Training progress: {'loss': 0.9806, 'grad_norm': 1.8654760122299194, 'learning_rate': 1.9870414227570225e-05, 'epoch': 0.2478929102627665}
2025-04-24 19:59:20,847 - INFO - Training progress: {'loss': 0.9806, 'grad_norm': 1.8654760122299194, 'learning_rate': 1.9870414227570225e-05, 'epoch': 0.2478929102627665}
2025-04-24 19:59:20,847 - INFO - Training metrics: {'loss': 0.9806, 'grad_norm': 1.8654760122299194, 'learning_rate': 1.9870414227570225e-05, 'epoch': 0.2478929102627665}
2025-04-24 20:02:18,252 - INFO - INFO: Training progress: {'loss': 0.9735, 'grad_norm': 2.183288335800171, 'learning_rate': 1.985260416996575e-05, 'epoch': 0.25780862667327714}
2025-04-24 20:02:18,252 - INFO - Training progress: {'loss': 0.9735, 'grad_norm': 2.183288335800171, 'learning_rate': 1.985260416996575e-05, 'epoch': 0.25780862667327714}
2025-04-24 20:02:18,252 - INFO - Training metrics: {'loss': 0.9735, 'grad_norm': 2.183288335800171, 'learning_rate': 1.985260416996575e-05, 'epoch': 0.25780862667327714}
2025-04-24 20:05:15,271 - INFO - INFO: Training progress: {'loss': 0.9028, 'grad_norm': 1.346072793006897, 'learning_rate': 1.983365676829466e-05, 'epoch': 0.2677243430837878}
2025-04-24 20:05:15,271 - INFO - Training progress: {'loss': 0.9028, 'grad_norm': 1.346072793006897, 'learning_rate': 1.983365676829466e-05, 'epoch': 0.2677243430837878}
2025-04-24 20:05:15,271 - INFO - Training metrics: {'loss': 0.9028, 'grad_norm': 1.346072793006897, 'learning_rate': 1.983365676829466e-05, 'epoch': 0.2677243430837878}
2025-04-24 20:08:12,078 - INFO - INFO: Training progress: {'loss': 0.8481, 'grad_norm': 1.7684437036514282, 'learning_rate': 1.9813574209767013e-05, 'epoch': 0.2776400594942985}
2025-04-24 20:08:12,078 - INFO - Training progress: {'loss': 0.8481, 'grad_norm': 1.7684437036514282, 'learning_rate': 1.9813574209767013e-05, 'epoch': 0.2776400594942985}
2025-04-24 20:08:12,078 - INFO - Training metrics: {'loss': 0.8481, 'grad_norm': 1.7684437036514282, 'learning_rate': 1.9813574209767013e-05, 'epoch': 0.2776400594942985}
2025-04-24 20:11:08,940 - INFO - INFO: Training progress: {'loss': 0.9089, 'grad_norm': 2.0608115196228027, 'learning_rate': 1.9792358812630686e-05, 'epoch': 0.28755577590480913}
2025-04-24 20:11:08,940 - INFO - Training progress: {'loss': 0.9089, 'grad_norm': 2.0608115196228027, 'learning_rate': 1.9792358812630686e-05, 'epoch': 0.28755577590480913}
2025-04-24 20:11:08,940 - INFO - Training metrics: {'loss': 0.9089, 'grad_norm': 2.0608115196228027, 'learning_rate': 1.9792358812630686e-05, 'epoch': 0.28755577590480913}
2025-04-24 20:14:05,748 - INFO - INFO: Training progress: {'loss': 0.9819, 'grad_norm': 1.2738791704177856, 'learning_rate': 1.9770013025903797e-05, 'epoch': 0.2974714923153198}
2025-04-24 20:14:05,748 - INFO - Training progress: {'loss': 0.9819, 'grad_norm': 1.2738791704177856, 'learning_rate': 1.9770013025903797e-05, 'epoch': 0.2974714923153198}
2025-04-24 20:14:05,748 - INFO - Training metrics: {'loss': 0.9819, 'grad_norm': 1.2738791704177856, 'learning_rate': 1.9770013025903797e-05, 'epoch': 0.2974714923153198}
2025-04-24 20:17:02,566 - INFO - INFO: Training progress: {'loss': 0.9225, 'grad_norm': 2.111628532409668, 'learning_rate': 1.974653942909197e-05, 'epoch': 0.3073872087258304}
2025-04-24 20:17:02,566 - INFO - Training progress: {'loss': 0.9225, 'grad_norm': 2.111628532409668, 'learning_rate': 1.974653942909197e-05, 'epoch': 0.3073872087258304}
2025-04-24 20:17:02,566 - INFO - Training metrics: {'loss': 0.9225, 'grad_norm': 2.111628532409668, 'learning_rate': 1.974653942909197e-05, 'epoch': 0.3073872087258304}
2025-04-24 20:19:59,808 - INFO - INFO: Training progress: {'loss': 0.8408, 'grad_norm': 1.4265726804733276, 'learning_rate': 1.97219407318906e-05, 'epoch': 0.3173029251363411}
2025-04-24 20:19:59,808 - INFO - Training progress: {'loss': 0.8408, 'grad_norm': 1.4265726804733276, 'learning_rate': 1.97219407318906e-05, 'epoch': 0.3173029251363411}
2025-04-24 20:19:59,808 - INFO - Training metrics: {'loss': 0.8408, 'grad_norm': 1.4265726804733276, 'learning_rate': 1.97219407318906e-05, 'epoch': 0.3173029251363411}
2025-04-24 20:22:56,720 - INFO - INFO: Training progress: {'loss': 0.9453, 'grad_norm': 1.9774545431137085, 'learning_rate': 1.9696219773872023e-05, 'epoch': 0.32721864154685176}
2025-04-24 20:22:56,720 - INFO - Training progress: {'loss': 0.9453, 'grad_norm': 1.9774545431137085, 'learning_rate': 1.9696219773872023e-05, 'epoch': 0.32721864154685176}
2025-04-24 20:22:56,720 - INFO - Training metrics: {'loss': 0.9453, 'grad_norm': 1.9774545431137085, 'learning_rate': 1.9696219773872023e-05, 'epoch': 0.32721864154685176}
2025-04-24 20:25:53,696 - INFO - INFO: Training progress: {'loss': 0.8947, 'grad_norm': 1.4888402223587036, 'learning_rate': 1.9669379524157755e-05, 'epoch': 0.3371343579573624}
2025-04-24 20:25:53,696 - INFO - Training progress: {'loss': 0.8947, 'grad_norm': 1.4888402223587036, 'learning_rate': 1.9669379524157755e-05, 'epoch': 0.3371343579573624}
2025-04-24 20:25:53,696 - INFO - Training metrics: {'loss': 0.8947, 'grad_norm': 1.4888402223587036, 'learning_rate': 1.9669379524157755e-05, 'epoch': 0.3371343579573624}
2025-04-24 20:28:50,582 - INFO - INFO: Training progress: {'loss': 0.8277, 'grad_norm': 2.51129412651062, 'learning_rate': 1.964142308107573e-05, 'epoch': 0.34705007436787305}
2025-04-24 20:28:50,582 - INFO - Training progress: {'loss': 0.8277, 'grad_norm': 2.51129412651062, 'learning_rate': 1.964142308107573e-05, 'epoch': 0.34705007436787305}
2025-04-24 20:28:50,582 - INFO - Training metrics: {'loss': 0.8277, 'grad_norm': 2.51129412651062, 'learning_rate': 1.964142308107573e-05, 'epoch': 0.34705007436787305}
2025-04-24 20:45:44,719 - INFO - INFO: Training progress: {'eval_loss': 0.9031513929367065, 'eval_runtime': 1014.1378, 'eval_samples_per_second': 1.838, 'eval_steps_per_second': 1.838, 'epoch': 0.34705007436787305}
2025-04-24 20:45:44,719 - INFO - Training progress: {'eval_loss': 0.9031513929367065, 'eval_runtime': 1014.1378, 'eval_samples_per_second': 1.838, 'eval_steps_per_second': 1.838, 'epoch': 0.34705007436787305}
2025-04-24 20:45:44,719 - INFO - Training metrics: {'eval_loss': 0.9031513929367065, 'eval_runtime': 1014.1378, 'eval_samples_per_second': 1.838, 'eval_steps_per_second': 1.838, 'epoch': 0.34705007436787305}
2025-04-24 20:48:41,976 - INFO - INFO: Training progress: {'loss': 0.7657, 'grad_norm': 2.007246971130371, 'learning_rate': 1.9612353671802658e-05, 'epoch': 0.35696579077838375}
2025-04-24 20:48:41,976 - INFO - Training progress: {'loss': 0.7657, 'grad_norm': 2.007246971130371, 'learning_rate': 1.9612353671802658e-05, 'epoch': 0.35696579077838375}
2025-04-24 20:48:41,976 - INFO - Training metrics: {'loss': 0.7657, 'grad_norm': 2.007246971130371, 'learning_rate': 1.9612353671802658e-05, 'epoch': 0.35696579077838375}
2025-04-24 20:51:39,139 - INFO - INFO: Training progress: {'loss': 0.8903, 'grad_norm': 1.1596072912216187, 'learning_rate': 1.9582174651991474e-05, 'epoch': 0.3668815071888944}
2025-04-24 20:51:39,139 - INFO - Training progress: {'loss': 0.8903, 'grad_norm': 1.1596072912216187, 'learning_rate': 1.9582174651991474e-05, 'epoch': 0.3668815071888944}
2025-04-24 20:51:39,139 - INFO - Training metrics: {'loss': 0.8903, 'grad_norm': 1.1596072912216187, 'learning_rate': 1.9582174651991474e-05, 'epoch': 0.3668815071888944}
2025-04-24 20:54:36,140 - INFO - INFO: Training progress: {'loss': 0.9189, 'grad_norm': 1.284295916557312, 'learning_rate': 1.9550889505383996e-05, 'epoch': 0.37679722359940504}
2025-04-24 20:54:36,140 - INFO - Training progress: {'loss': 0.9189, 'grad_norm': 1.284295916557312, 'learning_rate': 1.9550889505383996e-05, 'epoch': 0.37679722359940504}
2025-04-24 20:54:36,140 - INFO - Training metrics: {'loss': 0.9189, 'grad_norm': 1.284295916557312, 'learning_rate': 1.9550889505383996e-05, 'epoch': 0.37679722359940504}
2025-04-24 20:57:33,121 - INFO - INFO: Training progress: {'loss': 0.8933, 'grad_norm': 1.0322513580322266, 'learning_rate': 1.9518501843408763e-05, 'epoch': 0.38671294000991574}
2025-04-24 20:57:33,121 - INFO - Training progress: {'loss': 0.8933, 'grad_norm': 1.0322513580322266, 'learning_rate': 1.9518501843408763e-05, 'epoch': 0.38671294000991574}
2025-04-24 20:57:33,121 - INFO - Training metrics: {'loss': 0.8933, 'grad_norm': 1.0322513580322266, 'learning_rate': 1.9518501843408763e-05, 'epoch': 0.38671294000991574}
2025-04-24 21:00:30,051 - INFO - INFO: Training progress: {'loss': 0.953, 'grad_norm': 1.786908507347107, 'learning_rate': 1.948501540476414e-05, 'epoch': 0.3966286564204264}
2025-04-24 21:00:30,051 - INFO - Training progress: {'loss': 0.953, 'grad_norm': 1.786908507347107, 'learning_rate': 1.948501540476414e-05, 'epoch': 0.3966286564204264}
2025-04-24 21:00:30,051 - INFO - Training metrics: {'loss': 0.953, 'grad_norm': 1.786908507347107, 'learning_rate': 1.948501540476414e-05, 'epoch': 0.3966286564204264}
2025-04-24 21:00:30,704 - INFO - INFO: Saving checkpoint at step 400
2025-04-24 21:00:30,704 - INFO - Saving checkpoint at step 400
2025-04-24 21:00:30,704 - INFO - Saving checkpoint at step 400
2025-04-24 21:03:27,814 - INFO - INFO: Training progress: {'loss': 0.7727, 'grad_norm': 1.8988968133926392, 'learning_rate': 1.9450434054986766e-05, 'epoch': 0.40654437283093703}
2025-04-24 21:03:27,814 - INFO - Training progress: {'loss': 0.7727, 'grad_norm': 1.8988968133926392, 'learning_rate': 1.9450434054986766e-05, 'epoch': 0.40654437283093703}
2025-04-24 21:03:27,814 - INFO - Training metrics: {'loss': 0.7727, 'grad_norm': 1.8988968133926392, 'learning_rate': 1.9450434054986766e-05, 'epoch': 0.40654437283093703}
2025-04-24 21:06:24,817 - INFO - INFO: Training progress: {'loss': 0.8806, 'grad_norm': 2.6022963523864746, 'learning_rate': 1.9414761786005293e-05, 'epoch': 0.4164600892414477}
2025-04-24 21:06:24,817 - INFO - Training progress: {'loss': 0.8806, 'grad_norm': 2.6022963523864746, 'learning_rate': 1.9414761786005293e-05, 'epoch': 0.4164600892414477}
2025-04-24 21:06:24,817 - INFO - Training metrics: {'loss': 0.8806, 'grad_norm': 2.6022963523864746, 'learning_rate': 1.9414761786005293e-05, 'epoch': 0.4164600892414477}
2025-04-24 21:09:21,842 - INFO - INFO: Training progress: {'loss': 0.8007, 'grad_norm': 2.100355625152588, 'learning_rate': 1.9378002715679613e-05, 'epoch': 0.4263758056519584}
2025-04-24 21:09:21,842 - INFO - Training progress: {'loss': 0.8007, 'grad_norm': 2.100355625152588, 'learning_rate': 1.9378002715679613e-05, 'epoch': 0.4263758056519584}
2025-04-24 21:09:21,842 - INFO - Training metrics: {'loss': 0.8007, 'grad_norm': 2.100355625152588, 'learning_rate': 1.9378002715679613e-05, 'epoch': 0.4263758056519584}
2025-04-24 21:12:18,671 - INFO - INFO: Training progress: {'loss': 0.8276, 'grad_norm': 1.8012043237686157, 'learning_rate': 1.9340161087325483e-05, 'epoch': 0.436291522062469}
2025-04-24 21:12:18,671 - INFO - Training progress: {'loss': 0.8276, 'grad_norm': 1.8012043237686157, 'learning_rate': 1.9340161087325483e-05, 'epoch': 0.436291522062469}
2025-04-24 21:12:18,671 - INFO - Training metrics: {'loss': 0.8276, 'grad_norm': 1.8012043237686157, 'learning_rate': 1.9340161087325483e-05, 'epoch': 0.436291522062469}
2025-04-24 21:15:15,548 - INFO - INFO: Training progress: {'loss': 0.8043, 'grad_norm': 1.1738970279693604, 'learning_rate': 1.93012412692247e-05, 'epoch': 0.44620723847297966}
2025-04-24 21:15:15,548 - INFO - Training progress: {'loss': 0.8043, 'grad_norm': 1.1738970279693604, 'learning_rate': 1.93012412692247e-05, 'epoch': 0.44620723847297966}
2025-04-24 21:15:15,548 - INFO - Training metrics: {'loss': 0.8043, 'grad_norm': 1.1738970279693604, 'learning_rate': 1.93012412692247e-05, 'epoch': 0.44620723847297966}
2025-04-24 21:18:12,523 - INFO - INFO: Training progress: {'loss': 0.862, 'grad_norm': 0.9974725842475891, 'learning_rate': 1.9261247754120846e-05, 'epoch': 0.4561229548834903}
2025-04-24 21:18:12,538 - INFO - Training progress: {'loss': 0.862, 'grad_norm': 0.9974725842475891, 'learning_rate': 1.9261247754120846e-05, 'epoch': 0.4561229548834903}
2025-04-24 21:18:12,538 - INFO - Training metrics: {'loss': 0.862, 'grad_norm': 0.9974725842475891, 'learning_rate': 1.9261247754120846e-05, 'epoch': 0.4561229548834903}
2025-04-24 21:21:09,734 - INFO - INFO: Training progress: {'loss': 0.9277, 'grad_norm': 0.9998094439506531, 'learning_rate': 1.9220185158700677e-05, 'epoch': 0.466038671294001}
2025-04-24 21:21:09,734 - INFO - Training progress: {'loss': 0.9277, 'grad_norm': 0.9998094439506531, 'learning_rate': 1.9220185158700677e-05, 'epoch': 0.466038671294001}
2025-04-24 21:21:09,734 - INFO - Training metrics: {'loss': 0.9277, 'grad_norm': 0.9998094439506531, 'learning_rate': 1.9220185158700677e-05, 'epoch': 0.466038671294001}
2025-04-24 21:24:07,282 - INFO - INFO: Training progress: {'loss': 0.9235, 'grad_norm': 1.7047144174575806, 'learning_rate': 1.917805822306117e-05, 'epoch': 0.47595438770451165}
2025-04-24 21:24:07,282 - INFO - Training progress: {'loss': 0.9235, 'grad_norm': 1.7047144174575806, 'learning_rate': 1.917805822306117e-05, 'epoch': 0.47595438770451165}
2025-04-24 21:24:07,282 - INFO - Training metrics: {'loss': 0.9235, 'grad_norm': 1.7047144174575806, 'learning_rate': 1.917805822306117e-05, 'epoch': 0.47595438770451165}
2025-04-24 21:27:05,023 - INFO - INFO: Training progress: {'loss': 1.1136, 'grad_norm': 1.996516466140747, 'learning_rate': 1.9134871810162358e-05, 'epoch': 0.4858701041150223}
2025-04-24 21:27:05,023 - INFO - Training progress: {'loss': 1.1136, 'grad_norm': 1.996516466140747, 'learning_rate': 1.9134871810162358e-05, 'epoch': 0.4858701041150223}
2025-04-24 21:27:05,023 - INFO - Training metrics: {'loss': 1.1136, 'grad_norm': 1.996516466140747, 'learning_rate': 1.9134871810162358e-05, 'epoch': 0.4858701041150223}
2025-04-24 21:30:02,786 - INFO - INFO: Training progress: {'loss': 0.7939, 'grad_norm': 2.5499625205993652, 'learning_rate': 1.9090630905265963e-05, 'epoch': 0.495785820525533}
2025-04-24 21:30:02,786 - INFO - Training progress: {'loss': 0.7939, 'grad_norm': 2.5499625205993652, 'learning_rate': 1.9090630905265963e-05, 'epoch': 0.495785820525533}
2025-04-24 21:30:02,786 - INFO - Training metrics: {'loss': 0.7939, 'grad_norm': 2.5499625205993652, 'learning_rate': 1.9090630905265963e-05, 'epoch': 0.495785820525533}
2025-04-24 21:33:00,831 - INFO - INFO: Training progress: {'loss': 0.8701, 'grad_norm': 1.7225053310394287, 'learning_rate': 1.9045340615359927e-05, 'epoch': 0.5057015369360436}
2025-04-24 21:33:00,831 - INFO - Training progress: {'loss': 0.8701, 'grad_norm': 1.7225053310394287, 'learning_rate': 1.9045340615359927e-05, 'epoch': 0.5057015369360436}
2025-04-24 21:33:00,831 - INFO - Training metrics: {'loss': 0.8701, 'grad_norm': 1.7225053310394287, 'learning_rate': 1.9045340615359927e-05, 'epoch': 0.5057015369360436}
2025-04-24 21:35:57,810 - INFO - INFO: Training progress: {'loss': 0.8741, 'grad_norm': 2.095226287841797, 'learning_rate': 1.8999006168568883e-05, 'epoch': 0.5156172533465543}
2025-04-24 21:35:57,810 - INFO - Training progress: {'loss': 0.8741, 'grad_norm': 2.095226287841797, 'learning_rate': 1.8999006168568883e-05, 'epoch': 0.5156172533465543}
2025-04-24 21:35:57,810 - INFO - Training metrics: {'loss': 0.8741, 'grad_norm': 2.095226287841797, 'learning_rate': 1.8999006168568883e-05, 'epoch': 0.5156172533465543}
2025-04-24 21:38:54,712 - INFO - INFO: Training progress: {'loss': 0.8599, 'grad_norm': 2.3654568195343018, 'learning_rate': 1.8951632913550625e-05, 'epoch': 0.525532969757065}
2025-04-24 21:38:54,712 - INFO - Training progress: {'loss': 0.8599, 'grad_norm': 2.3654568195343018, 'learning_rate': 1.8951632913550625e-05, 'epoch': 0.525532969757065}
2025-04-24 21:38:54,712 - INFO - Training metrics: {'loss': 0.8599, 'grad_norm': 2.3654568195343018, 'learning_rate': 1.8951632913550625e-05, 'epoch': 0.525532969757065}
2025-04-24 21:41:51,592 - INFO - INFO: Training progress: {'loss': 0.8072, 'grad_norm': 1.6758531332015991, 'learning_rate': 1.89032263188787e-05, 'epoch': 0.5354486861675756}
2025-04-24 21:41:51,592 - INFO - Training progress: {'loss': 0.8072, 'grad_norm': 1.6758531332015991, 'learning_rate': 1.89032263188787e-05, 'epoch': 0.5354486861675756}
2025-04-24 21:41:51,592 - INFO - Training metrics: {'loss': 0.8072, 'grad_norm': 1.6758531332015991, 'learning_rate': 1.89032263188787e-05, 'epoch': 0.5354486861675756}
2025-04-24 21:44:48,759 - INFO - INFO: Training progress: {'loss': 0.8033, 'grad_norm': 1.847610592842102, 'learning_rate': 1.8853791972411124e-05, 'epoch': 0.5453644025780863}
2025-04-24 21:44:48,759 - INFO - Training progress: {'loss': 0.8033, 'grad_norm': 1.847610592842102, 'learning_rate': 1.8853791972411124e-05, 'epoch': 0.5453644025780863}
2025-04-24 21:44:48,759 - INFO - Training metrics: {'loss': 0.8033, 'grad_norm': 1.847610592842102, 'learning_rate': 1.8853791972411124e-05, 'epoch': 0.5453644025780863}
2025-04-24 21:47:45,446 - INFO - INFO: Training progress: {'loss': 0.878, 'grad_norm': 2.044783353805542, 'learning_rate': 1.880333558064536e-05, 'epoch': 0.555280118988597}
2025-04-24 21:47:45,446 - INFO - Training progress: {'loss': 0.878, 'grad_norm': 2.044783353805542, 'learning_rate': 1.880333558064536e-05, 'epoch': 0.555280118988597}
2025-04-24 21:47:45,446 - INFO - Training metrics: {'loss': 0.878, 'grad_norm': 2.044783353805542, 'learning_rate': 1.880333558064536e-05, 'epoch': 0.555280118988597}
2025-04-24 21:50:42,452 - INFO - INFO: Training progress: {'loss': 0.8553, 'grad_norm': 1.2773250341415405, 'learning_rate': 1.875186296805956e-05, 'epoch': 0.5651958353991076}
2025-04-24 21:50:42,452 - INFO - Training progress: {'loss': 0.8553, 'grad_norm': 1.2773250341415405, 'learning_rate': 1.875186296805956e-05, 'epoch': 0.5651958353991076}
2025-04-24 21:50:42,452 - INFO - Training metrics: {'loss': 0.8553, 'grad_norm': 1.2773250341415405, 'learning_rate': 1.875186296805956e-05, 'epoch': 0.5651958353991076}
2025-04-24 21:53:39,231 - INFO - INFO: Training progress: {'loss': 0.8349, 'grad_norm': 2.0980701446533203, 'learning_rate': 1.8699380076440242e-05, 'epoch': 0.5751115518096183}
2025-04-24 21:53:39,231 - INFO - Training progress: {'loss': 0.8349, 'grad_norm': 2.0980701446533203, 'learning_rate': 1.8699380076440242e-05, 'epoch': 0.5751115518096183}
2025-04-24 21:53:39,231 - INFO - Training metrics: {'loss': 0.8349, 'grad_norm': 2.0980701446533203, 'learning_rate': 1.8699380076440242e-05, 'epoch': 0.5751115518096183}
2025-04-24 21:56:36,093 - INFO - INFO: Training progress: {'loss': 0.8685, 'grad_norm': 2.908398151397705, 'learning_rate': 1.8645892964196356e-05, 'epoch': 0.585027268220129}
2025-04-24 21:56:36,093 - INFO - Training progress: {'loss': 0.8685, 'grad_norm': 2.908398151397705, 'learning_rate': 1.8645892964196356e-05, 'epoch': 0.585027268220129}
2025-04-24 21:56:36,093 - INFO - Training metrics: {'loss': 0.8685, 'grad_norm': 2.908398151397705, 'learning_rate': 1.8645892964196356e-05, 'epoch': 0.585027268220129}
2025-04-24 21:59:33,040 - INFO - INFO: Training progress: {'loss': 0.9571, 'grad_norm': 2.358144998550415, 'learning_rate': 1.859140780565996e-05, 'epoch': 0.5949429846306395}
2025-04-24 21:59:33,040 - INFO - Training progress: {'loss': 0.9571, 'grad_norm': 2.358144998550415, 'learning_rate': 1.859140780565996e-05, 'epoch': 0.5949429846306395}
2025-04-24 21:59:33,040 - INFO - Training metrics: {'loss': 0.9571, 'grad_norm': 2.358144998550415, 'learning_rate': 1.859140780565996e-05, 'epoch': 0.5949429846306395}
2025-04-24 21:59:33,747 - INFO - INFO: Saving checkpoint at step 600
2025-04-24 21:59:33,747 - INFO - Saving checkpoint at step 600
2025-04-24 21:59:33,747 - INFO - Saving checkpoint at step 600
2025-04-24 22:02:30,625 - INFO - INFO: Training progress: {'loss': 0.7809, 'grad_norm': 2.6729981899261475, 'learning_rate': 1.8535930890373467e-05, 'epoch': 0.6048587010411502}
2025-04-24 22:02:30,625 - INFO - Training progress: {'loss': 0.7809, 'grad_norm': 2.6729981899261475, 'learning_rate': 1.8535930890373467e-05, 'epoch': 0.6048587010411502}
2025-04-24 22:02:30,625 - INFO - Training metrics: {'loss': 0.7809, 'grad_norm': 2.6729981899261475, 'learning_rate': 1.8535930890373467e-05, 'epoch': 0.6048587010411502}
2025-04-24 22:05:27,571 - INFO - INFO: Training progress: {'loss': 0.8029, 'grad_norm': 1.756555199623108, 'learning_rate': 1.84794686223636e-05, 'epoch': 0.6147744174516608}
2025-04-24 22:05:27,571 - INFO - Training progress: {'loss': 0.8029, 'grad_norm': 1.756555199623108, 'learning_rate': 1.84794686223636e-05, 'epoch': 0.6147744174516608}
2025-04-24 22:05:27,571 - INFO - Training metrics: {'loss': 0.8029, 'grad_norm': 1.756555199623108, 'learning_rate': 1.84794686223636e-05, 'epoch': 0.6147744174516608}
2025-04-24 22:08:24,468 - INFO - INFO: Training progress: {'loss': 0.8233, 'grad_norm': 1.9046021699905396, 'learning_rate': 1.842202751940215e-05, 'epoch': 0.6246901338621715}
2025-04-24 22:08:24,468 - INFO - Training progress: {'loss': 0.8233, 'grad_norm': 1.9046021699905396, 'learning_rate': 1.842202751940215e-05, 'epoch': 0.6246901338621715}
2025-04-24 22:08:24,468 - INFO - Training metrics: {'loss': 0.8233, 'grad_norm': 1.9046021699905396, 'learning_rate': 1.842202751940215e-05, 'epoch': 0.6246901338621715}
2025-04-24 22:11:21,590 - INFO - INFO: Training progress: {'loss': 0.8751, 'grad_norm': 1.8939999341964722, 'learning_rate': 1.8363614212253585e-05, 'epoch': 0.6346058502726822}
2025-04-24 22:11:21,590 - INFO - Training progress: {'loss': 0.8751, 'grad_norm': 1.8939999341964722, 'learning_rate': 1.8363614212253585e-05, 'epoch': 0.6346058502726822}
2025-04-24 22:11:21,590 - INFO - Training metrics: {'loss': 0.8751, 'grad_norm': 1.8939999341964722, 'learning_rate': 1.8363614212253585e-05, 'epoch': 0.6346058502726822}
2025-04-24 22:14:21,257 - INFO - INFO: Training progress: {'loss': 0.8256, 'grad_norm': 1.8848367929458618, 'learning_rate': 1.8304235443909618e-05, 'epoch': 0.6445215666831928}
2025-04-24 22:14:21,257 - INFO - Training progress: {'loss': 0.8256, 'grad_norm': 1.8848367929458618, 'learning_rate': 1.8304235443909618e-05, 'epoch': 0.6445215666831928}
2025-04-24 22:14:21,257 - INFO - Training metrics: {'loss': 0.8256, 'grad_norm': 1.8848367929458618, 'learning_rate': 1.8304235443909618e-05, 'epoch': 0.6445215666831928}
2025-04-24 22:17:22,315 - INFO - INFO: Training progress: {'loss': 0.7944, 'grad_norm': 1.3182276487350464, 'learning_rate': 1.8243898068810833e-05, 'epoch': 0.6544372830937035}
2025-04-24 22:17:22,315 - INFO - Training progress: {'loss': 0.7944, 'grad_norm': 1.3182276487350464, 'learning_rate': 1.8243898068810833e-05, 'epoch': 0.6544372830937035}
2025-04-24 22:17:22,315 - INFO - Training metrics: {'loss': 0.7944, 'grad_norm': 1.3182276487350464, 'learning_rate': 1.8243898068810833e-05, 'epoch': 0.6544372830937035}
2025-04-24 22:20:23,454 - INFO - INFO: Training progress: {'loss': 0.8024, 'grad_norm': 2.219576358795166, 'learning_rate': 1.8182609052055432e-05, 'epoch': 0.6643529995042142}
2025-04-24 22:20:23,454 - INFO - Training progress: {'loss': 0.8024, 'grad_norm': 2.219576358795166, 'learning_rate': 1.8182609052055432e-05, 'epoch': 0.6643529995042142}
2025-04-24 22:20:23,454 - INFO - Training metrics: {'loss': 0.8024, 'grad_norm': 2.219576358795166, 'learning_rate': 1.8182609052055432e-05, 'epoch': 0.6643529995042142}
2025-04-24 22:23:21,362 - INFO - INFO: Training progress: {'loss': 0.8889, 'grad_norm': 1.804144024848938, 'learning_rate': 1.81203754685952e-05, 'epoch': 0.6742687159147248}
2025-04-24 22:23:21,362 - INFO - Training progress: {'loss': 0.8889, 'grad_norm': 1.804144024848938, 'learning_rate': 1.81203754685952e-05, 'epoch': 0.6742687159147248}
2025-04-24 22:23:21,362 - INFO - Training metrics: {'loss': 0.8889, 'grad_norm': 1.804144024848938, 'learning_rate': 1.81203754685952e-05, 'epoch': 0.6742687159147248}
2025-04-24 22:26:23,902 - INFO - INFO: Training progress: {'loss': 0.7473, 'grad_norm': 1.6966923475265503, 'learning_rate': 1.805720450241883e-05, 'epoch': 0.6841844323252355}
2025-04-24 22:26:23,902 - INFO - Training progress: {'loss': 0.7473, 'grad_norm': 1.6966923475265503, 'learning_rate': 1.805720450241883e-05, 'epoch': 0.6841844323252355}
2025-04-24 22:26:23,902 - INFO - Training metrics: {'loss': 0.7473, 'grad_norm': 1.6966923475265503, 'learning_rate': 1.805720450241883e-05, 'epoch': 0.6841844323252355}
2025-04-24 22:29:26,120 - INFO - INFO: Training progress: {'loss': 0.8448, 'grad_norm': 1.7031149864196777, 'learning_rate': 1.7993103445722615e-05, 'epoch': 0.6941001487357461}
2025-04-24 22:29:26,120 - INFO - Training progress: {'loss': 0.8448, 'grad_norm': 1.7031149864196777, 'learning_rate': 1.7993103445722615e-05, 'epoch': 0.6941001487357461}
2025-04-24 22:29:26,120 - INFO - Training metrics: {'loss': 0.8448, 'grad_norm': 1.7031149864196777, 'learning_rate': 1.7993103445722615e-05, 'epoch': 0.6941001487357461}
2025-04-24 22:46:47,736 - INFO - INFO: Training progress: {'eval_loss': 0.8257110714912415, 'eval_runtime': 1041.6123, 'eval_samples_per_second': 1.79, 'eval_steps_per_second': 1.79, 'epoch': 0.6941001487357461}
2025-04-24 22:46:47,737 - INFO - Training progress: {'eval_loss': 0.8257110714912415, 'eval_runtime': 1041.6123, 'eval_samples_per_second': 1.79, 'eval_steps_per_second': 1.79, 'epoch': 0.6941001487357461}
2025-04-24 22:46:47,737 - INFO - Training metrics: {'eval_loss': 0.8257110714912415, 'eval_runtime': 1041.6123, 'eval_samples_per_second': 1.79, 'eval_steps_per_second': 1.79, 'epoch': 0.6941001487357461}
2025-04-24 22:49:49,341 - INFO - INFO: Training progress: {'loss': 0.7479, 'grad_norm': 2.17936635017395, 'learning_rate': 1.792807969806866e-05, 'epoch': 0.7040158651462568}
2025-04-24 22:49:49,341 - INFO - Training progress: {'loss': 0.7479, 'grad_norm': 2.17936635017395, 'learning_rate': 1.792807969806866e-05, 'epoch': 0.7040158651462568}
2025-04-24 22:49:49,341 - INFO - Training metrics: {'loss': 0.7479, 'grad_norm': 2.17936635017395, 'learning_rate': 1.792807969806866e-05, 'epoch': 0.7040158651462568}
2025-04-24 22:52:59,046 - INFO - INFO: Training progress: {'loss': 0.8314, 'grad_norm': 1.1902064085006714, 'learning_rate': 1.7862140765530718e-05, 'epoch': 0.7139315815567675}
2025-04-24 22:52:59,046 - INFO - Training progress: {'loss': 0.8314, 'grad_norm': 1.1902064085006714, 'learning_rate': 1.7862140765530718e-05, 'epoch': 0.7139315815567675}
2025-04-24 22:52:59,046 - INFO - Training metrics: {'loss': 0.8314, 'grad_norm': 1.1902064085006714, 'learning_rate': 1.7862140765530718e-05, 'epoch': 0.7139315815567675}
2025-04-24 22:56:03,792 - INFO - INFO: Training progress: {'loss': 0.8757, 'grad_norm': 1.3634490966796875, 'learning_rate': 1.7795294259827725e-05, 'epoch': 0.7238472979672781}
2025-04-24 22:56:03,792 - INFO - Training progress: {'loss': 0.8757, 'grad_norm': 1.3634490966796875, 'learning_rate': 1.7795294259827725e-05, 'epoch': 0.7238472979672781}
2025-04-24 22:56:03,792 - INFO - Training metrics: {'loss': 0.8757, 'grad_norm': 1.3634490966796875, 'learning_rate': 1.7795294259827725e-05, 'epoch': 0.7238472979672781}
2025-04-24 22:59:16,655 - INFO - INFO: Training progress: {'loss': 0.7823, 'grad_norm': 1.2955152988433838, 'learning_rate': 1.7727547897445117e-05, 'epoch': 0.7337630143777888}
2025-04-24 22:59:16,655 - INFO - Training progress: {'loss': 0.7823, 'grad_norm': 1.2955152988433838, 'learning_rate': 1.7727547897445117e-05, 'epoch': 0.7337630143777888}
2025-04-24 22:59:16,655 - INFO - Training metrics: {'loss': 0.7823, 'grad_norm': 1.2955152988433838, 'learning_rate': 1.7727547897445117e-05, 'epoch': 0.7337630143777888}
2025-04-24 23:02:26,983 - INFO - INFO: Training progress: {'loss': 0.8134, 'grad_norm': 2.4129271507263184, 'learning_rate': 1.765890949874409e-05, 'epoch': 0.7436787307882995}
2025-04-24 23:02:26,983 - INFO - Training progress: {'loss': 0.8134, 'grad_norm': 2.4129271507263184, 'learning_rate': 1.765890949874409e-05, 'epoch': 0.7436787307882995}
2025-04-24 23:02:26,983 - INFO - Training metrics: {'loss': 0.8134, 'grad_norm': 2.4129271507263184, 'learning_rate': 1.765890949874409e-05, 'epoch': 0.7436787307882995}
2025-04-24 23:05:35,505 - INFO - INFO: Training progress: {'loss': 0.7841, 'grad_norm': 2.1369223594665527, 'learning_rate': 1.758938698705884e-05, 'epoch': 0.7535944471988101}
2025-04-24 23:05:35,505 - INFO - Training progress: {'loss': 0.7841, 'grad_norm': 2.1369223594665527, 'learning_rate': 1.758938698705884e-05, 'epoch': 0.7535944471988101}
2025-04-24 23:05:35,505 - INFO - Training metrics: {'loss': 0.7841, 'grad_norm': 2.1369223594665527, 'learning_rate': 1.758938698705884e-05, 'epoch': 0.7535944471988101}
2025-04-24 23:08:45,794 - INFO - INFO: Training progress: {'loss': 0.746, 'grad_norm': 1.2032790184020996, 'learning_rate': 1.7518988387781915e-05, 'epoch': 0.7635101636093208}
2025-04-24 23:08:45,794 - INFO - Training progress: {'loss': 0.746, 'grad_norm': 1.2032790184020996, 'learning_rate': 1.7518988387781915e-05, 'epoch': 0.7635101636093208}
2025-04-24 23:08:45,794 - INFO - Training metrics: {'loss': 0.746, 'grad_norm': 1.2032790184020996, 'learning_rate': 1.7518988387781915e-05, 'epoch': 0.7635101636093208}
2025-04-24 23:11:51,139 - INFO - INFO: Training progress: {'loss': 0.7666, 'grad_norm': 1.2424851655960083, 'learning_rate': 1.7447721827437822e-05, 'epoch': 0.7734258800198315}
2025-04-24 23:11:51,139 - INFO - Training progress: {'loss': 0.7666, 'grad_norm': 1.2424851655960083, 'learning_rate': 1.7447721827437822e-05, 'epoch': 0.7734258800198315}
2025-04-24 23:11:51,139 - INFO - Training metrics: {'loss': 0.7666, 'grad_norm': 1.2424851655960083, 'learning_rate': 1.7447721827437822e-05, 'epoch': 0.7734258800198315}
2025-04-24 23:14:49,086 - INFO - INFO: Training progress: {'loss': 0.7212, 'grad_norm': 2.288543224334717, 'learning_rate': 1.737559553274491e-05, 'epoch': 0.7833415964303421}
2025-04-24 23:14:49,086 - INFO - Training progress: {'loss': 0.7212, 'grad_norm': 2.288543224334717, 'learning_rate': 1.737559553274491e-05, 'epoch': 0.7833415964303421}
2025-04-24 23:14:49,086 - INFO - Training metrics: {'loss': 0.7212, 'grad_norm': 2.288543224334717, 'learning_rate': 1.737559553274491e-05, 'epoch': 0.7833415964303421}
2025-04-24 23:17:47,050 - INFO - INFO: Training progress: {'loss': 0.7999, 'grad_norm': 2.0034148693084717, 'learning_rate': 1.7302617829665725e-05, 'epoch': 0.7932573128408528}
2025-04-24 23:17:47,051 - INFO - Training progress: {'loss': 0.7999, 'grad_norm': 2.0034148693084717, 'learning_rate': 1.7302617829665725e-05, 'epoch': 0.7932573128408528}
2025-04-24 23:17:47,051 - INFO - Training metrics: {'loss': 0.7999, 'grad_norm': 2.0034148693084717, 'learning_rate': 1.7302617829665725e-05, 'epoch': 0.7932573128408528}
2025-04-24 23:17:47,716 - INFO - INFO: Saving checkpoint at step 800
2025-04-24 23:17:47,716 - INFO - Saving checkpoint at step 800
2025-04-24 23:17:47,716 - INFO - Saving checkpoint at step 800
2025-04-24 23:20:50,195 - INFO - INFO: Training progress: {'loss': 0.8022, 'grad_norm': 1.926966667175293, 'learning_rate': 1.7228797142445902e-05, 'epoch': 0.8031730292513634}
2025-04-24 23:20:50,196 - INFO - Training progress: {'loss': 0.8022, 'grad_norm': 1.926966667175293, 'learning_rate': 1.7228797142445902e-05, 'epoch': 0.8031730292513634}
2025-04-24 23:20:50,196 - INFO - Training metrics: {'loss': 0.8022, 'grad_norm': 1.926966667175293, 'learning_rate': 1.7228797142445902e-05, 'epoch': 0.8031730292513634}
2025-04-24 23:23:57,665 - INFO - INFO: Training progress: {'loss': 0.8331, 'grad_norm': 1.40554940700531, 'learning_rate': 1.715414199264168e-05, 'epoch': 0.8130887456618741}
2025-04-24 23:23:57,665 - INFO - Training progress: {'loss': 0.8331, 'grad_norm': 1.40554940700531, 'learning_rate': 1.715414199264168e-05, 'epoch': 0.8130887456618741}
2025-04-24 23:23:57,665 - INFO - Training metrics: {'loss': 0.8331, 'grad_norm': 1.40554940700531, 'learning_rate': 1.715414199264168e-05, 'epoch': 0.8130887456618741}
2025-04-24 23:27:01,367 - INFO - INFO: Training progress: {'loss': 0.7113, 'grad_norm': 1.647180199623108, 'learning_rate': 1.7078660998136232e-05, 'epoch': 0.8230044620723848}
2025-04-24 23:27:01,367 - INFO - Training progress: {'loss': 0.7113, 'grad_norm': 1.647180199623108, 'learning_rate': 1.7078660998136232e-05, 'epoch': 0.8230044620723848}
2025-04-24 23:27:01,367 - INFO - Training metrics: {'loss': 0.7113, 'grad_norm': 1.647180199623108, 'learning_rate': 1.7078660998136232e-05, 'epoch': 0.8230044620723848}
2025-04-24 23:30:03,630 - INFO - INFO: Training progress: {'loss': 0.6721, 'grad_norm': 1.3174368143081665, 'learning_rate': 1.7002362872144843e-05, 'epoch': 0.8329201784828953}
2025-04-24 23:30:03,631 - INFO - Training progress: {'loss': 0.6721, 'grad_norm': 1.3174368143081665, 'learning_rate': 1.7002362872144843e-05, 'epoch': 0.8329201784828953}
2025-04-24 23:30:03,631 - INFO - Training metrics: {'loss': 0.6721, 'grad_norm': 1.3174368143081665, 'learning_rate': 1.7002362872144843e-05, 'epoch': 0.8329201784828953}
2025-04-24 23:33:07,458 - INFO - INFO: Training progress: {'loss': 0.7556, 'grad_norm': 1.8238078355789185, 'learning_rate': 1.6925256422209094e-05, 'epoch': 0.842835894893406}
2025-04-24 23:33:07,458 - INFO - Training progress: {'loss': 0.7556, 'grad_norm': 1.8238078355789185, 'learning_rate': 1.6925256422209094e-05, 'epoch': 0.842835894893406}
2025-04-24 23:33:07,458 - INFO - Training metrics: {'loss': 0.7556, 'grad_norm': 1.8238078355789185, 'learning_rate': 1.6925256422209094e-05, 'epoch': 0.842835894893406}
2025-04-24 23:36:07,087 - INFO - INFO: Training progress: {'loss': 0.8889, 'grad_norm': 0.9769790768623352, 'learning_rate': 1.6847350549180148e-05, 'epoch': 0.8527516113039167}
2025-04-24 23:36:07,087 - INFO - Training progress: {'loss': 0.8889, 'grad_norm': 0.9769790768623352, 'learning_rate': 1.6847350549180148e-05, 'epoch': 0.8527516113039167}
2025-04-24 23:36:07,087 - INFO - Training metrics: {'loss': 0.8889, 'grad_norm': 0.9769790768623352, 'learning_rate': 1.6847350549180148e-05, 'epoch': 0.8527516113039167}
2025-04-24 23:39:07,404 - INFO - INFO: Training progress: {'loss': 0.6486, 'grad_norm': 1.5539108514785767, 'learning_rate': 1.676865424619129e-05, 'epoch': 0.8626673277144273}
2025-04-24 23:39:07,404 - INFO - Training progress: {'loss': 0.6486, 'grad_norm': 1.5539108514785767, 'learning_rate': 1.676865424619129e-05, 'epoch': 0.8626673277144273}
2025-04-24 23:39:07,404 - INFO - Training metrics: {'loss': 0.6486, 'grad_norm': 1.5539108514785767, 'learning_rate': 1.676865424619129e-05, 'epoch': 0.8626673277144273}
2025-04-24 23:42:07,097 - INFO - INFO: Training progress: {'loss': 0.8105, 'grad_norm': 1.8084359169006348, 'learning_rate': 1.6689176597619773e-05, 'epoch': 0.872583044124938}
2025-04-24 23:42:07,097 - INFO - Training progress: {'loss': 0.8105, 'grad_norm': 1.8084359169006348, 'learning_rate': 1.6689176597619773e-05, 'epoch': 0.872583044124938}
2025-04-24 23:42:07,097 - INFO - Training metrics: {'loss': 0.8105, 'grad_norm': 1.8084359169006348, 'learning_rate': 1.6689176597619773e-05, 'epoch': 0.872583044124938}
2025-04-24 23:45:05,733 - INFO - INFO: Training progress: {'loss': 0.8222, 'grad_norm': 2.205251693725586, 'learning_rate': 1.660892677803818e-05, 'epoch': 0.8824987605354487}
2025-04-24 23:45:05,733 - INFO - Training progress: {'loss': 0.8222, 'grad_norm': 2.205251693725586, 'learning_rate': 1.660892677803818e-05, 'epoch': 0.8824987605354487}
2025-04-24 23:45:05,733 - INFO - Training metrics: {'loss': 0.8222, 'grad_norm': 2.205251693725586, 'learning_rate': 1.660892677803818e-05, 'epoch': 0.8824987605354487}
2025-04-24 23:48:06,486 - INFO - INFO: Training progress: {'loss': 0.8633, 'grad_norm': 2.0862724781036377, 'learning_rate': 1.6527914051155328e-05, 'epoch': 0.8924144769459593}
2025-04-24 23:48:06,486 - INFO - Training progress: {'loss': 0.8633, 'grad_norm': 2.0862724781036377, 'learning_rate': 1.6527914051155328e-05, 'epoch': 0.8924144769459593}
2025-04-24 23:48:06,486 - INFO - Training metrics: {'loss': 0.8633, 'grad_norm': 2.0862724781036377, 'learning_rate': 1.6527914051155328e-05, 'epoch': 0.8924144769459593}
2025-04-24 23:51:05,465 - INFO - INFO: Training progress: {'loss': 0.827, 'grad_norm': 2.2229223251342773, 'learning_rate': 1.6446147768746913e-05, 'epoch': 0.90233019335647}
2025-04-24 23:51:05,466 - INFO - Training progress: {'loss': 0.827, 'grad_norm': 2.2229223251342773, 'learning_rate': 1.6446147768746913e-05, 'epoch': 0.90233019335647}
2025-04-24 23:51:05,466 - INFO - Training metrics: {'loss': 0.827, 'grad_norm': 2.2229223251342773, 'learning_rate': 1.6446147768746913e-05, 'epoch': 0.90233019335647}
2025-04-24 23:54:05,416 - INFO - INFO: Training progress: {'loss': 0.8767, 'grad_norm': 2.310899496078491, 'learning_rate': 1.6363637369575984e-05, 'epoch': 0.9122459097669806}
2025-04-24 23:54:05,416 - INFO - Training progress: {'loss': 0.8767, 'grad_norm': 2.310899496078491, 'learning_rate': 1.6363637369575984e-05, 'epoch': 0.9122459097669806}
2025-04-24 23:54:05,416 - INFO - Training metrics: {'loss': 0.8767, 'grad_norm': 2.310899496078491, 'learning_rate': 1.6363637369575984e-05, 'epoch': 0.9122459097669806}
2025-04-24 23:57:06,034 - INFO - INFO: Training progress: {'loss': 0.8135, 'grad_norm': 1.5211448669433594, 'learning_rate': 1.628039237830336e-05, 'epoch': 0.9221616261774913}
2025-04-24 23:57:06,034 - INFO - Training progress: {'loss': 0.8135, 'grad_norm': 1.5211448669433594, 'learning_rate': 1.628039237830336e-05, 'epoch': 0.9221616261774913}
2025-04-24 23:57:06,034 - INFO - Training metrics: {'loss': 0.8135, 'grad_norm': 1.5211448669433594, 'learning_rate': 1.628039237830336e-05, 'epoch': 0.9221616261774913}
2025-04-25 00:00:07,251 - INFO - INFO: Training progress: {'loss': 0.9297, 'grad_norm': 1.6738816499710083, 'learning_rate': 1.619642240438816e-05, 'epoch': 0.932077342588002}
2025-04-25 00:00:07,252 - INFO - Training progress: {'loss': 0.9297, 'grad_norm': 1.6738816499710083, 'learning_rate': 1.619642240438816e-05, 'epoch': 0.932077342588002}
2025-04-25 00:00:07,252 - INFO - Training metrics: {'loss': 0.9297, 'grad_norm': 1.6738816499710083, 'learning_rate': 1.619642240438816e-05, 'epoch': 0.932077342588002}
2025-04-25 00:03:13,081 - INFO - INFO: Training progress: {'loss': 0.7512, 'grad_norm': 1.9573473930358887, 'learning_rate': 1.6111737140978495e-05, 'epoch': 0.9419930589985126}
2025-04-25 00:03:13,081 - INFO - Training progress: {'loss': 0.7512, 'grad_norm': 1.9573473930358887, 'learning_rate': 1.6111737140978495e-05, 'epoch': 0.9419930589985126}
2025-04-25 00:03:13,081 - INFO - Training metrics: {'loss': 0.7512, 'grad_norm': 1.9573473930358887, 'learning_rate': 1.6111737140978495e-05, 'epoch': 0.9419930589985126}
2025-04-25 00:06:19,767 - INFO - INFO: Training progress: {'loss': 0.8083, 'grad_norm': 1.0834591388702393, 'learning_rate': 1.6026346363792565e-05, 'epoch': 0.9519087754090233}
2025-04-25 00:06:19,767 - INFO - Training progress: {'loss': 0.8083, 'grad_norm': 1.0834591388702393, 'learning_rate': 1.6026346363792565e-05, 'epoch': 0.9519087754090233}
2025-04-25 00:06:19,767 - INFO - Training metrics: {'loss': 0.8083, 'grad_norm': 1.0834591388702393, 'learning_rate': 1.6026346363792565e-05, 'epoch': 0.9519087754090233}
2025-04-25 00:09:28,244 - INFO - INFO: Training progress: {'loss': 0.7392, 'grad_norm': 1.8877332210540771, 'learning_rate': 1.5940259929990177e-05, 'epoch': 0.961824491819534}
2025-04-25 00:09:28,244 - INFO - Training progress: {'loss': 0.7392, 'grad_norm': 1.8877332210540771, 'learning_rate': 1.5940259929990177e-05, 'epoch': 0.961824491819534}
2025-04-25 00:09:28,244 - INFO - Training metrics: {'loss': 0.7392, 'grad_norm': 1.8877332210540771, 'learning_rate': 1.5940259929990177e-05, 'epoch': 0.961824491819534}
2025-04-25 00:12:35,477 - INFO - INFO: Training progress: {'loss': 0.832, 'grad_norm': 2.066525459289551, 'learning_rate': 1.585348777703486e-05, 'epoch': 0.9717402082300446}
2025-04-25 00:12:35,478 - INFO - Training progress: {'loss': 0.832, 'grad_norm': 2.066525459289551, 'learning_rate': 1.585348777703486e-05, 'epoch': 0.9717402082300446}
2025-04-25 00:12:35,478 - INFO - Training metrics: {'loss': 0.832, 'grad_norm': 2.066525459289551, 'learning_rate': 1.585348777703486e-05, 'epoch': 0.9717402082300446}
2025-04-25 00:15:36,047 - INFO - INFO: Training progress: {'loss': 0.8313, 'grad_norm': 1.2800413370132446, 'learning_rate': 1.5766039921546762e-05, 'epoch': 0.9816559246405553}
2025-04-25 00:15:36,048 - INFO - Training progress: {'loss': 0.8313, 'grad_norm': 1.2800413370132446, 'learning_rate': 1.5766039921546762e-05, 'epoch': 0.9816559246405553}
2025-04-25 00:15:36,048 - INFO - Training metrics: {'loss': 0.8313, 'grad_norm': 1.2800413370132446, 'learning_rate': 1.5766039921546762e-05, 'epoch': 0.9816559246405553}
2025-04-25 00:18:36,321 - INFO - INFO: Training progress: {'loss': 0.8222, 'grad_norm': 1.4758636951446533, 'learning_rate': 1.5677926458146327e-05, 'epoch': 0.991571641051066}
2025-04-25 00:18:36,321 - INFO - Training progress: {'loss': 0.8222, 'grad_norm': 1.4758636951446533, 'learning_rate': 1.5677926458146327e-05, 'epoch': 0.991571641051066}
2025-04-25 00:18:36,321 - INFO - Training metrics: {'loss': 0.8222, 'grad_norm': 1.4758636951446533, 'learning_rate': 1.5677926458146327e-05, 'epoch': 0.991571641051066}
2025-04-25 00:18:37,001 - INFO - INFO: Saving checkpoint at step 1000
2025-04-25 00:18:37,001 - INFO - Saving checkpoint at step 1000
2025-04-25 00:18:37,001 - INFO - Saving checkpoint at step 1000
2025-04-25 00:21:13,349 - INFO - INFO: Starting epoch 0.9995042141794744/3
2025-04-25 00:21:13,350 - INFO - Starting epoch 0.9995042141794744/3
2025-04-25 00:21:13,350 - INFO - Starting epoch 0.9995042141794744/3
2025-04-25 00:21:49,444 - INFO - INFO: Training progress: {'loss': 0.8075, 'grad_norm': 1.631502628326416, 'learning_rate': 1.5589157558289047e-05, 'epoch': 1.0014873574615766}
2025-04-25 00:21:49,445 - INFO - Training progress: {'loss': 0.8075, 'grad_norm': 1.631502628326416, 'learning_rate': 1.5589157558289047e-05, 'epoch': 1.0014873574615766}
2025-04-25 00:21:49,445 - INFO - Training metrics: {'loss': 0.8075, 'grad_norm': 1.631502628326416, 'learning_rate': 1.5589157558289047e-05, 'epoch': 1.0014873574615766}
2025-04-25 00:24:49,002 - INFO - INFO: Training progress: {'loss': 0.6299, 'grad_norm': 2.203219413757324, 'learning_rate': 1.5499743469091303e-05, 'epoch': 1.0114030738720872}
2025-04-25 00:24:49,003 - INFO - Training progress: {'loss': 0.6299, 'grad_norm': 2.203219413757324, 'learning_rate': 1.5499743469091303e-05, 'epoch': 1.0114030738720872}
2025-04-25 00:24:49,003 - INFO - Training metrics: {'loss': 0.6299, 'grad_norm': 2.203219413757324, 'learning_rate': 1.5499743469091303e-05, 'epoch': 1.0114030738720872}
2025-04-25 00:27:48,497 - INFO - INFO: Training progress: {'loss': 0.9816, 'grad_norm': 1.86391282081604, 'learning_rate': 1.5409694512147477e-05, 'epoch': 1.021318790282598}
2025-04-25 00:27:48,497 - INFO - Training progress: {'loss': 0.9816, 'grad_norm': 1.86391282081604, 'learning_rate': 1.5409694512147477e-05, 'epoch': 1.021318790282598}
2025-04-25 00:27:48,497 - INFO - Training metrics: {'loss': 0.9816, 'grad_norm': 1.86391282081604, 'learning_rate': 1.5409694512147477e-05, 'epoch': 1.021318790282598}
2025-04-25 00:30:47,695 - INFO - INFO: Training progress: {'loss': 0.7684, 'grad_norm': 1.3241475820541382, 'learning_rate': 1.5319021082338458e-05, 'epoch': 1.0312345066931086}
2025-04-25 00:30:47,695 - INFO - Training progress: {'loss': 0.7684, 'grad_norm': 1.3241475820541382, 'learning_rate': 1.5319021082338458e-05, 'epoch': 1.0312345066931086}
2025-04-25 00:30:47,695 - INFO - Training metrics: {'loss': 0.7684, 'grad_norm': 1.3241475820541382, 'learning_rate': 1.5319021082338458e-05, 'epoch': 1.0312345066931086}
2025-04-25 00:33:47,150 - INFO - INFO: Training progress: {'loss': 0.7693, 'grad_norm': 0.9132463932037354, 'learning_rate': 1.522773364663173e-05, 'epoch': 1.0411502231036192}
2025-04-25 00:33:47,150 - INFO - Training progress: {'loss': 0.7693, 'grad_norm': 0.9132463932037354, 'learning_rate': 1.522773364663173e-05, 'epoch': 1.0411502231036192}
2025-04-25 00:33:47,150 - INFO - Training metrics: {'loss': 0.7693, 'grad_norm': 0.9132463932037354, 'learning_rate': 1.522773364663173e-05, 'epoch': 1.0411502231036192}
2025-04-25 00:51:01,684 - INFO - INFO: Training progress: {'eval_loss': 0.7960623502731323, 'eval_runtime': 1034.53, 'eval_samples_per_second': 1.802, 'eval_steps_per_second': 1.802, 'epoch': 1.0411502231036192}
2025-04-25 00:51:01,684 - INFO - Training progress: {'eval_loss': 0.7960623502731323, 'eval_runtime': 1034.53, 'eval_samples_per_second': 1.802, 'eval_steps_per_second': 1.802, 'epoch': 1.0411502231036192}
2025-04-25 00:51:01,684 - INFO - Training metrics: {'eval_loss': 0.7960623502731323, 'eval_runtime': 1034.53, 'eval_samples_per_second': 1.802, 'eval_steps_per_second': 1.802, 'epoch': 1.0411502231036192}
2025-04-25 00:54:03,368 - INFO - INFO: Training progress: {'loss': 0.8109, 'grad_norm': 2.0527560710906982, 'learning_rate': 1.5135842742873077e-05, 'epoch': 1.05106593951413}
2025-04-25 00:54:03,368 - INFO - Training progress: {'loss': 0.8109, 'grad_norm': 2.0527560710906982, 'learning_rate': 1.5135842742873077e-05, 'epoch': 1.05106593951413}
2025-04-25 00:54:03,368 - INFO - Training metrics: {'loss': 0.8109, 'grad_norm': 2.0527560710906982, 'learning_rate': 1.5135842742873077e-05, 'epoch': 1.05106593951413}
2025-04-25 00:57:03,505 - INFO - INFO: Training progress: {'loss': 0.7171, 'grad_norm': 1.2748340368270874, 'learning_rate': 1.5043358978570158e-05, 'epoch': 1.0609816559246406}
2025-04-25 00:57:03,505 - INFO - Training progress: {'loss': 0.7171, 'grad_norm': 1.2748340368270874, 'learning_rate': 1.5043358978570158e-05, 'epoch': 1.0609816559246406}
2025-04-25 00:57:03,505 - INFO - Training metrics: {'loss': 0.7171, 'grad_norm': 1.2748340368270874, 'learning_rate': 1.5043358978570158e-05, 'epoch': 1.0609816559246406}
2025-04-25 01:00:03,992 - INFO - INFO: Training progress: {'loss': 0.8356, 'grad_norm': 2.2311315536499023, 'learning_rate': 1.4950293029668004e-05, 'epoch': 1.0708973723351511}
2025-04-25 01:00:03,992 - INFO - Training progress: {'loss': 0.8356, 'grad_norm': 2.2311315536499023, 'learning_rate': 1.4950293029668004e-05, 'epoch': 1.0708973723351511}
2025-04-25 01:00:03,992 - INFO - Training metrics: {'loss': 0.8356, 'grad_norm': 2.2311315536499023, 'learning_rate': 1.4950293029668004e-05, 'epoch': 1.0708973723351511}
2025-04-25 01:03:03,567 - INFO - INFO: Training progress: {'loss': 0.7562, 'grad_norm': 1.3515465259552002, 'learning_rate': 1.485665563931665e-05, 'epoch': 1.080813088745662}
2025-04-25 01:03:03,567 - INFO - Training progress: {'loss': 0.7562, 'grad_norm': 1.3515465259552002, 'learning_rate': 1.485665563931665e-05, 'epoch': 1.080813088745662}
2025-04-25 01:03:03,567 - INFO - Training metrics: {'loss': 0.7562, 'grad_norm': 1.3515465259552002, 'learning_rate': 1.485665563931665e-05, 'epoch': 1.080813088745662}
2025-04-25 01:06:02,735 - INFO - INFO: Training progress: {'loss': 0.7397, 'grad_norm': 2.0458481311798096, 'learning_rate': 1.4762457616630972e-05, 'epoch': 1.0907288051561725}
2025-04-25 01:06:02,736 - INFO - Training progress: {'loss': 0.7397, 'grad_norm': 2.0458481311798096, 'learning_rate': 1.4762457616630972e-05, 'epoch': 1.0907288051561725}
2025-04-25 01:06:02,736 - INFO - Training metrics: {'loss': 0.7397, 'grad_norm': 2.0458481311798096, 'learning_rate': 1.4762457616630972e-05, 'epoch': 1.0907288051561725}
2025-04-25 01:09:01,867 - INFO - INFO: Training progress: {'loss': 0.7771, 'grad_norm': 2.3746848106384277, 'learning_rate': 1.4667709835442944e-05, 'epoch': 1.1006445215666831}
2025-04-25 01:09:01,868 - INFO - Training progress: {'loss': 0.7771, 'grad_norm': 2.3746848106384277, 'learning_rate': 1.4667709835442944e-05, 'epoch': 1.1006445215666831}
2025-04-25 01:09:01,868 - INFO - Training metrics: {'loss': 0.7771, 'grad_norm': 2.3746848106384277, 'learning_rate': 1.4667709835442944e-05, 'epoch': 1.1006445215666831}
2025-04-25 01:11:59,698 - INFO - INFO: Training progress: {'loss': 0.8022, 'grad_norm': 1.5220589637756348, 'learning_rate': 1.4572423233046386e-05, 'epoch': 1.110560237977194}
2025-04-25 01:11:59,699 - INFO - Training progress: {'loss': 0.8022, 'grad_norm': 1.5220589637756348, 'learning_rate': 1.4572423233046386e-05, 'epoch': 1.110560237977194}
2025-04-25 01:11:59,699 - INFO - Training metrics: {'loss': 0.8022, 'grad_norm': 1.5220589637756348, 'learning_rate': 1.4572423233046386e-05, 'epoch': 1.110560237977194}
2025-04-25 01:15:04,613 - INFO - INFO: Training progress: {'loss': 0.7185, 'grad_norm': 1.7809767723083496, 'learning_rate': 1.447660880893443e-05, 'epoch': 1.1204759543877045}
2025-04-25 01:15:04,613 - INFO - Training progress: {'loss': 0.7185, 'grad_norm': 1.7809767723083496, 'learning_rate': 1.447660880893443e-05, 'epoch': 1.1204759543877045}
2025-04-25 01:15:04,613 - INFO - Training metrics: {'loss': 0.7185, 'grad_norm': 1.7809767723083496, 'learning_rate': 1.447660880893443e-05, 'epoch': 1.1204759543877045}
2025-04-25 01:18:12,219 - INFO - INFO: Training progress: {'loss': 0.7326, 'grad_norm': 1.9977136850357056, 'learning_rate': 1.4380277623529766e-05, 'epoch': 1.1303916707982151}
2025-04-25 01:18:12,219 - INFO - Training progress: {'loss': 0.7326, 'grad_norm': 1.9977136850357056, 'learning_rate': 1.4380277623529766e-05, 'epoch': 1.1303916707982151}
2025-04-25 01:18:12,219 - INFO - Training metrics: {'loss': 0.7326, 'grad_norm': 1.9977136850357056, 'learning_rate': 1.4380277623529766e-05, 'epoch': 1.1303916707982151}
2025-04-25 01:21:20,340 - INFO - INFO: Training progress: {'loss': 0.6749, 'grad_norm': 2.2159996032714844, 'learning_rate': 1.4283440796907888e-05, 'epoch': 1.140307387208726}
2025-04-25 01:21:20,340 - INFO - Training progress: {'loss': 0.6749, 'grad_norm': 2.2159996032714844, 'learning_rate': 1.4283440796907888e-05, 'epoch': 1.140307387208726}
2025-04-25 01:21:20,340 - INFO - Training metrics: {'loss': 0.6749, 'grad_norm': 2.2159996032714844, 'learning_rate': 1.4283440796907888e-05, 'epoch': 1.140307387208726}
2025-04-25 01:24:29,166 - INFO - INFO: Training progress: {'loss': 0.7687, 'grad_norm': 1.6832786798477173, 'learning_rate': 1.4186109507513425e-05, 'epoch': 1.1502231036192365}
2025-04-25 01:24:29,166 - INFO - Training progress: {'loss': 0.7687, 'grad_norm': 1.6832786798477173, 'learning_rate': 1.4186109507513425e-05, 'epoch': 1.1502231036192365}
2025-04-25 01:24:29,166 - INFO - Training metrics: {'loss': 0.7687, 'grad_norm': 1.6832786798477173, 'learning_rate': 1.4186109507513425e-05, 'epoch': 1.1502231036192365}
2025-04-25 01:27:36,935 - INFO - INFO: Training progress: {'loss': 0.7059, 'grad_norm': 1.5843677520751953, 'learning_rate': 1.4088294990869757e-05, 'epoch': 1.160138820029747}
2025-04-25 01:27:36,935 - INFO - Training progress: {'loss': 0.7059, 'grad_norm': 1.5843677520751953, 'learning_rate': 1.4088294990869757e-05, 'epoch': 1.160138820029747}
2025-04-25 01:27:36,935 - INFO - Training metrics: {'loss': 0.7059, 'grad_norm': 1.5843677520751953, 'learning_rate': 1.4088294990869757e-05, 'epoch': 1.160138820029747}
2025-04-25 01:30:48,909 - INFO - INFO: Training progress: {'loss': 0.75, 'grad_norm': 1.40496027469635, 'learning_rate': 1.3990008538282027e-05, 'epoch': 1.170054536440258}
2025-04-25 01:30:48,909 - INFO - Training progress: {'loss': 0.75, 'grad_norm': 1.40496027469635, 'learning_rate': 1.3990008538282027e-05, 'epoch': 1.170054536440258}
2025-04-25 01:30:48,909 - INFO - Training metrics: {'loss': 0.75, 'grad_norm': 1.40496027469635, 'learning_rate': 1.3990008538282027e-05, 'epoch': 1.170054536440258}
2025-04-25 01:33:56,879 - INFO - INFO: Training progress: {'loss': 0.6839, 'grad_norm': 2.0949838161468506, 'learning_rate': 1.389126149553372e-05, 'epoch': 1.1799702528507685}
2025-04-25 01:33:56,879 - INFO - Training progress: {'loss': 0.6839, 'grad_norm': 2.0949838161468506, 'learning_rate': 1.389126149553372e-05, 'epoch': 1.1799702528507685}
2025-04-25 01:33:56,879 - INFO - Training metrics: {'loss': 0.6839, 'grad_norm': 2.0949838161468506, 'learning_rate': 1.389126149553372e-05, 'epoch': 1.1799702528507685}
2025-04-25 01:36:59,230 - INFO - INFO: Training progress: {'loss': 0.6563, 'grad_norm': 2.3194220066070557, 'learning_rate': 1.3792065261576953e-05, 'epoch': 1.189885969261279}
2025-04-25 01:36:59,230 - INFO - Training progress: {'loss': 0.6563, 'grad_norm': 2.3194220066070557, 'learning_rate': 1.3792065261576953e-05, 'epoch': 1.189885969261279}
2025-04-25 01:36:59,230 - INFO - Training metrics: {'loss': 0.6563, 'grad_norm': 2.3194220066070557, 'learning_rate': 1.3792065261576953e-05, 'epoch': 1.189885969261279}
2025-04-25 01:37:00,055 - INFO - INFO: Saving checkpoint at step 1200
2025-04-25 01:37:00,057 - INFO - Saving checkpoint at step 1200
2025-04-25 01:37:00,057 - INFO - Saving checkpoint at step 1200
2025-04-25 01:40:00,421 - INFO - INFO: Training progress: {'loss': 0.6237, 'grad_norm': 2.2621047496795654, 'learning_rate': 1.3692431287216627e-05, 'epoch': 1.19980168567179}
2025-04-25 01:40:00,422 - INFO - Training progress: {'loss': 0.6237, 'grad_norm': 2.2621047496795654, 'learning_rate': 1.3692431287216627e-05, 'epoch': 1.19980168567179}
2025-04-25 01:40:00,422 - INFO - Training metrics: {'loss': 0.6237, 'grad_norm': 2.2621047496795654, 'learning_rate': 1.3692431287216627e-05, 'epoch': 1.19980168567179}
2025-04-25 01:43:00,796 - INFO - INFO: Training progress: {'loss': 0.735, 'grad_norm': 1.5168211460113525, 'learning_rate': 1.3592371073788595e-05, 'epoch': 1.2097174020823005}
2025-04-25 01:43:00,796 - INFO - Training progress: {'loss': 0.735, 'grad_norm': 1.5168211460113525, 'learning_rate': 1.3592371073788595e-05, 'epoch': 1.2097174020823005}
2025-04-25 01:43:00,796 - INFO - Training metrics: {'loss': 0.735, 'grad_norm': 1.5168211460113525, 'learning_rate': 1.3592371073788595e-05, 'epoch': 1.2097174020823005}
2025-04-25 01:46:02,759 - INFO - INFO: Training progress: {'loss': 0.8552, 'grad_norm': 2.8933348655700684, 'learning_rate': 1.3491896171831991e-05, 'epoch': 1.219633118492811}
2025-04-25 01:46:02,759 - INFO - Training progress: {'loss': 0.8552, 'grad_norm': 2.8933348655700684, 'learning_rate': 1.3491896171831991e-05, 'epoch': 1.219633118492811}
2025-04-25 01:46:02,759 - INFO - Training metrics: {'loss': 0.8552, 'grad_norm': 2.8933348655700684, 'learning_rate': 1.3491896171831991e-05, 'epoch': 1.219633118492811}
2025-04-25 01:49:03,294 - INFO - INFO: Training progress: {'loss': 0.8582, 'grad_norm': 1.860325574874878, 'learning_rate': 1.3391018179755886e-05, 'epoch': 1.2295488349033217}
2025-04-25 01:49:03,294 - INFO - Training progress: {'loss': 0.8582, 'grad_norm': 1.860325574874878, 'learning_rate': 1.3391018179755886e-05, 'epoch': 1.2295488349033217}
2025-04-25 01:49:03,294 - INFO - Training metrics: {'loss': 0.8582, 'grad_norm': 1.860325574874878, 'learning_rate': 1.3391018179755886e-05, 'epoch': 1.2295488349033217}
2025-04-25 01:52:03,555 - INFO - INFO: Training progress: {'loss': 0.7281, 'grad_norm': 3.006370782852173, 'learning_rate': 1.3289748742500415e-05, 'epoch': 1.2394645513138325}
2025-04-25 01:52:03,556 - INFO - Training progress: {'loss': 0.7281, 'grad_norm': 3.006370782852173, 'learning_rate': 1.3289748742500415e-05, 'epoch': 1.2394645513138325}
2025-04-25 01:52:03,556 - INFO - Training metrics: {'loss': 0.7281, 'grad_norm': 3.006370782852173, 'learning_rate': 1.3289748742500415e-05, 'epoch': 1.2394645513138325}
2025-04-25 01:55:04,227 - INFO - INFO: Training progress: {'loss': 0.6765, 'grad_norm': 3.132450819015503, 'learning_rate': 1.3188099550192537e-05, 'epoch': 1.249380267724343}
2025-04-25 01:55:04,227 - INFO - Training progress: {'loss': 0.6765, 'grad_norm': 3.132450819015503, 'learning_rate': 1.3188099550192537e-05, 'epoch': 1.249380267724343}
2025-04-25 01:55:04,227 - INFO - Training metrics: {'loss': 0.6765, 'grad_norm': 3.132450819015503, 'learning_rate': 1.3188099550192537e-05, 'epoch': 1.249380267724343}
2025-04-25 01:58:05,741 - INFO - INFO: Training progress: {'loss': 0.7136, 'grad_norm': 2.5282413959503174, 'learning_rate': 1.3086082336796567e-05, 'epoch': 1.2592959841348537}
2025-04-25 01:58:05,741 - INFO - Training progress: {'loss': 0.7136, 'grad_norm': 2.5282413959503174, 'learning_rate': 1.3086082336796567e-05, 'epoch': 1.2592959841348537}
2025-04-25 01:58:05,741 - INFO - Training metrics: {'loss': 0.7136, 'grad_norm': 2.5282413959503174, 'learning_rate': 1.3086082336796567e-05, 'epoch': 1.2592959841348537}
2025-04-25 02:01:06,991 - INFO - INFO: Training progress: {'loss': 0.7137, 'grad_norm': 1.3216955661773682, 'learning_rate': 1.2983708878759655e-05, 'epoch': 1.2692117005453645}
2025-04-25 02:01:06,991 - INFO - Training progress: {'loss': 0.7137, 'grad_norm': 1.3216955661773682, 'learning_rate': 1.2983708878759655e-05, 'epoch': 1.2692117005453645}
2025-04-25 02:01:06,992 - INFO - Training metrics: {'loss': 0.7137, 'grad_norm': 1.3216955661773682, 'learning_rate': 1.2983708878759655e-05, 'epoch': 1.2692117005453645}
2025-04-25 02:04:08,580 - INFO - INFO: Training progress: {'loss': 0.7087, 'grad_norm': 1.3756011724472046, 'learning_rate': 1.2880990993652379e-05, 'epoch': 1.279127416955875}
2025-04-25 02:04:08,580 - INFO - Training progress: {'loss': 0.7087, 'grad_norm': 1.3756011724472046, 'learning_rate': 1.2880990993652379e-05, 'epoch': 1.279127416955875}
2025-04-25 02:04:08,580 - INFO - Training metrics: {'loss': 0.7087, 'grad_norm': 1.3756011724472046, 'learning_rate': 1.2880990993652379e-05, 'epoch': 1.279127416955875}
2025-04-25 02:07:11,751 - INFO - INFO: Training progress: {'loss': 0.8002, 'grad_norm': 1.5213866233825684, 'learning_rate': 1.2777940538804545e-05, 'epoch': 1.2890431333663857}
2025-04-25 02:07:11,751 - INFO - Training progress: {'loss': 0.8002, 'grad_norm': 1.5213866233825684, 'learning_rate': 1.2777940538804545e-05, 'epoch': 1.2890431333663857}
2025-04-25 02:07:11,751 - INFO - Training metrics: {'loss': 0.8002, 'grad_norm': 1.5213866233825684, 'learning_rate': 1.2777940538804545e-05, 'epoch': 1.2890431333663857}
2025-04-25 02:10:15,218 - INFO - INFO: Training progress: {'loss': 0.6912, 'grad_norm': 3.510777473449707, 'learning_rate': 1.2674569409936453e-05, 'epoch': 1.2989588497768965}
2025-04-25 02:10:15,218 - INFO - Training progress: {'loss': 0.6912, 'grad_norm': 3.510777473449707, 'learning_rate': 1.2674569409936453e-05, 'epoch': 1.2989588497768965}
2025-04-25 02:10:15,218 - INFO - Training metrics: {'loss': 0.6912, 'grad_norm': 3.510777473449707, 'learning_rate': 1.2674569409936453e-05, 'epoch': 1.2989588497768965}
2025-04-25 02:13:17,951 - INFO - INFO: Training progress: {'loss': 0.8263, 'grad_norm': 2.142967462539673, 'learning_rate': 1.2570889539785683e-05, 'epoch': 1.308874566187407}
2025-04-25 02:13:17,951 - INFO - Training progress: {'loss': 0.8263, 'grad_norm': 2.142967462539673, 'learning_rate': 1.2570889539785683e-05, 'epoch': 1.308874566187407}
2025-04-25 02:13:17,951 - INFO - Training metrics: {'loss': 0.8263, 'grad_norm': 2.142967462539673, 'learning_rate': 1.2570889539785683e-05, 'epoch': 1.308874566187407}
2025-04-25 02:16:26,455 - INFO - INFO: Training progress: {'loss': 0.7051, 'grad_norm': 2.0934267044067383, 'learning_rate': 1.2466912896729646e-05, 'epoch': 1.3187902825979176}
2025-04-25 02:16:26,455 - INFO - Training progress: {'loss': 0.7051, 'grad_norm': 2.0934267044067383, 'learning_rate': 1.2466912896729646e-05, 'epoch': 1.3187902825979176}
2025-04-25 02:16:26,456 - INFO - Training metrics: {'loss': 0.7051, 'grad_norm': 2.0934267044067383, 'learning_rate': 1.2466912896729646e-05, 'epoch': 1.3187902825979176}
2025-04-25 02:19:28,534 - INFO - INFO: Training progress: {'loss': 0.7127, 'grad_norm': 1.7312062978744507, 'learning_rate': 1.2362651483403985e-05, 'epoch': 1.3287059990084282}
2025-04-25 02:19:28,535 - INFO - Training progress: {'loss': 0.7127, 'grad_norm': 1.7312062978744507, 'learning_rate': 1.2362651483403985e-05, 'epoch': 1.3287059990084282}
2025-04-25 02:19:28,535 - INFO - Training metrics: {'loss': 0.7127, 'grad_norm': 1.7312062978744507, 'learning_rate': 1.2362651483403985e-05, 'epoch': 1.3287059990084282}
2025-04-25 02:22:39,228 - INFO - INFO: Training progress: {'loss': 0.7407, 'grad_norm': 2.8890295028686523, 'learning_rate': 1.225811733531706e-05, 'epoch': 1.338621715418939}
2025-04-25 02:22:39,229 - INFO - Training progress: {'loss': 0.7407, 'grad_norm': 2.8890295028686523, 'learning_rate': 1.225811733531706e-05, 'epoch': 1.338621715418939}
2025-04-25 02:22:39,229 - INFO - Training metrics: {'loss': 0.7407, 'grad_norm': 2.8890295028686523, 'learning_rate': 1.225811733531706e-05, 'epoch': 1.338621715418939}
2025-04-25 02:25:45,125 - INFO - INFO: Training progress: {'loss': 0.7192, 'grad_norm': 2.1877405643463135, 'learning_rate': 1.215332251946061e-05, 'epoch': 1.3485374318294496}
2025-04-25 02:25:45,125 - INFO - Training progress: {'loss': 0.7192, 'grad_norm': 2.1877405643463135, 'learning_rate': 1.215332251946061e-05, 'epoch': 1.3485374318294496}
2025-04-25 02:25:45,125 - INFO - Training metrics: {'loss': 0.7192, 'grad_norm': 2.1877405643463135, 'learning_rate': 1.215332251946061e-05, 'epoch': 1.3485374318294496}
2025-04-25 02:28:50,252 - INFO - INFO: Training progress: {'loss': 0.8511, 'grad_norm': 2.4557948112487793, 'learning_rate': 1.2048279132916778e-05, 'epoch': 1.3584531482399602}
2025-04-25 02:28:50,252 - INFO - Training progress: {'loss': 0.8511, 'grad_norm': 2.4557948112487793, 'learning_rate': 1.2048279132916778e-05, 'epoch': 1.3584531482399602}
2025-04-25 02:28:50,252 - INFO - Training metrics: {'loss': 0.8511, 'grad_norm': 2.4557948112487793, 'learning_rate': 1.2048279132916778e-05, 'epoch': 1.3584531482399602}
2025-04-25 02:32:00,380 - INFO - INFO: Training progress: {'loss': 0.7553, 'grad_norm': 2.303438186645508, 'learning_rate': 1.1942999301461694e-05, 'epoch': 1.368368864650471}
2025-04-25 02:32:00,381 - INFO - Training progress: {'loss': 0.7553, 'grad_norm': 2.303438186645508, 'learning_rate': 1.1942999301461694e-05, 'epoch': 1.368368864650471}
2025-04-25 02:32:00,381 - INFO - Training metrics: {'loss': 0.7553, 'grad_norm': 2.303438186645508, 'learning_rate': 1.1942999301461694e-05, 'epoch': 1.368368864650471}
2025-04-25 02:35:02,560 - INFO - INFO: Training progress: {'loss': 0.7213, 'grad_norm': 2.344717502593994, 'learning_rate': 1.1837495178165706e-05, 'epoch': 1.3782845810609816}
2025-04-25 02:35:02,560 - INFO - Training progress: {'loss': 0.7213, 'grad_norm': 2.344717502593994, 'learning_rate': 1.1837495178165706e-05, 'epoch': 1.3782845810609816}
2025-04-25 02:35:02,560 - INFO - Training metrics: {'loss': 0.7213, 'grad_norm': 2.344717502593994, 'learning_rate': 1.1837495178165706e-05, 'epoch': 1.3782845810609816}
2025-04-25 02:38:01,434 - INFO - INFO: Training progress: {'loss': 0.778, 'grad_norm': 2.1621406078338623, 'learning_rate': 1.1731778941990497e-05, 'epoch': 1.3882002974714922}
2025-04-25 02:38:01,434 - INFO - Training progress: {'loss': 0.778, 'grad_norm': 2.1621406078338623, 'learning_rate': 1.1731778941990497e-05, 'epoch': 1.3882002974714922}
2025-04-25 02:38:01,434 - INFO - Training metrics: {'loss': 0.778, 'grad_norm': 2.1621406078338623, 'learning_rate': 1.1731778941990497e-05, 'epoch': 1.3882002974714922}
2025-04-25 02:55:15,444 - INFO - INFO: Training progress: {'eval_loss': 0.7730103731155396, 'eval_runtime': 1034.0051, 'eval_samples_per_second': 1.803, 'eval_steps_per_second': 1.803, 'epoch': 1.3882002974714922}
2025-04-25 02:55:15,444 - INFO - Training progress: {'eval_loss': 0.7730103731155396, 'eval_runtime': 1034.0051, 'eval_samples_per_second': 1.803, 'eval_steps_per_second': 1.803, 'epoch': 1.3882002974714922}
2025-04-25 02:55:15,444 - INFO - Training metrics: {'eval_loss': 0.7730103731155396, 'eval_runtime': 1034.0051, 'eval_samples_per_second': 1.803, 'eval_steps_per_second': 1.803, 'epoch': 1.3882002974714922}
2025-04-25 02:55:16,225 - INFO - INFO: Saving checkpoint at step 1400
2025-04-25 02:55:16,226 - INFO - Saving checkpoint at step 1400
2025-04-25 02:55:16,226 - INFO - Saving checkpoint at step 1400
2025-04-25 02:58:15,338 - INFO - INFO: Training progress: {'loss': 0.7161, 'grad_norm': 2.197488784790039, 'learning_rate': 1.1625862796383187e-05, 'epoch': 1.398116013882003}
2025-04-25 02:58:15,338 - INFO - Training progress: {'loss': 0.7161, 'grad_norm': 2.197488784790039, 'learning_rate': 1.1625862796383187e-05, 'epoch': 1.398116013882003}
2025-04-25 02:58:15,338 - INFO - Training metrics: {'loss': 0.7161, 'grad_norm': 2.197488784790039, 'learning_rate': 1.1625862796383187e-05, 'epoch': 1.398116013882003}
2025-04-25 03:01:16,422 - INFO - INFO: Training progress: {'loss': 0.8298, 'grad_norm': 3.2282447814941406, 'learning_rate': 1.1519758967867608e-05, 'epoch': 1.4080317302925136}
2025-04-25 03:01:16,422 - INFO - Training progress: {'loss': 0.8298, 'grad_norm': 3.2282447814941406, 'learning_rate': 1.1519758967867608e-05, 'epoch': 1.4080317302925136}
2025-04-25 03:01:16,422 - INFO - Training metrics: {'loss': 0.8298, 'grad_norm': 3.2282447814941406, 'learning_rate': 1.1519758967867608e-05, 'epoch': 1.4080317302925136}
2025-04-25 03:04:17,581 - INFO - INFO: Training progress: {'loss': 0.8759, 'grad_norm': 1.360072374343872, 'learning_rate': 1.141347970463295e-05, 'epoch': 1.4179474467030242}
2025-04-25 03:04:17,581 - INFO - Training progress: {'loss': 0.8759, 'grad_norm': 1.360072374343872, 'learning_rate': 1.141347970463295e-05, 'epoch': 1.4179474467030242}
2025-04-25 03:04:17,581 - INFO - Training metrics: {'loss': 0.8759, 'grad_norm': 1.360072374343872, 'learning_rate': 1.141347970463295e-05, 'epoch': 1.4179474467030242}
2025-04-25 03:07:19,858 - INFO - INFO: Training progress: {'loss': 0.7093, 'grad_norm': 1.4488444328308105, 'learning_rate': 1.1307037275119854e-05, 'epoch': 1.427863163113535}
2025-04-25 03:07:19,859 - INFO - Training progress: {'loss': 0.7093, 'grad_norm': 1.4488444328308105, 'learning_rate': 1.1307037275119854e-05, 'epoch': 1.427863163113535}
2025-04-25 03:07:19,859 - INFO - Training metrics: {'loss': 0.7093, 'grad_norm': 1.4488444328308105, 'learning_rate': 1.1307037275119854e-05, 'epoch': 1.427863163113535}
2025-04-25 03:10:20,296 - INFO - INFO: Training progress: {'loss': 0.6789, 'grad_norm': 1.6170790195465088, 'learning_rate': 1.1200443966604207e-05, 'epoch': 1.4377788795240456}
2025-04-25 03:10:20,296 - INFO - Training progress: {'loss': 0.6789, 'grad_norm': 1.6170790195465088, 'learning_rate': 1.1200443966604207e-05, 'epoch': 1.4377788795240456}
2025-04-25 03:10:20,296 - INFO - Training metrics: {'loss': 0.6789, 'grad_norm': 1.6170790195465088, 'learning_rate': 1.1200443966604207e-05, 'epoch': 1.4377788795240456}
2025-04-25 03:13:19,256 - INFO - INFO: Training progress: {'loss': 0.614, 'grad_norm': 0.7290269732475281, 'learning_rate': 1.1093712083778748e-05, 'epoch': 1.4476945959345562}
2025-04-25 03:13:19,257 - INFO - Training progress: {'loss': 0.614, 'grad_norm': 0.7290269732475281, 'learning_rate': 1.1093712083778748e-05, 'epoch': 1.4476945959345562}
2025-04-25 03:13:19,257 - INFO - Training metrics: {'loss': 0.614, 'grad_norm': 0.7290269732475281, 'learning_rate': 1.1093712083778748e-05, 'epoch': 1.4476945959345562}
2025-04-25 03:16:24,437 - INFO - INFO: Training progress: {'loss': 0.7858, 'grad_norm': 2.265855312347412, 'learning_rate': 1.0986853947332656e-05, 'epoch': 1.457610312345067}
2025-04-25 03:16:24,438 - INFO - Training progress: {'loss': 0.7858, 'grad_norm': 2.265855312347412, 'learning_rate': 1.0986853947332656e-05, 'epoch': 1.457610312345067}
2025-04-25 03:16:24,438 - INFO - Training metrics: {'loss': 0.7858, 'grad_norm': 2.265855312347412, 'learning_rate': 1.0986853947332656e-05, 'epoch': 1.457610312345067}
2025-04-25 03:19:30,809 - INFO - INFO: Training progress: {'loss': 0.7709, 'grad_norm': 2.333564043045044, 'learning_rate': 1.0879881892529325e-05, 'epoch': 1.4675260287555776}
2025-04-25 03:19:30,811 - INFO - Training progress: {'loss': 0.7709, 'grad_norm': 2.333564043045044, 'learning_rate': 1.0879881892529325e-05, 'epoch': 1.4675260287555776}
2025-04-25 03:19:30,811 - INFO - Training metrics: {'loss': 0.7709, 'grad_norm': 2.333564043045044, 'learning_rate': 1.0879881892529325e-05, 'epoch': 1.4675260287555776}
2025-04-25 03:22:37,157 - INFO - INFO: Training progress: {'loss': 0.8726, 'grad_norm': 1.9519340991973877, 'learning_rate': 1.0772808267782397e-05, 'epoch': 1.4774417451660882}
2025-04-25 03:22:37,158 - INFO - Training progress: {'loss': 0.8726, 'grad_norm': 1.9519340991973877, 'learning_rate': 1.0772808267782397e-05, 'epoch': 1.4774417451660882}
2025-04-25 03:22:37,158 - INFO - Training metrics: {'loss': 0.8726, 'grad_norm': 1.9519340991973877, 'learning_rate': 1.0772808267782397e-05, 'epoch': 1.4774417451660882}
2025-04-25 03:25:48,075 - INFO - INFO: Training progress: {'loss': 0.7335, 'grad_norm': 2.221713066101074, 'learning_rate': 1.0665645433230345e-05, 'epoch': 1.487357461576599}
2025-04-25 03:25:48,075 - INFO - Training progress: {'loss': 0.7335, 'grad_norm': 2.221713066101074, 'learning_rate': 1.0665645433230345e-05, 'epoch': 1.487357461576599}
2025-04-25 03:25:48,075 - INFO - Training metrics: {'loss': 0.7335, 'grad_norm': 2.221713066101074, 'learning_rate': 1.0665645433230345e-05, 'epoch': 1.487357461576599}
2025-04-25 03:28:56,508 - INFO - INFO: Training progress: {'loss': 0.7271, 'grad_norm': 2.0856401920318604, 'learning_rate': 1.0558405759309647e-05, 'epoch': 1.4972731779871096}
2025-04-25 03:28:56,508 - INFO - Training progress: {'loss': 0.7271, 'grad_norm': 2.0856401920318604, 'learning_rate': 1.0558405759309647e-05, 'epoch': 1.4972731779871096}
2025-04-25 03:28:56,508 - INFO - Training metrics: {'loss': 0.7271, 'grad_norm': 2.0856401920318604, 'learning_rate': 1.0558405759309647e-05, 'epoch': 1.4972731779871096}
2025-04-25 03:32:03,166 - INFO - INFO: Training progress: {'loss': 0.707, 'grad_norm': 1.6590913534164429, 'learning_rate': 1.0451101625326798e-05, 'epoch': 1.5071888943976202}
2025-04-25 03:32:03,167 - INFO - Training progress: {'loss': 0.707, 'grad_norm': 1.6590913534164429, 'learning_rate': 1.0451101625326798e-05, 'epoch': 1.5071888943976202}
2025-04-25 03:32:03,167 - INFO - Training metrics: {'loss': 0.707, 'grad_norm': 1.6590913534164429, 'learning_rate': 1.0451101625326798e-05, 'epoch': 1.5071888943976202}
2025-04-25 03:35:08,493 - INFO - INFO: Training progress: {'loss': 0.747, 'grad_norm': 2.110210657119751, 'learning_rate': 1.034374541802931e-05, 'epoch': 1.517104610808131}
2025-04-25 03:35:08,493 - INFO - Training progress: {'loss': 0.747, 'grad_norm': 2.110210657119751, 'learning_rate': 1.034374541802931e-05, 'epoch': 1.517104610808131}
2025-04-25 03:35:08,493 - INFO - Training metrics: {'loss': 0.747, 'grad_norm': 2.110210657119751, 'learning_rate': 1.034374541802931e-05, 'epoch': 1.517104610808131}
2025-04-25 03:38:10,470 - INFO - INFO: Training progress: {'loss': 0.8342, 'grad_norm': 2.23976993560791, 'learning_rate': 1.0236349530175807e-05, 'epoch': 1.5270203272186416}
2025-04-25 03:38:10,471 - INFO - Training progress: {'loss': 0.8342, 'grad_norm': 2.23976993560791, 'learning_rate': 1.0236349530175807e-05, 'epoch': 1.5270203272186416}
2025-04-25 03:38:10,471 - INFO - Training metrics: {'loss': 0.8342, 'grad_norm': 2.23976993560791, 'learning_rate': 1.0236349530175807e-05, 'epoch': 1.5270203272186416}
2025-04-25 03:41:08,641 - INFO - INFO: Training progress: {'loss': 0.7373, 'grad_norm': 1.8467779159545898, 'learning_rate': 1.0128926359105486e-05, 'epoch': 1.5369360436291521}
2025-04-25 03:41:08,641 - INFO - Training progress: {'loss': 0.7373, 'grad_norm': 1.8467779159545898, 'learning_rate': 1.0128926359105486e-05, 'epoch': 1.5369360436291521}
2025-04-25 03:41:08,641 - INFO - Training metrics: {'loss': 0.7373, 'grad_norm': 1.8467779159545898, 'learning_rate': 1.0128926359105486e-05, 'epoch': 1.5369360436291521}
2025-04-25 03:44:06,429 - INFO - INFO: Training progress: {'loss': 0.7637, 'grad_norm': 2.5649914741516113, 'learning_rate': 1.0021488305307003e-05, 'epoch': 1.546851760039663}
2025-04-25 03:44:06,430 - INFO - Training progress: {'loss': 0.7637, 'grad_norm': 2.5649914741516113, 'learning_rate': 1.0021488305307003e-05, 'epoch': 1.546851760039663}
2025-04-25 03:44:06,430 - INFO - Training metrics: {'loss': 0.7637, 'grad_norm': 2.5649914741516113, 'learning_rate': 1.0021488305307003e-05, 'epoch': 1.546851760039663}
2025-04-25 03:47:04,106 - INFO - INFO: Training progress: {'loss': 0.6954, 'grad_norm': 0.8108167052268982, 'learning_rate': 9.914047770987012e-06, 'epoch': 1.5567674764501735}
2025-04-25 03:47:04,106 - INFO - Training progress: {'loss': 0.6954, 'grad_norm': 0.8108167052268982, 'learning_rate': 9.914047770987012e-06, 'epoch': 1.5567674764501735}
2025-04-25 03:47:04,106 - INFO - Training metrics: {'loss': 0.6954, 'grad_norm': 0.8108167052268982, 'learning_rate': 9.914047770987012e-06, 'epoch': 1.5567674764501735}
2025-04-25 03:50:01,648 - INFO - INFO: Training progress: {'loss': 0.7724, 'grad_norm': 2.1617751121520996, 'learning_rate': 9.806617158638515e-06, 'epoch': 1.5666831928606841}
2025-04-25 03:50:01,648 - INFO - Training progress: {'loss': 0.7724, 'grad_norm': 2.1617751121520996, 'learning_rate': 9.806617158638515e-06, 'epoch': 1.5666831928606841}
2025-04-25 03:50:01,648 - INFO - Training metrics: {'loss': 0.7724, 'grad_norm': 2.1617751121520996, 'learning_rate': 9.806617158638515e-06, 'epoch': 1.5666831928606841}
2025-04-25 03:52:59,520 - INFO - INFO: Training progress: {'loss': 0.7377, 'grad_norm': 3.0473501682281494, 'learning_rate': 9.69920886960915e-06, 'epoch': 1.576598909271195}
2025-04-25 03:52:59,520 - INFO - Training progress: {'loss': 0.7377, 'grad_norm': 3.0473501682281494, 'learning_rate': 9.69920886960915e-06, 'epoch': 1.576598909271195}
2025-04-25 03:52:59,520 - INFO - Training metrics: {'loss': 0.7377, 'grad_norm': 3.0473501682281494, 'learning_rate': 9.69920886960915e-06, 'epoch': 1.576598909271195}
2025-04-25 03:55:57,355 - INFO - INFO: Training progress: {'loss': 0.7171, 'grad_norm': 2.147319793701172, 'learning_rate': 9.591835302669657e-06, 'epoch': 1.5865146256817055}
2025-04-25 03:55:57,355 - INFO - Training progress: {'loss': 0.7171, 'grad_norm': 2.147319793701172, 'learning_rate': 9.591835302669657e-06, 'epoch': 1.5865146256817055}
2025-04-25 03:55:57,355 - INFO - Training metrics: {'loss': 0.7171, 'grad_norm': 2.147319793701172, 'learning_rate': 9.591835302669657e-06, 'epoch': 1.5865146256817055}
2025-04-25 03:55:58,214 - INFO - INFO: Saving checkpoint at step 1600
2025-04-25 03:55:58,214 - INFO - Saving checkpoint at step 1600
2025-04-25 03:55:58,214 - INFO - Saving checkpoint at step 1600
2025-04-25 03:58:55,672 - INFO - INFO: Training progress: {'loss': 0.6851, 'grad_norm': 1.0504570007324219, 'learning_rate': 9.484508852582587e-06, 'epoch': 1.5964303420922161}
2025-04-25 03:58:55,672 - INFO - Training progress: {'loss': 0.6851, 'grad_norm': 1.0504570007324219, 'learning_rate': 9.484508852582587e-06, 'epoch': 1.5964303420922161}
2025-04-25 03:58:55,672 - INFO - Training metrics: {'loss': 0.6851, 'grad_norm': 1.0504570007324219, 'learning_rate': 9.484508852582587e-06, 'epoch': 1.5964303420922161}
2025-04-25 04:01:53,032 - INFO - INFO: Training progress: {'loss': 0.6682, 'grad_norm': 1.7969452142715454, 'learning_rate': 9.377241908671533e-06, 'epoch': 1.606346058502727}
2025-04-25 04:01:53,032 - INFO - Training progress: {'loss': 0.6682, 'grad_norm': 1.7969452142715454, 'learning_rate': 9.377241908671533e-06, 'epoch': 1.606346058502727}
2025-04-25 04:01:53,032 - INFO - Training metrics: {'loss': 0.6682, 'grad_norm': 1.7969452142715454, 'learning_rate': 9.377241908671533e-06, 'epoch': 1.606346058502727}
2025-04-25 04:04:50,499 - INFO - INFO: Training progress: {'loss': 0.689, 'grad_norm': 1.8186203241348267, 'learning_rate': 9.270046853390924e-06, 'epoch': 1.6162617749132375}
2025-04-25 04:04:50,499 - INFO - Training progress: {'loss': 0.689, 'grad_norm': 1.8186203241348267, 'learning_rate': 9.270046853390924e-06, 'epoch': 1.6162617749132375}
2025-04-25 04:04:50,499 - INFO - Training metrics: {'loss': 0.689, 'grad_norm': 1.8186203241348267, 'learning_rate': 9.270046853390924e-06, 'epoch': 1.6162617749132375}
2025-04-25 04:07:48,019 - INFO - INFO: Training progress: {'loss': 0.8099, 'grad_norm': 2.4563019275665283, 'learning_rate': 9.162936060896672e-06, 'epoch': 1.6261774913237481}
2025-04-25 04:07:48,019 - INFO - Training progress: {'loss': 0.8099, 'grad_norm': 2.4563019275665283, 'learning_rate': 9.162936060896672e-06, 'epoch': 1.6261774913237481}
2025-04-25 04:07:48,020 - INFO - Training metrics: {'loss': 0.8099, 'grad_norm': 2.4563019275665283, 'learning_rate': 9.162936060896672e-06, 'epoch': 1.6261774913237481}
2025-04-25 04:10:45,500 - INFO - INFO: Training progress: {'loss': 0.7649, 'grad_norm': 2.9471960067749023, 'learning_rate': 9.055921895617727e-06, 'epoch': 1.636093207734259}
2025-04-25 04:10:45,500 - INFO - Training progress: {'loss': 0.7649, 'grad_norm': 2.9471960067749023, 'learning_rate': 9.055921895617727e-06, 'epoch': 1.636093207734259}
2025-04-25 04:10:45,500 - INFO - Training metrics: {'loss': 0.7649, 'grad_norm': 2.9471960067749023, 'learning_rate': 9.055921895617727e-06, 'epoch': 1.636093207734259}
2025-04-25 04:13:43,119 - INFO - INFO: Training progress: {'loss': 0.7926, 'grad_norm': 2.015655517578125, 'learning_rate': 8.949016710828808e-06, 'epoch': 1.6460089241447695}
2025-04-25 04:13:43,119 - INFO - Training progress: {'loss': 0.7926, 'grad_norm': 2.015655517578125, 'learning_rate': 8.949016710828808e-06, 'epoch': 1.6460089241447695}
2025-04-25 04:13:43,120 - INFO - Training metrics: {'loss': 0.7926, 'grad_norm': 2.015655517578125, 'learning_rate': 8.949016710828808e-06, 'epoch': 1.6460089241447695}
2025-04-25 04:16:40,641 - INFO - INFO: Training progress: {'loss': 0.7477, 'grad_norm': 2.9009950160980225, 'learning_rate': 8.84223284722436e-06, 'epoch': 1.65592464055528}
2025-04-25 04:16:40,642 - INFO - Training progress: {'loss': 0.7477, 'grad_norm': 2.9009950160980225, 'learning_rate': 8.84223284722436e-06, 'epoch': 1.65592464055528}
2025-04-25 04:16:40,642 - INFO - Training metrics: {'loss': 0.7477, 'grad_norm': 2.9009950160980225, 'learning_rate': 8.84223284722436e-06, 'epoch': 1.65592464055528}
2025-04-25 04:19:38,332 - INFO - INFO: Training progress: {'loss': 0.6944, 'grad_norm': 1.8532426357269287, 'learning_rate': 8.73558263149402e-06, 'epoch': 1.665840356965791}
2025-04-25 04:19:38,333 - INFO - Training progress: {'loss': 0.6944, 'grad_norm': 1.8532426357269287, 'learning_rate': 8.73558263149402e-06, 'epoch': 1.665840356965791}
2025-04-25 04:19:38,333 - INFO - Training metrics: {'loss': 0.6944, 'grad_norm': 1.8532426357269287, 'learning_rate': 8.73558263149402e-06, 'epoch': 1.665840356965791}
2025-04-25 04:22:35,850 - INFO - INFO: Training progress: {'loss': 0.7765, 'grad_norm': 2.6589736938476562, 'learning_rate': 8.629078374899657e-06, 'epoch': 1.6757560733763013}
2025-04-25 04:22:35,851 - INFO - Training progress: {'loss': 0.7765, 'grad_norm': 2.6589736938476562, 'learning_rate': 8.629078374899657e-06, 'epoch': 1.6757560733763013}
2025-04-25 04:22:35,851 - INFO - Training metrics: {'loss': 0.7765, 'grad_norm': 2.6589736938476562, 'learning_rate': 8.629078374899657e-06, 'epoch': 1.6757560733763013}
2025-04-25 04:25:33,608 - INFO - INFO: Training progress: {'loss': 0.7077, 'grad_norm': 2.329000949859619, 'learning_rate': 8.522732371854228e-06, 'epoch': 1.685671789786812}
2025-04-25 04:25:33,608 - INFO - Training progress: {'loss': 0.7077, 'grad_norm': 2.329000949859619, 'learning_rate': 8.522732371854228e-06, 'epoch': 1.685671789786812}
2025-04-25 04:25:33,608 - INFO - Training metrics: {'loss': 0.7077, 'grad_norm': 2.329000949859619, 'learning_rate': 8.522732371854228e-06, 'epoch': 1.685671789786812}
2025-04-25 04:28:31,134 - INFO - INFO: Training progress: {'loss': 0.7833, 'grad_norm': 2.588061809539795, 'learning_rate': 8.41655689850254e-06, 'epoch': 1.695587506197323}
2025-04-25 04:28:31,134 - INFO - Training progress: {'loss': 0.7833, 'grad_norm': 2.588061809539795, 'learning_rate': 8.41655689850254e-06, 'epoch': 1.695587506197323}
2025-04-25 04:28:31,134 - INFO - Training metrics: {'loss': 0.7833, 'grad_norm': 2.588061809539795, 'learning_rate': 8.41655689850254e-06, 'epoch': 1.695587506197323}
2025-04-25 04:31:28,613 - INFO - INFO: Training progress: {'loss': 0.6612, 'grad_norm': 2.5296576023101807, 'learning_rate': 8.310564211304159e-06, 'epoch': 1.7055032226078333}
2025-04-25 04:31:28,613 - INFO - Training progress: {'loss': 0.6612, 'grad_norm': 2.5296576023101807, 'learning_rate': 8.310564211304159e-06, 'epoch': 1.7055032226078333}
2025-04-25 04:31:28,613 - INFO - Training metrics: {'loss': 0.6612, 'grad_norm': 2.5296576023101807, 'learning_rate': 8.310564211304159e-06, 'epoch': 1.7055032226078333}
2025-04-25 04:34:25,946 - INFO - INFO: Training progress: {'loss': 0.7768, 'grad_norm': 2.47294282913208, 'learning_rate': 8.204766545618574e-06, 'epoch': 1.715418939018344}
2025-04-25 04:34:25,946 - INFO - Training progress: {'loss': 0.7768, 'grad_norm': 2.47294282913208, 'learning_rate': 8.204766545618574e-06, 'epoch': 1.715418939018344}
2025-04-25 04:34:25,946 - INFO - Training metrics: {'loss': 0.7768, 'grad_norm': 2.47294282913208, 'learning_rate': 8.204766545618574e-06, 'epoch': 1.715418939018344}
2025-04-25 04:37:23,284 - INFO - INFO: Training progress: {'loss': 0.7702, 'grad_norm': 2.4812889099121094, 'learning_rate': 8.09917611429279e-06, 'epoch': 1.725334655428855}
2025-04-25 04:37:23,284 - INFO - Training progress: {'loss': 0.7702, 'grad_norm': 2.4812889099121094, 'learning_rate': 8.09917611429279e-06, 'epoch': 1.725334655428855}
2025-04-25 04:37:23,284 - INFO - Training metrics: {'loss': 0.7702, 'grad_norm': 2.4812889099121094, 'learning_rate': 8.09917611429279e-06, 'epoch': 1.725334655428855}
2025-04-25 04:40:20,864 - INFO - INFO: Training progress: {'loss': 0.644, 'grad_norm': 2.969548463821411, 'learning_rate': 7.993805106251528e-06, 'epoch': 1.7352503718393653}
2025-04-25 04:40:20,864 - INFO - Training progress: {'loss': 0.644, 'grad_norm': 2.969548463821411, 'learning_rate': 7.993805106251528e-06, 'epoch': 1.7352503718393653}
2025-04-25 04:40:20,864 - INFO - Training metrics: {'loss': 0.644, 'grad_norm': 2.969548463821411, 'learning_rate': 7.993805106251528e-06, 'epoch': 1.7352503718393653}
2025-04-25 04:57:26,486 - INFO - INFO: Training progress: {'eval_loss': 0.7594367265701294, 'eval_runtime': 1025.6201, 'eval_samples_per_second': 1.817, 'eval_steps_per_second': 1.817, 'epoch': 1.7352503718393653}
2025-04-25 04:57:26,486 - INFO - Training progress: {'eval_loss': 0.7594367265701294, 'eval_runtime': 1025.6201, 'eval_samples_per_second': 1.817, 'eval_steps_per_second': 1.817, 'epoch': 1.7352503718393653}
2025-04-25 04:57:26,486 - INFO - Training metrics: {'eval_loss': 0.7594367265701294, 'eval_runtime': 1025.6201, 'eval_samples_per_second': 1.817, 'eval_steps_per_second': 1.817, 'epoch': 1.7352503718393653}
2025-04-25 05:00:24,516 - INFO - INFO: Training progress: {'loss': 0.7951, 'grad_norm': 2.1070873737335205, 'learning_rate': 7.888665685090194e-06, 'epoch': 1.745166088249876}
2025-04-25 05:00:24,516 - INFO - Training progress: {'loss': 0.7951, 'grad_norm': 2.1070873737335205, 'learning_rate': 7.888665685090194e-06, 'epoch': 1.745166088249876}
2025-04-25 05:00:24,516 - INFO - Training metrics: {'loss': 0.7951, 'grad_norm': 2.1070873737335205, 'learning_rate': 7.888665685090194e-06, 'epoch': 1.745166088249876}
2025-04-25 05:03:22,336 - INFO - INFO: Training progress: {'loss': 0.7841, 'grad_norm': 1.6145312786102295, 'learning_rate': 7.783769987670749e-06, 'epoch': 1.7550818046603869}
2025-04-25 05:03:22,336 - INFO - Training progress: {'loss': 0.7841, 'grad_norm': 1.6145312786102295, 'learning_rate': 7.783769987670749e-06, 'epoch': 1.7550818046603869}
2025-04-25 05:03:22,336 - INFO - Training metrics: {'loss': 0.7841, 'grad_norm': 1.6145312786102295, 'learning_rate': 7.783769987670749e-06, 'epoch': 1.7550818046603869}
2025-04-25 05:06:19,891 - INFO - INFO: Training progress: {'loss': 0.799, 'grad_norm': 2.430234432220459, 'learning_rate': 7.679130122720704e-06, 'epoch': 1.7649975210708972}
2025-04-25 05:06:19,891 - INFO - Training progress: {'loss': 0.799, 'grad_norm': 2.430234432220459, 'learning_rate': 7.679130122720704e-06, 'epoch': 1.7649975210708972}
2025-04-25 05:06:19,891 - INFO - Training metrics: {'loss': 0.799, 'grad_norm': 2.430234432220459, 'learning_rate': 7.679130122720704e-06, 'epoch': 1.7649975210708972}
2025-04-25 05:09:17,704 - INFO - INFO: Training progress: {'loss': 0.6909, 'grad_norm': 1.9318121671676636, 'learning_rate': 7.5747581694353056e-06, 'epoch': 1.774913237481408}
2025-04-25 05:09:17,704 - INFO - Training progress: {'loss': 0.6909, 'grad_norm': 1.9318121671676636, 'learning_rate': 7.5747581694353056e-06, 'epoch': 1.774913237481408}
2025-04-25 05:09:17,704 - INFO - Training metrics: {'loss': 0.6909, 'grad_norm': 1.9318121671676636, 'learning_rate': 7.5747581694353056e-06, 'epoch': 1.774913237481408}
2025-04-25 05:12:15,374 - INFO - INFO: Training progress: {'loss': 0.7866, 'grad_norm': 2.5557641983032227, 'learning_rate': 7.470666176083193e-06, 'epoch': 1.7848289538919186}
2025-04-25 05:12:15,374 - INFO - Training progress: {'loss': 0.7866, 'grad_norm': 2.5557641983032227, 'learning_rate': 7.470666176083193e-06, 'epoch': 1.7848289538919186}
2025-04-25 05:12:15,374 - INFO - Training metrics: {'loss': 0.7866, 'grad_norm': 2.5557641983032227, 'learning_rate': 7.470666176083193e-06, 'epoch': 1.7848289538919186}
2025-04-25 05:12:16,114 - INFO - INFO: Saving checkpoint at step 1800
2025-04-25 05:12:16,114 - INFO - Saving checkpoint at step 1800
2025-04-25 05:12:16,114 - INFO - Saving checkpoint at step 1800
2025-04-25 05:15:13,706 - INFO - INFO: Training progress: {'loss': 0.6721, 'grad_norm': 2.4301822185516357, 'learning_rate': 7.366866158615575e-06, 'epoch': 1.7947446703024292}
2025-04-25 05:15:13,706 - INFO - Training progress: {'loss': 0.6721, 'grad_norm': 2.4301822185516357, 'learning_rate': 7.366866158615575e-06, 'epoch': 1.7947446703024292}
2025-04-25 05:15:13,706 - INFO - Training metrics: {'loss': 0.6721, 'grad_norm': 2.4301822185516357, 'learning_rate': 7.366866158615575e-06, 'epoch': 1.7947446703024292}
2025-04-25 05:18:11,206 - INFO - INFO: Training progress: {'loss': 0.6276, 'grad_norm': 1.5179955959320068, 'learning_rate': 7.263370099279173e-06, 'epoch': 1.80466038671294}
2025-04-25 05:18:11,207 - INFO - Training progress: {'loss': 0.6276, 'grad_norm': 1.5179955959320068, 'learning_rate': 7.263370099279173e-06, 'epoch': 1.80466038671294}
2025-04-25 05:18:11,207 - INFO - Training metrics: {'loss': 0.6276, 'grad_norm': 1.5179955959320068, 'learning_rate': 7.263370099279173e-06, 'epoch': 1.80466038671294}
2025-04-25 05:21:08,713 - INFO - INFO: Training progress: {'loss': 0.7484, 'grad_norm': 1.9675934314727783, 'learning_rate': 7.160189945233027e-06, 'epoch': 1.8145761031234506}
2025-04-25 05:21:08,713 - INFO - Training progress: {'loss': 0.7484, 'grad_norm': 1.9675934314727783, 'learning_rate': 7.160189945233027e-06, 'epoch': 1.8145761031234506}
2025-04-25 05:21:08,713 - INFO - Training metrics: {'loss': 0.7484, 'grad_norm': 1.9675934314727783, 'learning_rate': 7.160189945233027e-06, 'epoch': 1.8145761031234506}
2025-04-25 05:24:06,266 - INFO - INFO: Training progress: {'loss': 0.7675, 'grad_norm': 1.4511027336120605, 'learning_rate': 7.057337607169373e-06, 'epoch': 1.8244918195339612}
2025-04-25 05:24:06,266 - INFO - Training progress: {'loss': 0.7675, 'grad_norm': 1.4511027336120605, 'learning_rate': 7.057337607169373e-06, 'epoch': 1.8244918195339612}
2025-04-25 05:24:06,266 - INFO - Training metrics: {'loss': 0.7675, 'grad_norm': 1.4511027336120605, 'learning_rate': 7.057337607169373e-06, 'epoch': 1.8244918195339612}
2025-04-25 05:27:04,045 - INFO - INFO: Training progress: {'loss': 0.6939, 'grad_norm': 2.6393611431121826, 'learning_rate': 6.954824957938723e-06, 'epoch': 1.834407535944472}
2025-04-25 05:27:04,046 - INFO - Training progress: {'loss': 0.6939, 'grad_norm': 2.6393611431121826, 'learning_rate': 6.954824957938723e-06, 'epoch': 1.834407535944472}
2025-04-25 05:27:04,046 - INFO - Training metrics: {'loss': 0.6939, 'grad_norm': 2.6393611431121826, 'learning_rate': 6.954824957938723e-06, 'epoch': 1.834407535944472}
2025-04-25 05:30:01,578 - INFO - INFO: Training progress: {'loss': 0.8369, 'grad_norm': 2.569098472595215, 'learning_rate': 6.852663831179303e-06, 'epoch': 1.8443232523549826}
2025-04-25 05:30:01,578 - INFO - Training progress: {'loss': 0.8369, 'grad_norm': 2.569098472595215, 'learning_rate': 6.852663831179303e-06, 'epoch': 1.8443232523549826}
2025-04-25 05:30:01,578 - INFO - Training metrics: {'loss': 0.8369, 'grad_norm': 2.569098472595215, 'learning_rate': 6.852663831179303e-06, 'epoch': 1.8443232523549826}
2025-04-25 05:32:59,153 - INFO - INFO: Training progress: {'loss': 0.7394, 'grad_norm': 2.7716598510742188, 'learning_rate': 6.7508660199510356e-06, 'epoch': 1.8542389687654932}
2025-04-25 05:32:59,153 - INFO - Training progress: {'loss': 0.7394, 'grad_norm': 2.7716598510742188, 'learning_rate': 6.7508660199510356e-06, 'epoch': 1.8542389687654932}
2025-04-25 05:32:59,153 - INFO - Training metrics: {'loss': 0.7394, 'grad_norm': 2.7716598510742188, 'learning_rate': 6.7508660199510356e-06, 'epoch': 1.8542389687654932}
2025-04-25 05:35:56,456 - INFO - INFO: Training progress: {'loss': 0.7404, 'grad_norm': 3.089752435684204, 'learning_rate': 6.6494432753741935e-06, 'epoch': 1.864154685176004}
2025-04-25 05:35:56,457 - INFO - Training progress: {'loss': 0.7404, 'grad_norm': 3.089752435684204, 'learning_rate': 6.6494432753741935e-06, 'epoch': 1.864154685176004}
2025-04-25 05:35:56,457 - INFO - Training metrics: {'loss': 0.7404, 'grad_norm': 3.089752435684204, 'learning_rate': 6.6494432753741935e-06, 'epoch': 1.864154685176004}
2025-04-25 05:38:53,940 - INFO - INFO: Training progress: {'loss': 0.766, 'grad_norm': 2.83231782913208, 'learning_rate': 6.548407305272896e-06, 'epoch': 1.8740704015865146}
2025-04-25 05:38:53,940 - INFO - Training progress: {'loss': 0.766, 'grad_norm': 2.83231782913208, 'learning_rate': 6.548407305272896e-06, 'epoch': 1.8740704015865146}
2025-04-25 05:38:53,940 - INFO - Training metrics: {'loss': 0.766, 'grad_norm': 2.83231782913208, 'learning_rate': 6.548407305272896e-06, 'epoch': 1.8740704015865146}
2025-04-25 05:41:51,544 - INFO - INFO: Training progress: {'loss': 0.6493, 'grad_norm': 2.1910417079925537, 'learning_rate': 6.4477697728236146e-06, 'epoch': 1.8839861179970252}
2025-04-25 05:41:51,545 - INFO - Training progress: {'loss': 0.6493, 'grad_norm': 2.1910417079925537, 'learning_rate': 6.4477697728236146e-06, 'epoch': 1.8839861179970252}
2025-04-25 05:41:51,545 - INFO - Training metrics: {'loss': 0.6493, 'grad_norm': 2.1910417079925537, 'learning_rate': 6.4477697728236146e-06, 'epoch': 1.8839861179970252}
2025-04-25 05:44:49,579 - INFO - INFO: Training progress: {'loss': 0.7688, 'grad_norm': 1.8580213785171509, 'learning_rate': 6.347542295208813e-06, 'epoch': 1.893901834407536}
2025-04-25 05:44:49,580 - INFO - Training progress: {'loss': 0.7688, 'grad_norm': 1.8580213785171509, 'learning_rate': 6.347542295208813e-06, 'epoch': 1.893901834407536}
2025-04-25 05:44:49,580 - INFO - Training metrics: {'loss': 0.7688, 'grad_norm': 1.8580213785171509, 'learning_rate': 6.347542295208813e-06, 'epoch': 1.893901834407536}
2025-04-25 05:47:47,170 - INFO - INFO: Training progress: {'loss': 0.7451, 'grad_norm': 2.2263965606689453, 'learning_rate': 6.247736442275918e-06, 'epoch': 1.9038175508180466}
2025-04-25 05:47:47,172 - INFO - Training progress: {'loss': 0.7451, 'grad_norm': 2.2263965606689453, 'learning_rate': 6.247736442275918e-06, 'epoch': 1.9038175508180466}
2025-04-25 05:47:47,172 - INFO - Training metrics: {'loss': 0.7451, 'grad_norm': 2.2263965606689453, 'learning_rate': 6.247736442275918e-06, 'epoch': 1.9038175508180466}
2025-04-25 05:50:44,728 - INFO - INFO: Training progress: {'loss': 0.7092, 'grad_norm': 3.1212007999420166, 'learning_rate': 6.14836373520173e-06, 'epoch': 1.9137332672285572}
2025-04-25 05:50:44,728 - INFO - Training progress: {'loss': 0.7092, 'grad_norm': 3.1212007999420166, 'learning_rate': 6.14836373520173e-06, 'epoch': 1.9137332672285572}
2025-04-25 05:50:44,728 - INFO - Training metrics: {'loss': 0.7092, 'grad_norm': 3.1212007999420166, 'learning_rate': 6.14836373520173e-06, 'epoch': 1.9137332672285572}
2025-04-25 05:53:42,172 - INFO - INFO: Training progress: {'loss': 0.7153, 'grad_norm': 2.6395232677459717, 'learning_rate': 6.049435645162487e-06, 'epoch': 1.923648983639068}
2025-04-25 05:53:42,172 - INFO - Training progress: {'loss': 0.7153, 'grad_norm': 2.6395232677459717, 'learning_rate': 6.049435645162487e-06, 'epoch': 1.923648983639068}
2025-04-25 05:53:42,172 - INFO - Training metrics: {'loss': 0.7153, 'grad_norm': 2.6395232677459717, 'learning_rate': 6.049435645162487e-06, 'epoch': 1.923648983639068}
2025-04-25 05:56:39,807 - INFO - INFO: Training progress: {'loss': 0.6808, 'grad_norm': 2.2086827754974365, 'learning_rate': 5.950963592009662e-06, 'epoch': 1.9335647000495786}
2025-04-25 05:56:39,807 - INFO - Training progress: {'loss': 0.6808, 'grad_norm': 2.2086827754974365, 'learning_rate': 5.950963592009662e-06, 'epoch': 1.9335647000495786}
2025-04-25 05:56:39,807 - INFO - Training metrics: {'loss': 0.6808, 'grad_norm': 2.2086827754974365, 'learning_rate': 5.950963592009662e-06, 'epoch': 1.9335647000495786}
2025-04-25 05:59:37,537 - INFO - INFO: Training progress: {'loss': 0.7211, 'grad_norm': 2.716890335083008, 'learning_rate': 5.852958942951701e-06, 'epoch': 1.9434804164600892}
2025-04-25 05:59:37,538 - INFO - Training progress: {'loss': 0.7211, 'grad_norm': 2.716890335083008, 'learning_rate': 5.852958942951701e-06, 'epoch': 1.9434804164600892}
2025-04-25 05:59:37,538 - INFO - Training metrics: {'loss': 0.7211, 'grad_norm': 2.716890335083008, 'learning_rate': 5.852958942951701e-06, 'epoch': 1.9434804164600892}
2025-04-25 06:02:34,944 - INFO - INFO: Training progress: {'loss': 0.6605, 'grad_norm': 2.281801700592041, 'learning_rate': 5.755433011241851e-06, 'epoch': 1.9533961328706}
2025-04-25 06:02:34,945 - INFO - Training progress: {'loss': 0.6605, 'grad_norm': 2.281801700592041, 'learning_rate': 5.755433011241851e-06, 'epoch': 1.9533961328706}
2025-04-25 06:02:34,945 - INFO - Training metrics: {'loss': 0.6605, 'grad_norm': 2.281801700592041, 'learning_rate': 5.755433011241851e-06, 'epoch': 1.9533961328706}
2025-04-25 06:05:32,480 - INFO - INFO: Training progress: {'loss': 0.69, 'grad_norm': 1.6974680423736572, 'learning_rate': 5.658397054872197e-06, 'epoch': 1.9633118492811106}
2025-04-25 06:05:32,480 - INFO - Training progress: {'loss': 0.69, 'grad_norm': 1.6974680423736572, 'learning_rate': 5.658397054872197e-06, 'epoch': 1.9633118492811106}
2025-04-25 06:05:32,480 - INFO - Training metrics: {'loss': 0.69, 'grad_norm': 1.6974680423736572, 'learning_rate': 5.658397054872197e-06, 'epoch': 1.9633118492811106}
2025-04-25 06:08:30,160 - INFO - INFO: Training progress: {'loss': 0.7033, 'grad_norm': 1.0283046960830688, 'learning_rate': 5.561862275274088e-06, 'epoch': 1.9732275656916212}
2025-04-25 06:08:30,160 - INFO - Training progress: {'loss': 0.7033, 'grad_norm': 1.0283046960830688, 'learning_rate': 5.561862275274088e-06, 'epoch': 1.9732275656916212}
2025-04-25 06:08:30,160 - INFO - Training metrics: {'loss': 0.7033, 'grad_norm': 1.0283046960830688, 'learning_rate': 5.561862275274088e-06, 'epoch': 1.9732275656916212}
2025-04-25 06:11:27,840 - INFO - INFO: Training progress: {'loss': 0.7428, 'grad_norm': 1.9452122449874878, 'learning_rate': 5.465839816025093e-06, 'epoch': 1.983143282102132}
2025-04-25 06:11:27,841 - INFO - Training progress: {'loss': 0.7428, 'grad_norm': 1.9452122449874878, 'learning_rate': 5.465839816025093e-06, 'epoch': 1.983143282102132}
2025-04-25 06:11:27,841 - INFO - Training metrics: {'loss': 0.7428, 'grad_norm': 1.9452122449874878, 'learning_rate': 5.465839816025093e-06, 'epoch': 1.983143282102132}
2025-04-25 06:11:28,595 - INFO - INFO: Saving checkpoint at step 2000
2025-04-25 06:11:28,596 - INFO - Saving checkpoint at step 2000
2025-04-25 06:11:28,596 - INFO - Saving checkpoint at step 2000
2025-04-25 06:14:26,035 - INFO - INFO: Training progress: {'loss': 0.7159, 'grad_norm': 3.6637954711914062, 'learning_rate': 5.370340761562629e-06, 'epoch': 1.9930589985126426}
2025-04-25 06:14:26,036 - INFO - Training progress: {'loss': 0.7159, 'grad_norm': 3.6637954711914062, 'learning_rate': 5.370340761562629e-06, 'epoch': 1.9930589985126426}
2025-04-25 06:14:26,036 - INFO - Training metrics: {'loss': 0.7159, 'grad_norm': 3.6637954711914062, 'learning_rate': 5.370340761562629e-06, 'epoch': 1.9930589985126426}
2025-04-25 06:16:30,828 - INFO - INFO: Starting epoch 2.0/3
2025-04-25 06:16:30,828 - INFO - Starting epoch 2.0/3
2025-04-25 06:16:30,828 - INFO - Starting epoch 2.0/3
2025-04-25 06:17:32,642 - INFO - INFO: Training progress: {'loss': 0.7246, 'grad_norm': 2.6282763481140137, 'learning_rate': 5.275376135904408e-06, 'epoch': 2.002974714923153}
2025-04-25 06:17:32,642 - INFO - Training progress: {'loss': 0.7246, 'grad_norm': 2.6282763481140137, 'learning_rate': 5.275376135904408e-06, 'epoch': 2.002974714923153}
2025-04-25 06:17:32,642 - INFO - Training metrics: {'loss': 0.7246, 'grad_norm': 2.6282763481140137, 'learning_rate': 5.275376135904408e-06, 'epoch': 2.002974714923153}
2025-04-25 06:20:30,305 - INFO - INFO: Training progress: {'loss': 0.7074, 'grad_norm': 1.8565139770507812, 'learning_rate': 5.180956901375893e-06, 'epoch': 2.012890431333664}
2025-04-25 06:20:30,305 - INFO - Training progress: {'loss': 0.7074, 'grad_norm': 1.8565139770507812, 'learning_rate': 5.180956901375893e-06, 'epoch': 2.012890431333664}
2025-04-25 06:20:30,305 - INFO - Training metrics: {'loss': 0.7074, 'grad_norm': 1.8565139770507812, 'learning_rate': 5.180956901375893e-06, 'epoch': 2.012890431333664}
2025-04-25 06:23:27,968 - INFO - INFO: Training progress: {'loss': 0.6487, 'grad_norm': 2.236138343811035, 'learning_rate': 5.087093957344841e-06, 'epoch': 2.0228061477441743}
2025-04-25 06:23:27,968 - INFO - Training progress: {'loss': 0.6487, 'grad_norm': 2.236138343811035, 'learning_rate': 5.087093957344841e-06, 'epoch': 2.0228061477441743}
2025-04-25 06:23:27,968 - INFO - Training metrics: {'loss': 0.6487, 'grad_norm': 2.236138343811035, 'learning_rate': 5.087093957344841e-06, 'epoch': 2.0228061477441743}
2025-04-25 06:26:25,539 - INFO - INFO: Training progress: {'loss': 0.8042, 'grad_norm': 3.7864131927490234, 'learning_rate': 4.99379813896311e-06, 'epoch': 2.032721864154685}
2025-04-25 06:26:25,540 - INFO - Training progress: {'loss': 0.8042, 'grad_norm': 3.7864131927490234, 'learning_rate': 4.99379813896311e-06, 'epoch': 2.032721864154685}
2025-04-25 06:26:25,540 - INFO - Training metrics: {'loss': 0.8042, 'grad_norm': 3.7864131927490234, 'learning_rate': 4.99379813896311e-06, 'epoch': 2.032721864154685}
2025-04-25 06:29:23,323 - INFO - INFO: Training progress: {'loss': 0.7004, 'grad_norm': 2.9913973808288574, 'learning_rate': 4.9010802159159224e-06, 'epoch': 2.042637580565196}
2025-04-25 06:29:23,323 - INFO - Training progress: {'loss': 0.7004, 'grad_norm': 2.9913973808288574, 'learning_rate': 4.9010802159159224e-06, 'epoch': 2.042637580565196}
2025-04-25 06:29:23,323 - INFO - Training metrics: {'loss': 0.7004, 'grad_norm': 2.9913973808288574, 'learning_rate': 4.9010802159159224e-06, 'epoch': 2.042637580565196}
2025-04-25 06:32:20,716 - INFO - INFO: Training progress: {'loss': 0.6612, 'grad_norm': 2.6408281326293945, 'learning_rate': 4.808950891178634e-06, 'epoch': 2.0525532969757063}
2025-04-25 06:32:20,716 - INFO - Training progress: {'loss': 0.6612, 'grad_norm': 2.6408281326293945, 'learning_rate': 4.808950891178634e-06, 'epoch': 2.0525532969757063}
2025-04-25 06:32:20,716 - INFO - Training metrics: {'loss': 0.6612, 'grad_norm': 2.6408281326293945, 'learning_rate': 4.808950891178634e-06, 'epoch': 2.0525532969757063}
2025-04-25 06:35:18,315 - INFO - INFO: Training progress: {'loss': 0.6969, 'grad_norm': 2.2791647911071777, 'learning_rate': 4.7174207997812436e-06, 'epoch': 2.062469013386217}
2025-04-25 06:35:18,315 - INFO - Training progress: {'loss': 0.6969, 'grad_norm': 2.2791647911071777, 'learning_rate': 4.7174207997812436e-06, 'epoch': 2.062469013386217}
2025-04-25 06:35:18,315 - INFO - Training metrics: {'loss': 0.6969, 'grad_norm': 2.2791647911071777, 'learning_rate': 4.7174207997812436e-06, 'epoch': 2.062469013386217}
2025-04-25 06:38:15,594 - INFO - INFO: Training progress: {'loss': 0.5902, 'grad_norm': 2.0424094200134277, 'learning_rate': 4.626500507580701e-06, 'epoch': 2.072384729796728}
2025-04-25 06:38:15,594 - INFO - Training progress: {'loss': 0.5902, 'grad_norm': 2.0424094200134277, 'learning_rate': 4.626500507580701e-06, 'epoch': 2.072384729796728}
2025-04-25 06:38:15,594 - INFO - Training metrics: {'loss': 0.5902, 'grad_norm': 2.0424094200134277, 'learning_rate': 4.626500507580701e-06, 'epoch': 2.072384729796728}
2025-04-25 06:41:13,704 - INFO - INFO: Training progress: {'loss': 0.6664, 'grad_norm': 3.0967252254486084, 'learning_rate': 4.536200510041271e-06, 'epoch': 2.0823004462072383}
2025-04-25 06:41:13,704 - INFO - Training progress: {'loss': 0.6664, 'grad_norm': 3.0967252254486084, 'learning_rate': 4.536200510041271e-06, 'epoch': 2.0823004462072383}
2025-04-25 06:41:13,704 - INFO - Training metrics: {'loss': 0.6664, 'grad_norm': 3.0967252254486084, 'learning_rate': 4.536200510041271e-06, 'epoch': 2.0823004462072383}
2025-04-25 06:58:15,611 - INFO - INFO: Training progress: {'eval_loss': 0.7524966597557068, 'eval_runtime': 1021.9034, 'eval_samples_per_second': 1.824, 'eval_steps_per_second': 1.824, 'epoch': 2.0823004462072383}
2025-04-25 06:58:15,612 - INFO - Training progress: {'eval_loss': 0.7524966597557068, 'eval_runtime': 1021.9034, 'eval_samples_per_second': 1.824, 'eval_steps_per_second': 1.824, 'epoch': 2.0823004462072383}
2025-04-25 06:58:15,612 - INFO - Training metrics: {'eval_loss': 0.7524966597557068, 'eval_runtime': 1021.9034, 'eval_samples_per_second': 1.824, 'eval_steps_per_second': 1.824, 'epoch': 2.0823004462072383}
2025-04-25 07:01:13,429 - INFO - INFO: Training progress: {'loss': 0.6836, 'grad_norm': 3.0860884189605713, 'learning_rate': 4.446531231022946e-06, 'epoch': 2.092216162617749}
2025-04-25 07:01:13,429 - INFO - Training progress: {'loss': 0.6836, 'grad_norm': 3.0860884189605713, 'learning_rate': 4.446531231022946e-06, 'epoch': 2.092216162617749}
2025-04-25 07:01:13,429 - INFO - Training metrics: {'loss': 0.6836, 'grad_norm': 3.0860884189605713, 'learning_rate': 4.446531231022946e-06, 'epoch': 2.092216162617749}
2025-04-25 07:04:10,838 - INFO - INFO: Training progress: {'loss': 0.6758, 'grad_norm': 2.481217622756958, 'learning_rate': 4.357503021578158e-06, 'epoch': 2.10213187902826}
2025-04-25 07:04:10,838 - INFO - Training progress: {'loss': 0.6758, 'grad_norm': 2.481217622756958, 'learning_rate': 4.357503021578158e-06, 'epoch': 2.10213187902826}
2025-04-25 07:04:10,838 - INFO - Training metrics: {'loss': 0.6758, 'grad_norm': 2.481217622756958, 'learning_rate': 4.357503021578158e-06, 'epoch': 2.10213187902826}
2025-04-25 07:07:08,291 - INFO - INFO: Training progress: {'loss': 0.817, 'grad_norm': 3.9058802127838135, 'learning_rate': 4.26912615875692e-06, 'epoch': 2.1120475954387703}
2025-04-25 07:07:08,291 - INFO - Training progress: {'loss': 0.817, 'grad_norm': 3.9058802127838135, 'learning_rate': 4.26912615875692e-06, 'epoch': 2.1120475954387703}
2025-04-25 07:07:08,291 - INFO - Training metrics: {'loss': 0.817, 'grad_norm': 3.9058802127838135, 'learning_rate': 4.26912615875692e-06, 'epoch': 2.1120475954387703}
2025-04-25 07:10:05,701 - INFO - INFO: Training progress: {'loss': 0.6523, 'grad_norm': 2.9696576595306396, 'learning_rate': 4.181410844420473e-06, 'epoch': 2.121963311849281}
2025-04-25 07:10:05,701 - INFO - Training progress: {'loss': 0.6523, 'grad_norm': 2.9696576595306396, 'learning_rate': 4.181410844420473e-06, 'epoch': 2.121963311849281}
2025-04-25 07:10:05,701 - INFO - Training metrics: {'loss': 0.6523, 'grad_norm': 2.9696576595306396, 'learning_rate': 4.181410844420473e-06, 'epoch': 2.121963311849281}
2025-04-25 07:13:03,233 - INFO - INFO: Training progress: {'loss': 0.653, 'grad_norm': 2.0168731212615967, 'learning_rate': 4.0943672040636115e-06, 'epoch': 2.131879028259792}
2025-04-25 07:13:03,233 - INFO - Training progress: {'loss': 0.653, 'grad_norm': 2.0168731212615967, 'learning_rate': 4.0943672040636115e-06, 'epoch': 2.131879028259792}
2025-04-25 07:13:03,233 - INFO - Training metrics: {'loss': 0.653, 'grad_norm': 2.0168731212615967, 'learning_rate': 4.0943672040636115e-06, 'epoch': 2.131879028259792}
2025-04-25 07:16:00,736 - INFO - INFO: Training progress: {'loss': 0.8018, 'grad_norm': 1.2549692392349243, 'learning_rate': 4.008005285645863e-06, 'epoch': 2.1417947446703023}
2025-04-25 07:16:00,736 - INFO - Training progress: {'loss': 0.8018, 'grad_norm': 1.2549692392349243, 'learning_rate': 4.008005285645863e-06, 'epoch': 2.1417947446703023}
2025-04-25 07:16:00,736 - INFO - Training metrics: {'loss': 0.8018, 'grad_norm': 1.2549692392349243, 'learning_rate': 4.008005285645863e-06, 'epoch': 2.1417947446703023}
2025-04-25 07:18:58,025 - INFO - INFO: Training progress: {'loss': 0.7059, 'grad_norm': 1.855150818824768, 'learning_rate': 3.922335058431575e-06, 'epoch': 2.151710461080813}
2025-04-25 07:18:58,025 - INFO - Training progress: {'loss': 0.7059, 'grad_norm': 1.855150818824768, 'learning_rate': 3.922335058431575e-06, 'epoch': 2.151710461080813}
2025-04-25 07:18:58,025 - INFO - Training metrics: {'loss': 0.7059, 'grad_norm': 1.855150818824768, 'learning_rate': 3.922335058431575e-06, 'epoch': 2.151710461080813}
2025-04-25 07:21:55,521 - INFO - INFO: Training progress: {'loss': 0.7563, 'grad_norm': 3.7454659938812256, 'learning_rate': 3.837366411839114e-06, 'epoch': 2.161626177491324}
2025-04-25 07:21:55,521 - INFO - Training progress: {'loss': 0.7563, 'grad_norm': 3.7454659938812256, 'learning_rate': 3.837366411839114e-06, 'epoch': 2.161626177491324}
2025-04-25 07:21:55,521 - INFO - Training metrics: {'loss': 0.7563, 'grad_norm': 3.7454659938812256, 'learning_rate': 3.837366411839114e-06, 'epoch': 2.161626177491324}
2025-04-25 07:24:52,813 - INFO - INFO: Training progress: {'loss': 0.7223, 'grad_norm': 2.1147336959838867, 'learning_rate': 3.753109154299258e-06, 'epoch': 2.1715418939018343}
2025-04-25 07:24:52,813 - INFO - Training progress: {'loss': 0.7223, 'grad_norm': 2.1147336959838867, 'learning_rate': 3.753109154299258e-06, 'epoch': 2.1715418939018343}
2025-04-25 07:24:52,813 - INFO - Training metrics: {'loss': 0.7223, 'grad_norm': 2.1147336959838867, 'learning_rate': 3.753109154299258e-06, 'epoch': 2.1715418939018343}
2025-04-25 07:27:50,335 - INFO - INFO: Training progress: {'loss': 0.7004, 'grad_norm': 2.6348259449005127, 'learning_rate': 3.6695730121229734e-06, 'epoch': 2.181457610312345}
2025-04-25 07:27:50,335 - INFO - Training progress: {'loss': 0.7004, 'grad_norm': 2.6348259449005127, 'learning_rate': 3.6695730121229734e-06, 'epoch': 2.181457610312345}
2025-04-25 07:27:50,335 - INFO - Training metrics: {'loss': 0.7004, 'grad_norm': 2.6348259449005127, 'learning_rate': 3.6695730121229734e-06, 'epoch': 2.181457610312345}
2025-04-25 07:27:51,057 - INFO - INFO: Saving checkpoint at step 2200
2025-04-25 07:27:51,057 - INFO - Saving checkpoint at step 2200
2025-04-25 07:27:51,058 - INFO - Saving checkpoint at step 2200
2025-04-25 07:30:48,339 - INFO - INFO: Training progress: {'loss': 0.6548, 'grad_norm': 1.955670714378357, 'learning_rate': 3.5867676283786335e-06, 'epoch': 2.191373326722856}
2025-04-25 07:30:48,340 - INFO - Training progress: {'loss': 0.6548, 'grad_norm': 1.955670714378357, 'learning_rate': 3.5867676283786335e-06, 'epoch': 2.191373326722856}
2025-04-25 07:30:48,340 - INFO - Training metrics: {'loss': 0.6548, 'grad_norm': 1.955670714378357, 'learning_rate': 3.5867676283786335e-06, 'epoch': 2.191373326722856}
2025-04-25 07:33:45,824 - INFO - INFO: Training progress: {'loss': 0.6627, 'grad_norm': 2.4795851707458496, 'learning_rate': 3.5047025617788578e-06, 'epoch': 2.2012890431333663}
2025-04-25 07:33:45,824 - INFO - Training progress: {'loss': 0.6627, 'grad_norm': 2.4795851707458496, 'learning_rate': 3.5047025617788578e-06, 'epoch': 2.2012890431333663}
2025-04-25 07:33:45,824 - INFO - Training metrics: {'loss': 0.6627, 'grad_norm': 2.4795851707458496, 'learning_rate': 3.5047025617788578e-06, 'epoch': 2.2012890431333663}
2025-04-25 07:36:43,281 - INFO - INFO: Training progress: {'loss': 0.6319, 'grad_norm': 3.1162490844726562, 'learning_rate': 3.4233872855771145e-06, 'epoch': 2.211204759543877}
2025-04-25 07:36:43,281 - INFO - Training progress: {'loss': 0.6319, 'grad_norm': 3.1162490844726562, 'learning_rate': 3.4233872855771145e-06, 'epoch': 2.211204759543877}
2025-04-25 07:36:43,281 - INFO - Training metrics: {'loss': 0.6319, 'grad_norm': 3.1162490844726562, 'learning_rate': 3.4233872855771145e-06, 'epoch': 2.211204759543877}
2025-04-25 07:39:40,762 - INFO - INFO: Training progress: {'loss': 0.7792, 'grad_norm': 2.9662024974823, 'learning_rate': 3.342831186474149e-06, 'epoch': 2.221120475954388}
2025-04-25 07:39:40,762 - INFO - Training progress: {'loss': 0.7792, 'grad_norm': 2.9662024974823, 'learning_rate': 3.342831186474149e-06, 'epoch': 2.221120475954388}
2025-04-25 07:39:40,762 - INFO - Training metrics: {'loss': 0.7792, 'grad_norm': 2.9662024974823, 'learning_rate': 3.342831186474149e-06, 'epoch': 2.221120475954388}
2025-04-25 07:42:38,132 - INFO - INFO: Training progress: {'loss': 0.6863, 'grad_norm': 2.229951858520508, 'learning_rate': 3.2630435635344283e-06, 'epoch': 2.2310361923648983}
2025-04-25 07:42:38,132 - INFO - Training progress: {'loss': 0.6863, 'grad_norm': 2.229951858520508, 'learning_rate': 3.2630435635344283e-06, 'epoch': 2.2310361923648983}
2025-04-25 07:42:38,132 - INFO - Training metrics: {'loss': 0.6863, 'grad_norm': 2.229951858520508, 'learning_rate': 3.2630435635344283e-06, 'epoch': 2.2310361923648983}
2025-04-25 07:45:35,642 - INFO - INFO: Training progress: {'loss': 0.7042, 'grad_norm': 2.4209187030792236, 'learning_rate': 3.1840336271126935e-06, 'epoch': 2.240951908775409}
2025-04-25 07:45:35,643 - INFO - Training progress: {'loss': 0.7042, 'grad_norm': 2.4209187030792236, 'learning_rate': 3.1840336271126935e-06, 'epoch': 2.240951908775409}
2025-04-25 07:45:35,643 - INFO - Training metrics: {'loss': 0.7042, 'grad_norm': 2.4209187030792236, 'learning_rate': 3.1840336271126935e-06, 'epoch': 2.240951908775409}
2025-04-25 07:48:33,097 - INFO - INFO: Training progress: {'loss': 0.6611, 'grad_norm': 2.988680362701416, 'learning_rate': 3.1058104977907576e-06, 'epoch': 2.25086762518592}
2025-04-25 07:48:33,097 - INFO - Training progress: {'loss': 0.6611, 'grad_norm': 2.988680362701416, 'learning_rate': 3.1058104977907576e-06, 'epoch': 2.25086762518592}
2025-04-25 07:48:33,097 - INFO - Training metrics: {'loss': 0.6611, 'grad_norm': 2.988680362701416, 'learning_rate': 3.1058104977907576e-06, 'epoch': 2.25086762518592}
2025-04-25 07:51:30,701 - INFO - INFO: Training progress: {'loss': 0.5966, 'grad_norm': 1.9855464696884155, 'learning_rate': 3.0283832053246644e-06, 'epoch': 2.2607833415964302}
2025-04-25 07:51:30,701 - INFO - Training progress: {'loss': 0.5966, 'grad_norm': 1.9855464696884155, 'learning_rate': 3.0283832053246644e-06, 'epoch': 2.2607833415964302}
2025-04-25 07:51:30,701 - INFO - Training metrics: {'loss': 0.5966, 'grad_norm': 1.9855464696884155, 'learning_rate': 3.0283832053246644e-06, 'epoch': 2.2607833415964302}
2025-04-25 07:54:28,204 - INFO - INFO: Training progress: {'loss': 0.6966, 'grad_norm': 1.4977164268493652, 'learning_rate': 2.951760687602313e-06, 'epoch': 2.270699058006941}
2025-04-25 07:54:28,205 - INFO - Training progress: {'loss': 0.6966, 'grad_norm': 1.4977164268493652, 'learning_rate': 2.951760687602313e-06, 'epoch': 2.270699058006941}
2025-04-25 07:54:28,205 - INFO - Training metrics: {'loss': 0.6966, 'grad_norm': 1.4977164268493652, 'learning_rate': 2.951760687602313e-06, 'epoch': 2.270699058006941}
2025-04-25 07:57:25,844 - INFO - INFO: Training progress: {'loss': 0.7413, 'grad_norm': 3.52377986907959, 'learning_rate': 2.875951789611734e-06, 'epoch': 2.280614774417452}
2025-04-25 07:57:25,844 - INFO - Training progress: {'loss': 0.7413, 'grad_norm': 3.52377986907959, 'learning_rate': 2.875951789611734e-06, 'epoch': 2.280614774417452}
2025-04-25 07:57:25,844 - INFO - Training metrics: {'loss': 0.7413, 'grad_norm': 3.52377986907959, 'learning_rate': 2.875951789611734e-06, 'epoch': 2.280614774417452}
2025-04-25 08:00:23,176 - INFO - INFO: Training progress: {'loss': 0.753, 'grad_norm': 3.2451422214508057, 'learning_rate': 2.8009652624200436e-06, 'epoch': 2.2905304908279622}
2025-04-25 08:00:23,176 - INFO - Training progress: {'loss': 0.753, 'grad_norm': 3.2451422214508057, 'learning_rate': 2.8009652624200436e-06, 'epoch': 2.2905304908279622}
2025-04-25 08:00:23,176 - INFO - Training metrics: {'loss': 0.753, 'grad_norm': 3.2451422214508057, 'learning_rate': 2.8009652624200436e-06, 'epoch': 2.2905304908279622}
2025-04-25 08:03:20,702 - INFO - INFO: Training progress: {'loss': 0.7138, 'grad_norm': 3.187623977661133, 'learning_rate': 2.7268097621632473e-06, 'epoch': 2.300446207238473}
2025-04-25 08:03:20,702 - INFO - Training progress: {'loss': 0.7138, 'grad_norm': 3.187623977661133, 'learning_rate': 2.7268097621632473e-06, 'epoch': 2.300446207238473}
2025-04-25 08:03:20,702 - INFO - Training metrics: {'loss': 0.7138, 'grad_norm': 3.187623977661133, 'learning_rate': 2.7268097621632473e-06, 'epoch': 2.300446207238473}
2025-04-25 08:06:17,964 - INFO - INFO: Training progress: {'loss': 0.5742, 'grad_norm': 1.8296881914138794, 'learning_rate': 2.653493849047033e-06, 'epoch': 2.3103619236489834}
2025-04-25 08:06:17,964 - INFO - Training progress: {'loss': 0.5742, 'grad_norm': 1.8296881914138794, 'learning_rate': 2.653493849047033e-06, 'epoch': 2.3103619236489834}
2025-04-25 08:06:17,964 - INFO - Training metrics: {'loss': 0.5742, 'grad_norm': 1.8296881914138794, 'learning_rate': 2.653493849047033e-06, 'epoch': 2.3103619236489834}
2025-04-25 08:09:15,286 - INFO - INFO: Training progress: {'loss': 0.7594, 'grad_norm': 2.001058578491211, 'learning_rate': 2.581025986358602e-06, 'epoch': 2.320277640059494}
2025-04-25 08:09:15,286 - INFO - Training progress: {'loss': 0.7594, 'grad_norm': 2.001058578491211, 'learning_rate': 2.581025986358602e-06, 'epoch': 2.320277640059494}
2025-04-25 08:09:15,286 - INFO - Training metrics: {'loss': 0.7594, 'grad_norm': 2.001058578491211, 'learning_rate': 2.581025986358602e-06, 'epoch': 2.320277640059494}
2025-04-25 08:12:12,834 - INFO - INFO: Training progress: {'loss': 0.7325, 'grad_norm': 2.14129376411438, 'learning_rate': 2.5094145394897087e-06, 'epoch': 2.330193356470005}
2025-04-25 08:12:12,834 - INFO - Training progress: {'loss': 0.7325, 'grad_norm': 2.14129376411438, 'learning_rate': 2.5094145394897087e-06, 'epoch': 2.330193356470005}
2025-04-25 08:12:12,834 - INFO - Training metrics: {'loss': 0.7325, 'grad_norm': 2.14129376411438, 'learning_rate': 2.5094145394897087e-06, 'epoch': 2.330193356470005}
2025-04-25 08:15:10,117 - INFO - INFO: Training progress: {'loss': 0.7103, 'grad_norm': 1.085726261138916, 'learning_rate': 2.438667774970981e-06, 'epoch': 2.340109072880516}
2025-04-25 08:15:10,117 - INFO - Training progress: {'loss': 0.7103, 'grad_norm': 1.085726261138916, 'learning_rate': 2.438667774970981e-06, 'epoch': 2.340109072880516}
2025-04-25 08:15:10,117 - INFO - Training metrics: {'loss': 0.7103, 'grad_norm': 1.085726261138916, 'learning_rate': 2.438667774970981e-06, 'epoch': 2.340109072880516}
2025-04-25 08:18:07,549 - INFO - INFO: Training progress: {'loss': 0.6327, 'grad_norm': 1.7638756036758423, 'learning_rate': 2.368793859517684e-06, 'epoch': 2.350024789291026}
2025-04-25 08:18:07,549 - INFO - Training progress: {'loss': 0.6327, 'grad_norm': 1.7638756036758423, 'learning_rate': 2.368793859517684e-06, 'epoch': 2.350024789291026}
2025-04-25 08:18:07,549 - INFO - Training metrics: {'loss': 0.6327, 'grad_norm': 1.7638756036758423, 'learning_rate': 2.368793859517684e-06, 'epoch': 2.350024789291026}
2025-04-25 08:21:04,985 - INFO - INFO: Training progress: {'loss': 0.6521, 'grad_norm': 1.6236636638641357, 'learning_rate': 2.2998008590869838e-06, 'epoch': 2.359940505701537}
2025-04-25 08:21:04,985 - INFO - Training progress: {'loss': 0.6521, 'grad_norm': 1.6236636638641357, 'learning_rate': 2.2998008590869838e-06, 'epoch': 2.359940505701537}
2025-04-25 08:21:04,985 - INFO - Training metrics: {'loss': 0.6521, 'grad_norm': 1.6236636638641357, 'learning_rate': 2.2998008590869838e-06, 'epoch': 2.359940505701537}
2025-04-25 08:24:02,198 - INFO - INFO: Training progress: {'loss': 0.6997, 'grad_norm': 2.083237648010254, 'learning_rate': 2.231696737946829e-06, 'epoch': 2.3698562221120474}
2025-04-25 08:24:02,198 - INFO - Training progress: {'loss': 0.6997, 'grad_norm': 2.083237648010254, 'learning_rate': 2.231696737946829e-06, 'epoch': 2.3698562221120474}
2025-04-25 08:24:02,198 - INFO - Training metrics: {'loss': 0.6997, 'grad_norm': 2.083237648010254, 'learning_rate': 2.231696737946829e-06, 'epoch': 2.3698562221120474}
2025-04-25 08:26:59,553 - INFO - INFO: Training progress: {'loss': 0.6492, 'grad_norm': 3.1065568923950195, 'learning_rate': 2.1644893577566118e-06, 'epoch': 2.379771938522558}
2025-04-25 08:26:59,553 - INFO - Training progress: {'loss': 0.6492, 'grad_norm': 3.1065568923950195, 'learning_rate': 2.1644893577566118e-06, 'epoch': 2.379771938522558}
2025-04-25 08:26:59,553 - INFO - Training metrics: {'loss': 0.6492, 'grad_norm': 3.1065568923950195, 'learning_rate': 2.1644893577566118e-06, 'epoch': 2.379771938522558}
2025-04-25 08:27:00,287 - INFO - INFO: Saving checkpoint at step 2400
2025-04-25 08:27:00,287 - INFO - Saving checkpoint at step 2400
2025-04-25 08:27:00,288 - INFO - Saving checkpoint at step 2400
2025-04-25 08:29:57,590 - INFO - INFO: Training progress: {'loss': 0.7634, 'grad_norm': 2.6494944095611572, 'learning_rate': 2.0981864766596406e-06, 'epoch': 2.389687654933069}
2025-04-25 08:29:57,590 - INFO - Training progress: {'loss': 0.7634, 'grad_norm': 2.6494944095611572, 'learning_rate': 2.0981864766596406e-06, 'epoch': 2.389687654933069}
2025-04-25 08:29:57,590 - INFO - Training metrics: {'loss': 0.7634, 'grad_norm': 2.6494944095611572, 'learning_rate': 2.0981864766596406e-06, 'epoch': 2.389687654933069}
2025-04-25 08:32:54,689 - INFO - INFO: Training progress: {'loss': 0.7919, 'grad_norm': 1.6850136518478394, 'learning_rate': 2.0327957483875693e-06, 'epoch': 2.39960337134358}
2025-04-25 08:32:54,689 - INFO - Training progress: {'loss': 0.7919, 'grad_norm': 1.6850136518478394, 'learning_rate': 2.0327957483875693e-06, 'epoch': 2.39960337134358}
2025-04-25 08:32:54,689 - INFO - Training metrics: {'loss': 0.7919, 'grad_norm': 1.6850136518478394, 'learning_rate': 2.0327957483875693e-06, 'epoch': 2.39960337134358}
2025-04-25 08:35:51,965 - INFO - INFO: Training progress: {'loss': 0.7295, 'grad_norm': 2.5879383087158203, 'learning_rate': 1.968324721376884e-06, 'epoch': 2.40951908775409}
2025-04-25 08:35:51,965 - INFO - Training progress: {'loss': 0.7295, 'grad_norm': 2.5879383087158203, 'learning_rate': 1.968324721376884e-06, 'epoch': 2.40951908775409}
2025-04-25 08:35:51,965 - INFO - Training metrics: {'loss': 0.7295, 'grad_norm': 2.5879383087158203, 'learning_rate': 1.968324721376884e-06, 'epoch': 2.40951908775409}
2025-04-25 08:38:49,259 - INFO - INFO: Training progress: {'loss': 0.7281, 'grad_norm': 3.1085288524627686, 'learning_rate': 1.9047808378975485e-06, 'epoch': 2.419434804164601}
2025-04-25 08:38:49,259 - INFO - Training progress: {'loss': 0.7281, 'grad_norm': 3.1085288524627686, 'learning_rate': 1.9047808378975485e-06, 'epoch': 2.419434804164601}
2025-04-25 08:38:49,260 - INFO - Training metrics: {'loss': 0.7281, 'grad_norm': 3.1085288524627686, 'learning_rate': 1.9047808378975485e-06, 'epoch': 2.419434804164601}
2025-04-25 08:41:46,562 - INFO - INFO: Training progress: {'loss': 0.7099, 'grad_norm': 2.7773427963256836, 'learning_rate': 1.8421714331938845e-06, 'epoch': 2.4293505205751114}
2025-04-25 08:41:46,562 - INFO - Training progress: {'loss': 0.7099, 'grad_norm': 2.7773427963256836, 'learning_rate': 1.8421714331938845e-06, 'epoch': 2.4293505205751114}
2025-04-25 08:41:46,562 - INFO - Training metrics: {'loss': 0.7099, 'grad_norm': 2.7773427963256836, 'learning_rate': 1.8421714331938845e-06, 'epoch': 2.4293505205751114}
2025-04-25 08:58:38,771 - INFO - INFO: Training progress: {'eval_loss': 0.7449567317962646, 'eval_runtime': 1012.2062, 'eval_samples_per_second': 1.842, 'eval_steps_per_second': 1.842, 'epoch': 2.4293505205751114}
2025-04-25 08:58:38,772 - INFO - Training progress: {'eval_loss': 0.7449567317962646, 'eval_runtime': 1012.2062, 'eval_samples_per_second': 1.842, 'eval_steps_per_second': 1.842, 'epoch': 2.4293505205751114}
2025-04-25 08:58:38,772 - INFO - Training metrics: {'eval_loss': 0.7449567317962646, 'eval_runtime': 1012.2062, 'eval_samples_per_second': 1.842, 'eval_steps_per_second': 1.842, 'epoch': 2.4293505205751114}
2025-04-25 09:01:36,490 - INFO - INFO: Training progress: {'loss': 0.8197, 'grad_norm': 3.126828193664551, 'learning_rate': 1.7805037346378384e-06, 'epoch': 2.439266236985622}
2025-04-25 09:01:36,490 - INFO - Training progress: {'loss': 0.8197, 'grad_norm': 3.126828193664551, 'learning_rate': 1.7805037346378384e-06, 'epoch': 2.439266236985622}
2025-04-25 09:01:36,490 - INFO - Training metrics: {'loss': 0.8197, 'grad_norm': 3.126828193664551, 'learning_rate': 1.7805037346378384e-06, 'epoch': 2.439266236985622}
2025-04-25 09:04:33,724 - INFO - INFO: Training progress: {'loss': 0.6791, 'grad_norm': 2.263254165649414, 'learning_rate': 1.7197848608946722e-06, 'epoch': 2.449181953396133}
2025-04-25 09:04:33,724 - INFO - Training progress: {'loss': 0.6791, 'grad_norm': 2.263254165649414, 'learning_rate': 1.7197848608946722e-06, 'epoch': 2.449181953396133}
2025-04-25 09:04:33,724 - INFO - Training metrics: {'loss': 0.6791, 'grad_norm': 2.263254165649414, 'learning_rate': 1.7197848608946722e-06, 'epoch': 2.449181953396133}
2025-04-25 09:07:31,077 - INFO - INFO: Training progress: {'loss': 0.7137, 'grad_norm': 2.434612512588501, 'learning_rate': 1.660021821101222e-06, 'epoch': 2.4590976698066433}
2025-04-25 09:07:31,077 - INFO - Training progress: {'loss': 0.7137, 'grad_norm': 2.434612512588501, 'learning_rate': 1.660021821101222e-06, 'epoch': 2.4590976698066433}
2025-04-25 09:07:31,077 - INFO - Training metrics: {'loss': 0.7137, 'grad_norm': 2.434612512588501, 'learning_rate': 1.660021821101222e-06, 'epoch': 2.4590976698066433}
2025-04-25 09:10:28,362 - INFO - INFO: Training progress: {'loss': 0.7037, 'grad_norm': 3.0292537212371826, 'learning_rate': 1.6012215140567789e-06, 'epoch': 2.469013386217154}
2025-04-25 09:10:28,362 - INFO - Training progress: {'loss': 0.7037, 'grad_norm': 3.0292537212371826, 'learning_rate': 1.6012215140567789e-06, 'epoch': 2.469013386217154}
2025-04-25 09:10:28,362 - INFO - Training metrics: {'loss': 0.7037, 'grad_norm': 3.0292537212371826, 'learning_rate': 1.6012215140567789e-06, 'epoch': 2.469013386217154}
2025-04-25 09:13:25,829 - INFO - INFO: Training progress: {'loss': 0.6542, 'grad_norm': 1.6884019374847412, 'learning_rate': 1.5433907274267357e-06, 'epoch': 2.478929102627665}
2025-04-25 09:13:25,830 - INFO - Training progress: {'loss': 0.6542, 'grad_norm': 1.6884019374847412, 'learning_rate': 1.5433907274267357e-06, 'epoch': 2.478929102627665}
2025-04-25 09:13:25,830 - INFO - Training metrics: {'loss': 0.6542, 'grad_norm': 1.6884019374847412, 'learning_rate': 1.5433907274267357e-06, 'epoch': 2.478929102627665}
2025-04-25 09:16:25,823 - INFO - INFO: Training progress: {'loss': 0.5911, 'grad_norm': 1.682489275932312, 'learning_rate': 1.4865361369590392e-06, 'epoch': 2.4888448190381753}
2025-04-25 09:16:25,823 - INFO - Training progress: {'loss': 0.5911, 'grad_norm': 1.682489275932312, 'learning_rate': 1.4865361369590392e-06, 'epoch': 2.4888448190381753}
2025-04-25 09:16:25,823 - INFO - Training metrics: {'loss': 0.5911, 'grad_norm': 1.682489275932312, 'learning_rate': 1.4865361369590392e-06, 'epoch': 2.4888448190381753}
2025-04-25 09:19:27,914 - INFO - INFO: Training progress: {'loss': 0.5866, 'grad_norm': 1.7671079635620117, 'learning_rate': 1.4306643057135638e-06, 'epoch': 2.498760535448686}
2025-04-25 09:19:27,915 - INFO - Training progress: {'loss': 0.5866, 'grad_norm': 1.7671079635620117, 'learning_rate': 1.4306643057135638e-06, 'epoch': 2.498760535448686}
2025-04-25 09:19:27,915 - INFO - Training metrics: {'loss': 0.5866, 'grad_norm': 1.7671079635620117, 'learning_rate': 1.4306643057135638e-06, 'epoch': 2.498760535448686}
2025-04-25 09:22:26,623 - INFO - INFO: Training progress: {'loss': 0.7192, 'grad_norm': 1.787898063659668, 'learning_rate': 1.3757816833045123e-06, 'epoch': 2.508676251859197}
2025-04-25 09:22:26,623 - INFO - Training progress: {'loss': 0.7192, 'grad_norm': 1.787898063659668, 'learning_rate': 1.3757816833045123e-06, 'epoch': 2.508676251859197}
2025-04-25 09:22:26,623 - INFO - Training metrics: {'loss': 0.7192, 'grad_norm': 1.787898063659668, 'learning_rate': 1.3757816833045123e-06, 'epoch': 2.508676251859197}
2025-04-25 09:25:24,863 - INFO - INFO: Training progress: {'loss': 0.6073, 'grad_norm': 2.0886294841766357, 'learning_rate': 1.3218946051558867e-06, 'epoch': 2.5185919682697073}
2025-04-25 09:25:24,863 - INFO - Training progress: {'loss': 0.6073, 'grad_norm': 2.0886294841766357, 'learning_rate': 1.3218946051558867e-06, 'epoch': 2.5185919682697073}
2025-04-25 09:25:24,863 - INFO - Training metrics: {'loss': 0.6073, 'grad_norm': 2.0886294841766357, 'learning_rate': 1.3218946051558867e-06, 'epoch': 2.5185919682697073}
2025-04-25 09:28:23,090 - INFO - INFO: Training progress: {'loss': 0.6949, 'grad_norm': 2.766666889190674, 'learning_rate': 1.2690092917701636e-06, 'epoch': 2.528507684680218}
2025-04-25 09:28:23,090 - INFO - Training progress: {'loss': 0.6949, 'grad_norm': 2.766666889190674, 'learning_rate': 1.2690092917701636e-06, 'epoch': 2.528507684680218}
2025-04-25 09:28:23,090 - INFO - Training metrics: {'loss': 0.6949, 'grad_norm': 2.766666889190674, 'learning_rate': 1.2690092917701636e-06, 'epoch': 2.528507684680218}
2025-04-25 09:31:25,906 - INFO - INFO: Training progress: {'loss': 0.6538, 'grad_norm': 2.2145824432373047, 'learning_rate': 1.217131848010209e-06, 'epoch': 2.538423401090729}
2025-04-25 09:31:25,907 - INFO - Training progress: {'loss': 0.6538, 'grad_norm': 2.2145824432373047, 'learning_rate': 1.217131848010209e-06, 'epoch': 2.538423401090729}
2025-04-25 09:31:25,907 - INFO - Training metrics: {'loss': 0.6538, 'grad_norm': 2.2145824432373047, 'learning_rate': 1.217131848010209e-06, 'epoch': 2.538423401090729}
2025-04-25 09:34:27,063 - INFO - INFO: Training progress: {'loss': 0.6821, 'grad_norm': 2.3744139671325684, 'learning_rate': 1.1662682623945753e-06, 'epoch': 2.5483391175012393}
2025-04-25 09:34:27,063 - INFO - Training progress: {'loss': 0.6821, 'grad_norm': 2.3744139671325684, 'learning_rate': 1.1662682623945753e-06, 'epoch': 2.5483391175012393}
2025-04-25 09:34:27,063 - INFO - Training metrics: {'loss': 0.6821, 'grad_norm': 2.3744139671325684, 'learning_rate': 1.1662682623945753e-06, 'epoch': 2.5483391175012393}
2025-04-25 09:37:30,884 - INFO - INFO: Training progress: {'loss': 0.6338, 'grad_norm': 1.5773552656173706, 'learning_rate': 1.1164244064062101e-06, 'epoch': 2.55825483391175}
2025-04-25 09:37:30,885 - INFO - Training progress: {'loss': 0.6338, 'grad_norm': 1.5773552656173706, 'learning_rate': 1.1164244064062101e-06, 'epoch': 2.55825483391175}
2025-04-25 09:37:30,885 - INFO - Training metrics: {'loss': 0.6338, 'grad_norm': 1.5773552656173706, 'learning_rate': 1.1164244064062101e-06, 'epoch': 2.55825483391175}
2025-04-25 09:40:32,113 - INFO - INFO: Training progress: {'loss': 0.8352, 'grad_norm': 1.7276183366775513, 'learning_rate': 1.0676060338146555e-06, 'epoch': 2.568170550322261}
2025-04-25 09:40:32,113 - INFO - Training progress: {'loss': 0.8352, 'grad_norm': 1.7276183366775513, 'learning_rate': 1.0676060338146555e-06, 'epoch': 2.568170550322261}
2025-04-25 09:40:32,114 - INFO - Training metrics: {'loss': 0.8352, 'grad_norm': 1.7276183366775513, 'learning_rate': 1.0676060338146555e-06, 'epoch': 2.568170550322261}
2025-04-25 09:43:32,566 - INFO - INFO: Training progress: {'loss': 0.6142, 'grad_norm': 2.798150062561035, 'learning_rate': 1.0198187800118842e-06, 'epoch': 2.5780862667327713}
2025-04-25 09:43:32,566 - INFO - Training progress: {'loss': 0.6142, 'grad_norm': 2.798150062561035, 'learning_rate': 1.0198187800118842e-06, 'epoch': 2.5780862667327713}
2025-04-25 09:43:32,566 - INFO - Training metrics: {'loss': 0.6142, 'grad_norm': 2.798150062561035, 'learning_rate': 1.0198187800118842e-06, 'epoch': 2.5780862667327713}
2025-04-25 09:43:33,319 - INFO - INFO: Saving checkpoint at step 2600
2025-04-25 09:43:33,319 - INFO - Saving checkpoint at step 2600
2025-04-25 09:43:33,320 - INFO - Saving checkpoint at step 2600
2025-04-25 09:46:33,567 - INFO - INFO: Training progress: {'loss': 0.761, 'grad_norm': 1.8630696535110474, 'learning_rate': 9.730681613617577e-07, 'epoch': 2.588001983143282}
2025-04-25 09:46:33,568 - INFO - Training progress: {'loss': 0.761, 'grad_norm': 1.8630696535110474, 'learning_rate': 9.730681613617577e-07, 'epoch': 2.588001983143282}
2025-04-25 09:46:33,568 - INFO - Training metrics: {'loss': 0.761, 'grad_norm': 1.8630696535110474, 'learning_rate': 9.730681613617577e-07, 'epoch': 2.588001983143282}
2025-04-25 09:49:40,937 - INFO - INFO: Training progress: {'loss': 0.6505, 'grad_norm': 2.8200337886810303, 'learning_rate': 9.27359574563238e-07, 'epoch': 2.597917699553793}
2025-04-25 09:49:40,938 - INFO - Training progress: {'loss': 0.6505, 'grad_norm': 2.8200337886810303, 'learning_rate': 9.27359574563238e-07, 'epoch': 2.597917699553793}
2025-04-25 09:49:40,938 - INFO - Training metrics: {'loss': 0.6505, 'grad_norm': 2.8200337886810303, 'learning_rate': 9.27359574563238e-07, 'epoch': 2.597917699553793}
2025-04-25 09:52:42,945 - INFO - INFO: Training progress: {'loss': 0.6623, 'grad_norm': 2.116865873336792, 'learning_rate': 8.826982960274244e-07, 'epoch': 2.6078334159643033}
2025-04-25 09:52:42,945 - INFO - Training progress: {'loss': 0.6623, 'grad_norm': 2.116865873336792, 'learning_rate': 8.826982960274244e-07, 'epoch': 2.6078334159643033}
2025-04-25 09:52:42,945 - INFO - Training metrics: {'loss': 0.6623, 'grad_norm': 2.116865873336792, 'learning_rate': 8.826982960274244e-07, 'epoch': 2.6078334159643033}
2025-04-25 09:55:44,784 - INFO - INFO: Training progress: {'loss': 0.628, 'grad_norm': 3.490833282470703, 'learning_rate': 8.390894812684602e-07, 'epoch': 2.617749132374814}
2025-04-25 09:55:44,784 - INFO - Training progress: {'loss': 0.628, 'grad_norm': 3.490833282470703, 'learning_rate': 8.390894812684602e-07, 'epoch': 2.617749132374814}
2025-04-25 09:55:44,784 - INFO - Training metrics: {'loss': 0.628, 'grad_norm': 3.490833282470703, 'learning_rate': 8.390894812684602e-07, 'epoch': 2.617749132374814}
2025-04-25 09:58:44,769 - INFO - INFO: Training progress: {'loss': 0.7352, 'grad_norm': 3.236455202102661, 'learning_rate': 7.965381643084069e-07, 'epoch': 2.627664848785325}
2025-04-25 09:58:44,769 - INFO - Training progress: {'loss': 0.7352, 'grad_norm': 3.236455202102661, 'learning_rate': 7.965381643084069e-07, 'epoch': 2.627664848785325}
2025-04-25 09:58:44,769 - INFO - Training metrics: {'loss': 0.7352, 'grad_norm': 3.236455202102661, 'learning_rate': 7.965381643084069e-07, 'epoch': 2.627664848785325}
2025-04-25 10:01:42,813 - INFO - INFO: Training progress: {'loss': 0.6905, 'grad_norm': 3.07289457321167, 'learning_rate': 7.550492570961243e-07, 'epoch': 2.6375805651958353}
2025-04-25 10:01:42,814 - INFO - Training progress: {'loss': 0.6905, 'grad_norm': 3.07289457321167, 'learning_rate': 7.550492570961243e-07, 'epoch': 2.6375805651958353}
2025-04-25 10:01:42,814 - INFO - Training metrics: {'loss': 0.6905, 'grad_norm': 3.07289457321167, 'learning_rate': 7.550492570961243e-07, 'epoch': 2.6375805651958353}
2025-04-25 10:04:41,421 - INFO - INFO: Training progress: {'loss': 0.5668, 'grad_norm': 2.164675235748291, 'learning_rate': 7.146275489402721e-07, 'epoch': 2.647496281606346}
2025-04-25 10:04:41,422 - INFO - Training progress: {'loss': 0.5668, 'grad_norm': 2.164675235748291, 'learning_rate': 7.146275489402721e-07, 'epoch': 2.647496281606346}
2025-04-25 10:04:41,422 - INFO - Training metrics: {'loss': 0.5668, 'grad_norm': 2.164675235748291, 'learning_rate': 7.146275489402721e-07, 'epoch': 2.647496281606346}
2025-04-25 10:07:39,958 - INFO - INFO: Training progress: {'loss': 0.7089, 'grad_norm': 2.3995320796966553, 'learning_rate': 6.752777059564431e-07, 'epoch': 2.6574119980168565}
2025-04-25 10:07:39,958 - INFO - Training progress: {'loss': 0.7089, 'grad_norm': 2.3995320796966553, 'learning_rate': 6.752777059564431e-07, 'epoch': 2.6574119980168565}
2025-04-25 10:07:39,958 - INFO - Training metrics: {'loss': 0.7089, 'grad_norm': 2.3995320796966553, 'learning_rate': 6.752777059564431e-07, 'epoch': 2.6574119980168565}
2025-04-25 10:10:38,469 - INFO - INFO: Training progress: {'loss': 0.6339, 'grad_norm': 2.4284493923187256, 'learning_rate': 6.370042705285229e-07, 'epoch': 2.6673277144273673}
2025-04-25 10:10:38,469 - INFO - Training progress: {'loss': 0.6339, 'grad_norm': 2.4284493923187256, 'learning_rate': 6.370042705285229e-07, 'epoch': 2.6673277144273673}
2025-04-25 10:10:38,469 - INFO - Training metrics: {'loss': 0.6339, 'grad_norm': 2.4284493923187256, 'learning_rate': 6.370042705285229e-07, 'epoch': 2.6673277144273673}
2025-04-25 10:13:36,544 - INFO - INFO: Training progress: {'loss': 0.7494, 'grad_norm': 2.190843105316162, 'learning_rate': 5.99811660784344e-07, 'epoch': 2.677243430837878}
2025-04-25 10:13:36,545 - INFO - Training progress: {'loss': 0.7494, 'grad_norm': 2.190843105316162, 'learning_rate': 5.99811660784344e-07, 'epoch': 2.677243430837878}
2025-04-25 10:13:36,545 - INFO - Training metrics: {'loss': 0.7494, 'grad_norm': 2.190843105316162, 'learning_rate': 5.99811660784344e-07, 'epoch': 2.677243430837878}
2025-04-25 10:16:34,580 - INFO - INFO: Training progress: {'loss': 0.6129, 'grad_norm': 2.4932961463928223, 'learning_rate': 5.637041700856705e-07, 'epoch': 2.687159147248389}
2025-04-25 10:16:34,581 - INFO - Training progress: {'loss': 0.6129, 'grad_norm': 2.4932961463928223, 'learning_rate': 5.637041700856705e-07, 'epoch': 2.687159147248389}
2025-04-25 10:16:34,581 - INFO - Training metrics: {'loss': 0.6129, 'grad_norm': 2.4932961463928223, 'learning_rate': 5.637041700856705e-07, 'epoch': 2.687159147248389}
2025-04-25 10:19:32,641 - INFO - INFO: Training progress: {'loss': 0.6841, 'grad_norm': 1.9702728986740112, 'learning_rate': 5.286859665325905e-07, 'epoch': 2.6970748636588993}
2025-04-25 10:19:32,641 - INFO - Training progress: {'loss': 0.6841, 'grad_norm': 1.9702728986740112, 'learning_rate': 5.286859665325905e-07, 'epoch': 2.6970748636588993}
2025-04-25 10:19:32,641 - INFO - Training metrics: {'loss': 0.6841, 'grad_norm': 1.9702728986740112, 'learning_rate': 5.286859665325905e-07, 'epoch': 2.6970748636588993}
2025-04-25 10:22:30,702 - INFO - INFO: Training progress: {'loss': 0.5449, 'grad_norm': 1.614729881286621, 'learning_rate': 4.947610924823643e-07, 'epoch': 2.70699058006941}
2025-04-25 10:22:30,702 - INFO - Training progress: {'loss': 0.5449, 'grad_norm': 1.614729881286621, 'learning_rate': 4.947610924823643e-07, 'epoch': 2.70699058006941}
2025-04-25 10:22:30,702 - INFO - Training metrics: {'loss': 0.5449, 'grad_norm': 1.614729881286621, 'learning_rate': 4.947610924823643e-07, 'epoch': 2.70699058006941}
2025-04-25 10:25:28,532 - INFO - INFO: Training progress: {'loss': 0.7179, 'grad_norm': 2.5228466987609863, 'learning_rate': 4.6193346408280216e-07, 'epoch': 2.7169062964799204}
2025-04-25 10:25:28,533 - INFO - Training progress: {'loss': 0.7179, 'grad_norm': 2.5228466987609863, 'learning_rate': 4.6193346408280216e-07, 'epoch': 2.7169062964799204}
2025-04-25 10:25:28,533 - INFO - Training metrics: {'loss': 0.7179, 'grad_norm': 2.5228466987609863, 'learning_rate': 4.6193346408280216e-07, 'epoch': 2.7169062964799204}
2025-04-25 10:28:26,533 - INFO - INFO: Training progress: {'loss': 0.6411, 'grad_norm': 1.643210530281067, 'learning_rate': 4.302068708201912e-07, 'epoch': 2.7268220128904312}
2025-04-25 10:28:26,534 - INFO - Training progress: {'loss': 0.6411, 'grad_norm': 1.643210530281067, 'learning_rate': 4.302068708201912e-07, 'epoch': 2.7268220128904312}
2025-04-25 10:28:26,534 - INFO - Training metrics: {'loss': 0.6411, 'grad_norm': 1.643210530281067, 'learning_rate': 4.302068708201912e-07, 'epoch': 2.7268220128904312}
2025-04-25 10:31:24,480 - INFO - INFO: Training progress: {'loss': 0.6744, 'grad_norm': 1.4056233167648315, 'learning_rate': 3.9958497508185036e-07, 'epoch': 2.736737729300942}
2025-04-25 10:31:24,480 - INFO - Training progress: {'loss': 0.6744, 'grad_norm': 1.4056233167648315, 'learning_rate': 3.9958497508185036e-07, 'epoch': 2.736737729300942}
2025-04-25 10:31:24,480 - INFO - Training metrics: {'loss': 0.6744, 'grad_norm': 1.4056233167648315, 'learning_rate': 3.9958497508185036e-07, 'epoch': 2.736737729300942}
2025-04-25 10:34:22,359 - INFO - INFO: Training progress: {'loss': 0.6419, 'grad_norm': 2.549421787261963, 'learning_rate': 3.7007131173336766e-07, 'epoch': 2.746653445711453}
2025-04-25 10:34:22,359 - INFO - Training progress: {'loss': 0.6419, 'grad_norm': 2.549421787261963, 'learning_rate': 3.7007131173336766e-07, 'epoch': 2.746653445711453}
2025-04-25 10:34:22,359 - INFO - Training metrics: {'loss': 0.6419, 'grad_norm': 2.549421787261963, 'learning_rate': 3.7007131173336766e-07, 'epoch': 2.746653445711453}
2025-04-25 10:37:20,504 - INFO - INFO: Training progress: {'loss': 0.6639, 'grad_norm': 1.602239966392517, 'learning_rate': 3.4166928771054653e-07, 'epoch': 2.7565691621219632}
2025-04-25 10:37:20,504 - INFO - Training progress: {'loss': 0.6639, 'grad_norm': 1.602239966392517, 'learning_rate': 3.4166928771054653e-07, 'epoch': 2.7565691621219632}
2025-04-25 10:37:20,504 - INFO - Training metrics: {'loss': 0.6639, 'grad_norm': 1.602239966392517, 'learning_rate': 3.4166928771054653e-07, 'epoch': 2.7565691621219632}
2025-04-25 10:40:18,293 - INFO - INFO: Training progress: {'loss': 0.6979, 'grad_norm': 2.527963161468506, 'learning_rate': 3.1438218162612057e-07, 'epoch': 2.766484878532474}
2025-04-25 10:40:18,293 - INFO - Training progress: {'loss': 0.6979, 'grad_norm': 2.527963161468506, 'learning_rate': 3.1438218162612057e-07, 'epoch': 2.766484878532474}
2025-04-25 10:40:18,293 - INFO - Training metrics: {'loss': 0.6979, 'grad_norm': 2.527963161468506, 'learning_rate': 3.1438218162612057e-07, 'epoch': 2.766484878532474}
2025-04-25 12:02:32,882 - INFO - INFO: File logger setup to write to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\logging.txt
2025-04-25 12:02:32,883 - INFO - 

==================================================
2025-04-25 12:02:32,883 - INFO - Resuming from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:02:32,883 - INFO - ==================================================

2025-04-25 12:02:32,883 - INFO - Starting unsupervised fine-tuning with parameters: {'mode': 'unsupervised', 'data_path': 'N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets', 'text_column': 'text', 'use_checkpoint': True, 'checkpoint_path': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600', 'max_samples': None, 'pre_eval': False, 'eval_split': 0, 'model_path': 'C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1', 'output_dir': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2', 'logging_dir': None, 'use_flash_attention': True, 'max_length': 3000, 'chunk_size': None, 'quantization_config': {'load_in_8bit': True}, 'peft_config': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'inference_mode': False, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'w2']}, 'training_config': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'warmup_steps': 100, 'warmup_ratio': 0.03, 'logging_steps': 10, 'save_steps': 200, 'save_total_limit': 3, 'eval_strategy': 'steps', 'eval_steps': 350, 'per_device_eval_batch_size': 1, 'eval_accumulation_steps': 4, 'fp16': True, 'lr_scheduler_type': 'cosine', 'weight_decay': 0.01, 'gradient_checkpointing': True, 'report_to': 'none', 'disable_tqdm': False, 'max_grad_norm': 0.3, 'dataloader_num_workers': 2}}
2025-04-25 12:02:32,883 - INFO - INFO: Loading datasets from individual JSONL files
2025-04-25 12:02:32,883 - INFO - Loading datasets from individual JSONL files
2025-04-25 12:02:32,976 - INFO - INFO: Loaded 8068 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\training_set.jsonl
2025-04-25 12:02:33,056 - INFO - INFO: Loaded 1864 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\validation_set.jsonl
2025-04-25 12:02:33,081 - INFO - INFO: Loaded separate validation set with 1864 examples
2025-04-25 12:02:33,081 - INFO - Loaded separate validation set with 1864 examples
2025-04-25 12:02:33,098 - INFO - INFO: Loaded 1298 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\test_set.jsonl
2025-04-25 12:02:33,108 - INFO - INFO: Loaded separate test set with 1298 examples
2025-04-25 12:02:33,108 - INFO - Loaded separate test set with 1298 examples
2025-04-25 12:02:33,654 - INFO - INFO: Tokenizer vocabulary size: 128256
2025-04-25 12:02:33,655 - INFO - INFO: Model max length: 1000000000000000019884624838656
2025-04-25 12:02:42,253 - INFO - INFO: Dataset prepared with 8068 examples
2025-04-25 12:02:44,150 - INFO - INFO: Dataset prepared with 1864 examples
2025-04-25 12:02:46,008 - INFO - INFO: Dataset prepared with 1298 examples
2025-04-25 12:02:46,021 - INFO - INFO: CUDA cache cleared
2025-04-25 12:02:46,152 - INFO - INFO: Garbage collector freed 70 objects
2025-04-25 12:03:16,724 - INFO - INFO: Model loaded from C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1
2025-04-25 12:03:16,726 - INFO - INFO: Model has 8030261248 parameters, 0 are trainable (0.00%)
2025-04-25 12:03:17,492 - INFO - INFO: Model has 41943040 trainable parameters after PEFT configuration
2025-04-25 12:03:17,567 - INFO - Starting model training with 8068 training examples
2025-04-25 12:03:17,567 - INFO - Using 1864 examples for validation during training
2025-04-25 12:03:17,568 - INFO - Using 1298 examples for pre/final evaluation
2025-04-25 12:03:17,660 - INFO - INFO: Starting training...
2025-04-25 12:03:17,660 - INFO - Starting training...
2025-04-25 12:03:17,661 - INFO - Starting training...
2025-04-25 12:03:17,661 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:03:17,662 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:03:17,662 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:03:17,662 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:03:18,432 - INFO - INFO: Starting epoch 2.5780862667327713/3
2025-04-25 12:03:18,432 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:03:18,432 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:03:26,511 - INFO - ERROR: Training failed with error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([_reconstruct])` or the `torch.serialization.safe_globals([_reconstruct])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:03:26,511 - INFO - INFO: Training failed with error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([_reconstruct])` or the `torch.serialization.safe_globals([_reconstruct])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:03:26,511 - INFO - Training failed with error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([_reconstruct])` or the `torch.serialization.safe_globals([_reconstruct])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:03:26,511 - INFO - Training failed with error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([_reconstruct])` or the `torch.serialization.safe_globals([_reconstruct])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:06:48,121 - INFO - INFO: File logger setup to write to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\logging.txt
2025-04-25 12:06:48,121 - INFO - 

==================================================
2025-04-25 12:06:48,121 - INFO - Resuming from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:06:48,121 - INFO - ==================================================

2025-04-25 12:06:48,121 - INFO - Starting unsupervised fine-tuning with parameters: {'mode': 'unsupervised', 'data_path': 'N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets', 'text_column': 'text', 'use_checkpoint': True, 'checkpoint_path': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600', 'max_samples': None, 'pre_eval': False, 'eval_split': 0, 'model_path': 'C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1', 'output_dir': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2', 'logging_dir': None, 'use_flash_attention': True, 'max_length': 3000, 'chunk_size': None, 'quantization_config': {'load_in_8bit': True}, 'peft_config': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'inference_mode': False, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'w2']}, 'training_config': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'warmup_steps': 100, 'warmup_ratio': 0.03, 'logging_steps': 10, 'save_steps': 200, 'save_total_limit': 3, 'eval_strategy': 'steps', 'eval_steps': 350, 'per_device_eval_batch_size': 1, 'eval_accumulation_steps': 4, 'fp16': True, 'lr_scheduler_type': 'cosine', 'weight_decay': 0.01, 'gradient_checkpointing': True, 'report_to': 'none', 'disable_tqdm': False, 'max_grad_norm': 0.3, 'dataloader_num_workers': 2}}
2025-04-25 12:06:48,121 - INFO - INFO: Loading datasets from individual JSONL files
2025-04-25 12:06:48,121 - INFO - Loading datasets from individual JSONL files
2025-04-25 12:06:48,178 - INFO - INFO: Loaded 8068 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\training_set.jsonl
2025-04-25 12:06:48,231 - INFO - INFO: Loaded 1864 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\validation_set.jsonl
2025-04-25 12:06:48,241 - INFO - INFO: Loaded separate validation set with 1864 examples
2025-04-25 12:06:48,241 - INFO - Loaded separate validation set with 1864 examples
2025-04-25 12:06:48,250 - INFO - INFO: Loaded 1298 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\test_set.jsonl
2025-04-25 12:06:48,254 - INFO - INFO: Loaded separate test set with 1298 examples
2025-04-25 12:06:48,254 - INFO - Loaded separate test set with 1298 examples
2025-04-25 12:06:48,753 - INFO - INFO: Tokenizer vocabulary size: 128256
2025-04-25 12:06:48,753 - INFO - INFO: Model max length: 1000000000000000019884624838656
2025-04-25 12:06:56,288 - INFO - INFO: Dataset prepared with 8068 examples
2025-04-25 12:06:58,090 - INFO - INFO: Dataset prepared with 1864 examples
2025-04-25 12:06:59,354 - INFO - INFO: Dataset prepared with 1298 examples
2025-04-25 12:06:59,359 - INFO - INFO: CUDA cache cleared
2025-04-25 12:06:59,471 - INFO - INFO: Garbage collector freed 70 objects
2025-04-25 12:07:07,995 - INFO - INFO: Model loaded from C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1
2025-04-25 12:07:07,995 - INFO - INFO: Model has 8030261248 parameters, 0 are trainable (0.00%)
2025-04-25 12:07:08,605 - INFO - INFO: Model has 41943040 trainable parameters after PEFT configuration
2025-04-25 12:07:08,647 - INFO - Starting model training with 8068 training examples
2025-04-25 12:07:08,647 - INFO - Using 1864 examples for validation during training
2025-04-25 12:07:08,647 - INFO - Using 1298 examples for pre/final evaluation
2025-04-25 12:07:08,670 - INFO - INFO: Starting training...
2025-04-25 12:07:08,670 - INFO - Starting training...
2025-04-25 12:07:08,670 - INFO - Starting training...
2025-04-25 12:07:08,670 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:07:08,670 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:07:08,670 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:07:08,670 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:07:09,374 - INFO - INFO: Starting epoch 2.5780862667327713/3
2025-04-25 12:07:09,374 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:07:09,374 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:07:17,481 - INFO - ERROR: Training failed with error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.ndarray was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ndarray])` or the `torch.serialization.safe_globals([ndarray])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:07:17,481 - INFO - INFO: Training failed with error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.ndarray was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ndarray])` or the `torch.serialization.safe_globals([ndarray])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:07:17,481 - INFO - Training failed with error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.ndarray was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ndarray])` or the `torch.serialization.safe_globals([ndarray])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:07:17,481 - INFO - Training failed with error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.ndarray was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ndarray])` or the `torch.serialization.safe_globals([ndarray])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:12:05,407 - INFO - INFO: File logger setup to write to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\logging.txt
2025-04-25 12:12:05,408 - INFO - 

==================================================
2025-04-25 12:12:05,408 - INFO - Resuming from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:12:05,408 - INFO - ==================================================

2025-04-25 12:12:05,408 - INFO - Starting unsupervised fine-tuning with parameters: {'mode': 'unsupervised', 'data_path': 'N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets', 'text_column': 'text', 'use_checkpoint': True, 'checkpoint_path': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600', 'max_samples': None, 'pre_eval': False, 'eval_split': 0, 'model_path': 'C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1', 'output_dir': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2', 'logging_dir': None, 'use_flash_attention': True, 'max_length': 3000, 'chunk_size': None, 'quantization_config': {'load_in_8bit': True}, 'peft_config': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'inference_mode': False, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'w2']}, 'training_config': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'warmup_steps': 100, 'warmup_ratio': 0.03, 'logging_steps': 10, 'save_steps': 200, 'save_total_limit': 3, 'eval_strategy': 'steps', 'eval_steps': 350, 'per_device_eval_batch_size': 1, 'eval_accumulation_steps': 4, 'fp16': True, 'lr_scheduler_type': 'cosine', 'weight_decay': 0.01, 'gradient_checkpointing': True, 'report_to': 'none', 'disable_tqdm': False, 'max_grad_norm': 0.3, 'dataloader_num_workers': 2}}
2025-04-25 12:12:05,408 - INFO - INFO: Loading datasets from individual JSONL files
2025-04-25 12:12:05,408 - INFO - Loading datasets from individual JSONL files
2025-04-25 12:12:05,461 - INFO - INFO: Loaded 8068 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\training_set.jsonl
2025-04-25 12:12:05,513 - INFO - INFO: Loaded 1864 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\validation_set.jsonl
2025-04-25 12:12:05,518 - INFO - INFO: Loaded separate validation set with 1864 examples
2025-04-25 12:12:05,518 - INFO - Loaded separate validation set with 1864 examples
2025-04-25 12:12:05,531 - INFO - INFO: Loaded 1298 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\test_set.jsonl
2025-04-25 12:12:05,540 - INFO - INFO: Loaded separate test set with 1298 examples
2025-04-25 12:12:05,540 - INFO - Loaded separate test set with 1298 examples
2025-04-25 12:12:06,047 - INFO - INFO: Tokenizer vocabulary size: 128256
2025-04-25 12:12:06,047 - INFO - INFO: Model max length: 1000000000000000019884624838656
2025-04-25 12:12:13,557 - INFO - INFO: Dataset prepared with 8068 examples
2025-04-25 12:12:15,267 - INFO - INFO: Dataset prepared with 1864 examples
2025-04-25 12:12:16,567 - INFO - INFO: Dataset prepared with 1298 examples
2025-04-25 12:12:16,576 - INFO - INFO: CUDA cache cleared
2025-04-25 12:12:16,705 - INFO - INFO: Garbage collector freed 70 objects
2025-04-25 12:12:24,969 - INFO - INFO: Model loaded from C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1
2025-04-25 12:12:24,969 - INFO - INFO: Model has 8030261248 parameters, 0 are trainable (0.00%)
2025-04-25 12:12:25,587 - INFO - INFO: Model has 41943040 trainable parameters after PEFT configuration
2025-04-25 12:12:25,635 - INFO - Starting model training with 8068 training examples
2025-04-25 12:12:25,635 - INFO - Using 1864 examples for validation during training
2025-04-25 12:12:25,635 - INFO - Using 1298 examples for pre/final evaluation
2025-04-25 12:12:25,654 - INFO - INFO: Starting training...
2025-04-25 12:12:25,655 - INFO - Starting training...
2025-04-25 12:12:25,655 - INFO - Starting training...
2025-04-25 12:12:25,655 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:12:25,655 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:12:25,655 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:12:25,655 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:12:25,656 - INFO - INFO: Registering numpy components as safe globals for checkpoint loading
2025-04-25 12:12:25,656 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:12:25,657 - INFO - INFO: Registering numpy components as safe globals for checkpoint loading
2025-04-25 12:12:25,657 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:12:26,308 - INFO - INFO: Starting epoch 2.5780862667327713/3
2025-04-25 12:12:26,308 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:12:26,308 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:12:34,283 - INFO - ERROR: Training failed with error: 'str' object has no attribute '__module__'
2025-04-25 12:12:34,283 - INFO - INFO: Training failed with error: 'str' object has no attribute '__module__'
2025-04-25 12:12:34,283 - INFO - Training failed with error: 'str' object has no attribute '__module__'
2025-04-25 12:12:34,283 - INFO - Training failed with error: 'str' object has no attribute '__module__'
2025-04-25 12:27:14,705 - INFO - INFO: File logger setup to write to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\logging.txt
2025-04-25 12:27:14,705 - INFO - 

==================================================
2025-04-25 12:27:14,705 - INFO - Resuming from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:27:14,705 - INFO - ==================================================

2025-04-25 12:27:14,705 - INFO - Starting unsupervised fine-tuning with parameters: {'mode': 'unsupervised', 'data_path': 'N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets', 'text_column': 'text', 'use_checkpoint': True, 'checkpoint_path': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600', 'max_samples': None, 'pre_eval': False, 'eval_split': 0, 'model_path': 'C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1', 'output_dir': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2', 'logging_dir': None, 'use_flash_attention': True, 'max_length': 3000, 'chunk_size': None, 'quantization_config': {'load_in_8bit': True}, 'peft_config': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'inference_mode': False, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'w2']}, 'training_config': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'warmup_steps': 100, 'warmup_ratio': 0.03, 'logging_steps': 10, 'save_steps': 200, 'save_total_limit': 3, 'eval_strategy': 'steps', 'eval_steps': 350, 'per_device_eval_batch_size': 1, 'eval_accumulation_steps': 4, 'fp16': True, 'lr_scheduler_type': 'cosine', 'weight_decay': 0.01, 'gradient_checkpointing': True, 'report_to': 'none', 'disable_tqdm': False, 'max_grad_norm': 0.3, 'dataloader_num_workers': 2}}
2025-04-25 12:27:14,705 - INFO - INFO: Loading datasets from individual JSONL files
2025-04-25 12:27:14,705 - INFO - Loading datasets from individual JSONL files
2025-04-25 12:27:14,774 - INFO - INFO: Loaded 8068 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\training_set.jsonl
2025-04-25 12:27:14,836 - INFO - INFO: Loaded 1864 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\validation_set.jsonl
2025-04-25 12:27:14,847 - INFO - INFO: Loaded separate validation set with 1864 examples
2025-04-25 12:27:14,847 - INFO - Loaded separate validation set with 1864 examples
2025-04-25 12:27:14,857 - INFO - INFO: Loaded 1298 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\test_set.jsonl
2025-04-25 12:27:14,865 - INFO - INFO: Loaded separate test set with 1298 examples
2025-04-25 12:27:14,865 - INFO - Loaded separate test set with 1298 examples
2025-04-25 12:27:15,382 - INFO - INFO: Tokenizer vocabulary size: 128256
2025-04-25 12:27:15,382 - INFO - INFO: Model max length: 1000000000000000019884624838656
2025-04-25 12:27:22,900 - INFO - INFO: Dataset prepared with 8068 examples
2025-04-25 12:27:24,645 - INFO - INFO: Dataset prepared with 1864 examples
2025-04-25 12:27:25,931 - INFO - INFO: Dataset prepared with 1298 examples
2025-04-25 12:27:25,936 - INFO - INFO: CUDA cache cleared
2025-04-25 12:27:26,077 - INFO - INFO: Garbage collector freed 70 objects
2025-04-25 12:27:36,268 - INFO - INFO: Model loaded from C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1
2025-04-25 12:27:36,268 - INFO - INFO: Model has 8030261248 parameters, 0 are trainable (0.00%)
2025-04-25 12:27:36,898 - INFO - INFO: Model has 41943040 trainable parameters after PEFT configuration
2025-04-25 12:27:36,963 - INFO - Starting model training with 8068 training examples
2025-04-25 12:27:36,963 - INFO - Using 1864 examples for validation during training
2025-04-25 12:27:36,963 - INFO - Using 1298 examples for pre/final evaluation
2025-04-25 12:27:36,989 - INFO - INFO: Starting training...
2025-04-25 12:27:36,989 - INFO - Starting training...
2025-04-25 12:27:36,989 - INFO - Starting training...
2025-04-25 12:27:36,989 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:27:36,989 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:27:36,990 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:27:36,990 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:27:36,990 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:27:36,990 - INFO - INFO: Registering numpy modules as safe globals
2025-04-25 12:27:36,990 - INFO - INFO: Successfully registered module: numpy
2025-04-25 12:27:36,991 - INFO - INFO: Successfully registered module: numpy.core
2025-04-25 12:27:36,991 - INFO - INFO: Successfully registered module: numpy.core.multiarray
2025-04-25 12:27:36,991 - INFO - INFO: Registering additional pickle-related globals
2025-04-25 12:27:36,991 - INFO - INFO: Registered numpy.array
2025-04-25 12:27:36,992 - INFO - INFO: Registered numpy.zeros
2025-04-25 12:27:36,992 - INFO - INFO: Registered numpy.core.multiarray._reconstruct
2025-04-25 12:27:36,992 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:27:36,992 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:27:36,993 - INFO - INFO: Registering numpy modules as safe globals
2025-04-25 12:27:36,993 - INFO - INFO: Successfully registered module: numpy
2025-04-25 12:27:36,993 - INFO - INFO: Successfully registered module: numpy.core
2025-04-25 12:27:36,993 - INFO - INFO: Successfully registered module: numpy.core.multiarray
2025-04-25 12:27:36,994 - INFO - INFO: Registering additional pickle-related globals
2025-04-25 12:27:36,994 - INFO - INFO: Registered numpy.array
2025-04-25 12:27:36,994 - INFO - INFO: Registered numpy.zeros
2025-04-25 12:27:36,995 - INFO - INFO: Registered numpy.core.multiarray._reconstruct
2025-04-25 12:27:36,995 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:27:37,660 - INFO - INFO: Starting epoch 2.5780862667327713/3
2025-04-25 12:27:37,660 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:27:37,660 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:27:45,494 - INFO - ERROR: Training failed with error: module 'numpy' has no attribute '__module__'
2025-04-25 12:27:45,494 - INFO - INFO: Training failed with error: module 'numpy' has no attribute '__module__'
2025-04-25 12:27:45,494 - INFO - Training failed with error: module 'numpy' has no attribute '__module__'
2025-04-25 12:27:45,494 - INFO - Training failed with error: module 'numpy' has no attribute '__module__'
2025-04-25 12:30:25,211 - INFO - INFO: File logger setup to write to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\logging.txt
2025-04-25 12:30:25,211 - INFO - 

==================================================
2025-04-25 12:30:25,211 - INFO - Resuming from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:30:25,211 - INFO - ==================================================

2025-04-25 12:30:25,211 - INFO - Starting unsupervised fine-tuning with parameters: {'mode': 'unsupervised', 'data_path': 'N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets', 'text_column': 'text', 'use_checkpoint': True, 'checkpoint_path': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600', 'max_samples': None, 'pre_eval': False, 'eval_split': 0, 'model_path': 'C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1', 'output_dir': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2', 'logging_dir': None, 'use_flash_attention': True, 'max_length': 3000, 'chunk_size': None, 'quantization_config': {'load_in_8bit': True}, 'peft_config': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'inference_mode': False, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'w2']}, 'training_config': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'warmup_steps': 100, 'warmup_ratio': 0.03, 'logging_steps': 10, 'save_steps': 200, 'save_total_limit': 3, 'eval_strategy': 'steps', 'eval_steps': 350, 'per_device_eval_batch_size': 1, 'eval_accumulation_steps': 4, 'fp16': True, 'lr_scheduler_type': 'cosine', 'weight_decay': 0.01, 'gradient_checkpointing': True, 'report_to': 'none', 'disable_tqdm': False, 'max_grad_norm': 0.3, 'dataloader_num_workers': 2}}
2025-04-25 12:30:25,211 - INFO - INFO: Loading datasets from individual JSONL files
2025-04-25 12:30:25,211 - INFO - Loading datasets from individual JSONL files
2025-04-25 12:30:25,263 - INFO - INFO: Loaded 8068 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\training_set.jsonl
2025-04-25 12:30:25,321 - INFO - INFO: Loaded 1864 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\validation_set.jsonl
2025-04-25 12:30:25,326 - INFO - INFO: Loaded separate validation set with 1864 examples
2025-04-25 12:30:25,326 - INFO - Loaded separate validation set with 1864 examples
2025-04-25 12:30:25,340 - INFO - INFO: Loaded 1298 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\test_set.jsonl
2025-04-25 12:30:25,347 - INFO - INFO: Loaded separate test set with 1298 examples
2025-04-25 12:30:25,347 - INFO - Loaded separate test set with 1298 examples
2025-04-25 12:30:25,844 - INFO - INFO: Tokenizer vocabulary size: 128256
2025-04-25 12:30:25,844 - INFO - INFO: Model max length: 1000000000000000019884624838656
2025-04-25 12:30:33,357 - INFO - INFO: Dataset prepared with 8068 examples
2025-04-25 12:30:35,166 - INFO - INFO: Dataset prepared with 1864 examples
2025-04-25 12:30:36,451 - INFO - INFO: Dataset prepared with 1298 examples
2025-04-25 12:30:36,457 - INFO - INFO: CUDA cache cleared
2025-04-25 12:30:36,577 - INFO - INFO: Garbage collector freed 70 objects
2025-04-25 12:30:44,896 - INFO - INFO: Model loaded from C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1
2025-04-25 12:30:44,902 - INFO - INFO: Model has 8030261248 parameters, 0 are trainable (0.00%)
2025-04-25 12:30:45,490 - INFO - INFO: Model has 41943040 trainable parameters after PEFT configuration
2025-04-25 12:30:45,550 - INFO - Starting model training with 8068 training examples
2025-04-25 12:30:45,550 - INFO - Using 1864 examples for validation during training
2025-04-25 12:30:45,550 - INFO - Using 1298 examples for pre/final evaluation
2025-04-25 12:30:45,572 - INFO - INFO: Starting training...
2025-04-25 12:30:45,572 - INFO - Starting training...
2025-04-25 12:30:45,572 - INFO - Starting training...
2025-04-25 12:30:45,572 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:30:45,575 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:30:45,575 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:30:45,575 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:30:45,575 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:30:45,576 - INFO - INFO: Registering module names in the PyTorch safe registry
2025-04-25 12:30:45,576 - INFO - WARNING: torch.serialization.safe_registry not available, using alternative registration
2025-04-25 12:30:45,576 - INFO - INFO: Registered class name: numpy.ndarray
2025-04-25 12:30:45,576 - INFO - INFO: Registered class name: numpy.dtype
2025-04-25 12:30:45,577 - INFO - INFO: Registered class name: numpy.generic
2025-04-25 12:30:45,577 - INFO - INFO: Registered class name: numpy.core.multiarray._reconstruct
2025-04-25 12:30:45,577 - INFO - INFO: Registered class name: numpy.int64
2025-04-25 12:30:45,578 - INFO - INFO: Registered class name: numpy.float32
2025-04-25 12:30:45,578 - INFO - INFO: Registered class name: numpy.float16
2025-04-25 12:30:45,578 - INFO - INFO: Registered class name: numpy.bool_
2025-04-25 12:30:45,579 - INFO - INFO: Registered class name: numpy.array
2025-04-25 12:30:45,579 - INFO - INFO: Registered class name: numpy.zeros
2025-04-25 12:30:45,579 - INFO - INFO: Registering numpy array creation patterns
2025-04-25 12:30:45,579 - INFO - INFO: Registered multiarray module for array reconstruction
2025-04-25 12:30:45,580 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:30:45,580 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:30:45,580 - INFO - INFO: Registering module names in the PyTorch safe registry
2025-04-25 12:30:45,581 - INFO - WARNING: torch.serialization.safe_registry not available, using alternative registration
2025-04-25 12:30:45,581 - INFO - INFO: Registered class name: numpy.ndarray
2025-04-25 12:30:45,581 - INFO - INFO: Registered class name: numpy.dtype
2025-04-25 12:30:45,581 - INFO - INFO: Registered class name: numpy.generic
2025-04-25 12:30:45,583 - INFO - INFO: Registered class name: numpy.core.multiarray._reconstruct
2025-04-25 12:30:45,583 - INFO - INFO: Registered class name: numpy.int64
2025-04-25 12:30:45,583 - INFO - INFO: Registered class name: numpy.float32
2025-04-25 12:30:45,583 - INFO - INFO: Registered class name: numpy.float16
2025-04-25 12:30:45,583 - INFO - INFO: Registered class name: numpy.bool_
2025-04-25 12:30:45,583 - INFO - INFO: Registered class name: numpy.array
2025-04-25 12:30:45,584 - INFO - INFO: Registered class name: numpy.zeros
2025-04-25 12:30:45,584 - INFO - INFO: Registering numpy array creation patterns
2025-04-25 12:30:45,584 - INFO - INFO: Registered multiarray module for array reconstruction
2025-04-25 12:30:45,584 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:30:46,275 - INFO - INFO: Starting epoch 2.5780862667327713/3
2025-04-25 12:30:46,275 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:30:46,275 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:30:54,331 - INFO - ERROR: Training failed with error: 'str' object has no attribute '__module__'
2025-04-25 12:30:54,331 - INFO - INFO: Training failed with error: 'str' object has no attribute '__module__'
2025-04-25 12:30:54,331 - INFO - Training failed with error: 'str' object has no attribute '__module__'
2025-04-25 12:30:54,331 - INFO - Training failed with error: 'str' object has no attribute '__module__'
2025-04-25 12:32:51,534 - INFO - INFO: File logger setup to write to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\logging.txt
2025-04-25 12:32:51,534 - INFO - 

==================================================
2025-04-25 12:32:51,534 - INFO - Resuming from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:32:51,534 - INFO - ==================================================

2025-04-25 12:32:51,534 - INFO - Starting unsupervised fine-tuning with parameters: {'mode': 'unsupervised', 'data_path': 'N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets', 'text_column': 'text', 'use_checkpoint': True, 'checkpoint_path': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600', 'max_samples': None, 'pre_eval': False, 'eval_split': 0, 'model_path': 'C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1', 'output_dir': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2', 'logging_dir': None, 'use_flash_attention': True, 'max_length': 3000, 'chunk_size': None, 'quantization_config': {'load_in_8bit': True}, 'peft_config': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'inference_mode': False, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'w2']}, 'training_config': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'warmup_steps': 100, 'warmup_ratio': 0.03, 'logging_steps': 10, 'save_steps': 200, 'save_total_limit': 3, 'eval_strategy': 'steps', 'eval_steps': 350, 'per_device_eval_batch_size': 1, 'eval_accumulation_steps': 4, 'fp16': True, 'lr_scheduler_type': 'cosine', 'weight_decay': 0.01, 'gradient_checkpointing': True, 'report_to': 'none', 'disable_tqdm': False, 'max_grad_norm': 0.3, 'dataloader_num_workers': 2}}
2025-04-25 12:32:51,534 - INFO - INFO: Loading datasets from individual JSONL files
2025-04-25 12:32:51,534 - INFO - Loading datasets from individual JSONL files
2025-04-25 12:32:51,590 - INFO - INFO: Loaded 8068 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\training_set.jsonl
2025-04-25 12:32:51,646 - INFO - INFO: Loaded 1864 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\validation_set.jsonl
2025-04-25 12:32:51,650 - INFO - INFO: Loaded separate validation set with 1864 examples
2025-04-25 12:32:51,650 - INFO - Loaded separate validation set with 1864 examples
2025-04-25 12:32:51,665 - INFO - INFO: Loaded 1298 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\test_set.jsonl
2025-04-25 12:32:51,674 - INFO - INFO: Loaded separate test set with 1298 examples
2025-04-25 12:32:51,674 - INFO - Loaded separate test set with 1298 examples
2025-04-25 12:32:52,203 - INFO - INFO: Tokenizer vocabulary size: 128256
2025-04-25 12:32:52,203 - INFO - INFO: Model max length: 1000000000000000019884624838656
2025-04-25 12:32:59,828 - INFO - INFO: Dataset prepared with 8068 examples
2025-04-25 12:33:01,522 - INFO - INFO: Dataset prepared with 1864 examples
2025-04-25 12:33:02,807 - INFO - INFO: Dataset prepared with 1298 examples
2025-04-25 12:33:02,810 - INFO - INFO: CUDA cache cleared
2025-04-25 12:33:02,928 - INFO - INFO: Garbage collector freed 70 objects
2025-04-25 12:33:11,216 - INFO - INFO: Model loaded from C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1
2025-04-25 12:33:11,216 - INFO - INFO: Model has 8030261248 parameters, 0 are trainable (0.00%)
2025-04-25 12:33:11,794 - INFO - INFO: Model has 41943040 trainable parameters after PEFT configuration
2025-04-25 12:33:11,847 - INFO - Starting model training with 8068 training examples
2025-04-25 12:33:11,847 - INFO - Using 1864 examples for validation during training
2025-04-25 12:33:11,847 - INFO - Using 1298 examples for pre/final evaluation
2025-04-25 12:33:11,851 - INFO - INFO: Starting training...
2025-04-25 12:33:11,851 - INFO - Starting training...
2025-04-25 12:33:11,851 - INFO - Starting training...
2025-04-25 12:33:11,851 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:33:11,851 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:33:11,865 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:33:11,865 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:33:11,865 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:33:11,865 - INFO - INFO: Registering module names in the PyTorch safe registry
2025-04-25 12:33:11,866 - INFO - WARNING: torch.serialization.safe_registry not available, using alternative registration
2025-04-25 12:33:11,866 - INFO - INFO: Registered numpy core multiarray module
2025-04-25 12:33:11,866 - INFO - INFO: Registering numpy array creation patterns
2025-04-25 12:33:11,867 - INFO - INFO: Registered multiarray module for array reconstruction
2025-04-25 12:33:11,867 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:33:11,867 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:33:11,867 - INFO - INFO: Registering module names in the PyTorch safe registry
2025-04-25 12:33:11,867 - INFO - WARNING: torch.serialization.safe_registry not available, using alternative registration
2025-04-25 12:33:11,868 - INFO - INFO: Registered numpy core multiarray module
2025-04-25 12:33:11,868 - INFO - INFO: Registering numpy array creation patterns
2025-04-25 12:33:11,869 - INFO - INFO: Registered multiarray module for array reconstruction
2025-04-25 12:33:11,870 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:33:12,549 - INFO - INFO: Starting epoch 2.5780862667327713/3
2025-04-25 12:33:12,549 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:33:12,549 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:33:20,645 - INFO - ERROR: Training failed with error: module 'numpy.core.multiarray' has no attribute '__module__'
2025-04-25 12:33:20,645 - INFO - INFO: Training failed with error: module 'numpy.core.multiarray' has no attribute '__module__'
2025-04-25 12:33:20,645 - INFO - Training failed with error: module 'numpy.core.multiarray' has no attribute '__module__'
2025-04-25 12:33:20,645 - INFO - Training failed with error: module 'numpy.core.multiarray' has no attribute '__module__'
2025-04-25 12:34:41,458 - INFO - INFO: File logger setup to write to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\logging.txt
2025-04-25 12:34:41,458 - INFO - 

==================================================
2025-04-25 12:34:41,459 - INFO - Resuming from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:34:41,459 - INFO - ==================================================

2025-04-25 12:34:41,459 - INFO - Starting unsupervised fine-tuning with parameters: {'mode': 'unsupervised', 'data_path': 'N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets', 'text_column': 'text', 'use_checkpoint': True, 'checkpoint_path': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600', 'max_samples': None, 'pre_eval': False, 'eval_split': 0, 'model_path': 'C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1', 'output_dir': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2', 'logging_dir': None, 'use_flash_attention': True, 'max_length': 3000, 'chunk_size': None, 'quantization_config': {'load_in_8bit': True}, 'peft_config': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'inference_mode': False, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'w2']}, 'training_config': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'warmup_steps': 100, 'warmup_ratio': 0.03, 'logging_steps': 10, 'save_steps': 200, 'save_total_limit': 3, 'eval_strategy': 'steps', 'eval_steps': 350, 'per_device_eval_batch_size': 1, 'eval_accumulation_steps': 4, 'fp16': True, 'lr_scheduler_type': 'cosine', 'weight_decay': 0.01, 'gradient_checkpointing': True, 'report_to': 'none', 'disable_tqdm': False, 'max_grad_norm': 0.3, 'dataloader_num_workers': 2}}
2025-04-25 12:34:41,459 - INFO - INFO: Loading datasets from individual JSONL files
2025-04-25 12:34:41,459 - INFO - Loading datasets from individual JSONL files
2025-04-25 12:34:41,509 - INFO - INFO: Loaded 8068 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\training_set.jsonl
2025-04-25 12:34:41,565 - INFO - INFO: Loaded 1864 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\validation_set.jsonl
2025-04-25 12:34:41,581 - INFO - INFO: Loaded separate validation set with 1864 examples
2025-04-25 12:34:41,581 - INFO - Loaded separate validation set with 1864 examples
2025-04-25 12:34:41,590 - INFO - INFO: Loaded 1298 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\test_set.jsonl
2025-04-25 12:34:41,599 - INFO - INFO: Loaded separate test set with 1298 examples
2025-04-25 12:34:41,599 - INFO - Loaded separate test set with 1298 examples
2025-04-25 12:34:42,144 - INFO - INFO: Tokenizer vocabulary size: 128256
2025-04-25 12:34:42,144 - INFO - INFO: Model max length: 1000000000000000019884624838656
2025-04-25 12:34:49,938 - INFO - INFO: Dataset prepared with 8068 examples
2025-04-25 12:34:51,780 - INFO - INFO: Dataset prepared with 1864 examples
2025-04-25 12:34:53,098 - INFO - INFO: Dataset prepared with 1298 examples
2025-04-25 12:34:53,104 - INFO - INFO: CUDA cache cleared
2025-04-25 12:34:53,234 - INFO - INFO: Garbage collector freed 70 objects
2025-04-25 12:35:01,663 - INFO - INFO: Model loaded from C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1
2025-04-25 12:35:01,663 - INFO - INFO: Model has 8030261248 parameters, 0 are trainable (0.00%)
2025-04-25 12:35:02,188 - INFO - INFO: Model has 41943040 trainable parameters after PEFT configuration
2025-04-25 12:35:02,238 - INFO - Starting model training with 8068 training examples
2025-04-25 12:35:02,238 - INFO - Using 1864 examples for validation during training
2025-04-25 12:35:02,238 - INFO - Using 1298 examples for pre/final evaluation
2025-04-25 12:35:02,257 - INFO - INFO: Starting training...
2025-04-25 12:35:02,257 - INFO - Starting training...
2025-04-25 12:35:02,257 - INFO - Starting training...
2025-04-25 12:35:02,258 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:35:02,258 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:35:02,258 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:35:02,258 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:35:02,258 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:35:02,259 - INFO - INFO: Registering module names in the PyTorch safe registry
2025-04-25 12:35:02,259 - INFO - WARNING: torch.serialization.safe_registry not available, using alternative registration
2025-04-25 12:35:02,259 - INFO - INFO: Registering specific numpy components
2025-04-25 12:35:02,259 - INFO - INFO: Registering numpy array creation patterns
2025-04-25 12:35:02,259 - INFO - INFO: Set up safe dtype handler for array reconstruction
2025-04-25 12:35:02,259 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:35:02,259 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:35:02,259 - INFO - INFO: Registering module names in the PyTorch safe registry
2025-04-25 12:35:02,259 - INFO - WARNING: torch.serialization.safe_registry not available, using alternative registration
2025-04-25 12:35:02,259 - INFO - INFO: Registering specific numpy components
2025-04-25 12:35:02,259 - INFO - INFO: Registering numpy array creation patterns
2025-04-25 12:35:02,259 - INFO - INFO: Set up safe dtype handler for array reconstruction
2025-04-25 12:35:02,259 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:35:02,955 - INFO - INFO: Starting epoch 2.5780862667327713/3
2025-04-25 12:35:02,956 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:35:02,956 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:35:11,125 - INFO - ERROR: Training failed with error: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Can only build Tensor, Parameter, OrderedDict or types allowlisted via `add_safe_globals`, but got <class 'numpy.dtypes.UInt32DType'>

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:35:11,125 - INFO - INFO: Training failed with error: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Can only build Tensor, Parameter, OrderedDict or types allowlisted via `add_safe_globals`, but got <class 'numpy.dtypes.UInt32DType'>

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:35:11,125 - INFO - Training failed with error: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Can only build Tensor, Parameter, OrderedDict or types allowlisted via `add_safe_globals`, but got <class 'numpy.dtypes.UInt32DType'>

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:35:11,125 - INFO - Training failed with error: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Can only build Tensor, Parameter, OrderedDict or types allowlisted via `add_safe_globals`, but got <class 'numpy.dtypes.UInt32DType'>

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-04-25 12:37:20,609 - INFO - INFO: File logger setup to write to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\logging.txt
2025-04-25 12:37:20,609 - INFO - 

==================================================
2025-04-25 12:37:20,609 - INFO - Resuming from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:37:20,609 - INFO - ==================================================

2025-04-25 12:37:20,609 - INFO - Starting unsupervised fine-tuning with parameters: {'mode': 'unsupervised', 'data_path': 'N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets', 'text_column': 'text', 'use_checkpoint': True, 'checkpoint_path': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600', 'max_samples': None, 'pre_eval': False, 'eval_split': 0, 'model_path': 'C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1', 'output_dir': 'C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2', 'logging_dir': None, 'use_flash_attention': True, 'max_length': 3000, 'chunk_size': None, 'quantization_config': {'load_in_8bit': True}, 'peft_config': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'inference_mode': False, 'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'w2']}, 'training_config': {'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 8, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'warmup_steps': 100, 'warmup_ratio': 0.03, 'logging_steps': 10, 'save_steps': 200, 'save_total_limit': 3, 'eval_strategy': 'steps', 'eval_steps': 350, 'per_device_eval_batch_size': 1, 'eval_accumulation_steps': 4, 'fp16': True, 'lr_scheduler_type': 'cosine', 'weight_decay': 0.01, 'gradient_checkpointing': True, 'report_to': 'none', 'disable_tqdm': False, 'max_grad_norm': 0.3, 'dataloader_num_workers': 2}}
2025-04-25 12:37:20,609 - INFO - INFO: Loading datasets from individual JSONL files
2025-04-25 12:37:20,609 - INFO - Loading datasets from individual JSONL files
2025-04-25 12:37:20,687 - INFO - INFO: Loaded 8068 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\training_set.jsonl
2025-04-25 12:37:20,743 - INFO - INFO: Loaded 1864 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\validation_set.jsonl
2025-04-25 12:37:20,761 - INFO - INFO: Loaded separate validation set with 1864 examples
2025-04-25 12:37:20,761 - INFO - Loaded separate validation set with 1864 examples
2025-04-25 12:37:20,770 - INFO - INFO: Loaded 1298 examples from N:/Thesis/data_prepare/datasets_ready/unsupervised/single_chapters/combined_datasets\test_set.jsonl
2025-04-25 12:37:20,779 - INFO - INFO: Loaded separate test set with 1298 examples
2025-04-25 12:37:20,779 - INFO - Loaded separate test set with 1298 examples
2025-04-25 12:37:21,304 - INFO - INFO: Tokenizer vocabulary size: 128256
2025-04-25 12:37:21,304 - INFO - INFO: Model max length: 1000000000000000019884624838656
2025-04-25 12:37:28,946 - INFO - INFO: Dataset prepared with 8068 examples
2025-04-25 12:37:30,650 - INFO - INFO: Dataset prepared with 1864 examples
2025-04-25 12:37:31,980 - INFO - INFO: Dataset prepared with 1298 examples
2025-04-25 12:37:31,985 - INFO - INFO: CUDA cache cleared
2025-04-25 12:37:32,123 - INFO - INFO: Garbage collector freed 70 objects
2025-04-25 12:38:02,145 - INFO - INFO: Model loaded from C:/Users/Paul/.cache/merged_models/llama3_german_merged_unsupervised_1
2025-04-25 12:38:02,145 - INFO - INFO: Model has 8030261248 parameters, 0 are trainable (0.00%)
2025-04-25 12:38:02,916 - INFO - INFO: Model has 41943040 trainable parameters after PEFT configuration
2025-04-25 12:38:03,003 - INFO - Starting model training with 8068 training examples
2025-04-25 12:38:03,003 - INFO - Using 1864 examples for validation during training
2025-04-25 12:38:03,003 - INFO - Using 1298 examples for pre/final evaluation
2025-04-25 12:38:03,022 - INFO - INFO: Starting training...
2025-04-25 12:38:03,022 - INFO - Starting training...
2025-04-25 12:38:03,026 - INFO - Starting training...
2025-04-25 12:38:03,026 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:38:03,026 - INFO - INFO: Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:38:03,027 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:38:03,027 - INFO - Resuming training from checkpoint: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2/checkpoint-2600
2025-04-25 12:38:03,027 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:38:03,028 - INFO - INFO: Registering module names in the PyTorch safe registry
2025-04-25 12:38:03,028 - INFO - WARNING: torch.serialization.safe_registry not available, using alternative registration
2025-04-25 12:38:03,028 - INFO - INFO: Registering specific numpy components
2025-04-25 12:38:03,028 - INFO - INFO: Registering numpy array creation patterns
2025-04-25 12:38:03,028 - INFO - INFO: Set up safe dtype handler for array reconstruction
2025-04-25 12:38:03,028 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:38:03,028 - INFO - INFO: Registering numpy component classes as safe globals
2025-04-25 12:38:03,028 - INFO - INFO: Registering module names in the PyTorch safe registry
2025-04-25 12:38:03,028 - INFO - WARNING: torch.serialization.safe_registry not available, using alternative registration
2025-04-25 12:38:03,028 - INFO - INFO: Registering specific numpy components
2025-04-25 12:38:03,032 - INFO - INFO: Registering numpy array creation patterns
2025-04-25 12:38:03,032 - INFO - INFO: Set up safe dtype handler for array reconstruction
2025-04-25 12:38:03,032 - INFO - INFO: Numpy components registered as safe globals
2025-04-25 12:38:04,402 - INFO - INFO: Starting epoch 2.5780862667327713/3
2025-04-25 12:38:04,402 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:38:04,402 - INFO - Starting epoch 2.5780862667327713/3
2025-04-25 12:41:14,900 - INFO - INFO: Training progress: {'loss': 0.7773, 'grad_norm': 3.3599183559417725, 'learning_rate': 9.730681613617577e-07, 'epoch': 2.588993554784333}
2025-04-25 12:41:14,900 - INFO - Training progress: {'loss': 0.7773, 'grad_norm': 3.3599183559417725, 'learning_rate': 9.730681613617577e-07, 'epoch': 2.588993554784333}
2025-04-25 12:41:14,900 - INFO - Training metrics: {'loss': 0.7773, 'grad_norm': 3.3599183559417725, 'learning_rate': 9.730681613617577e-07, 'epoch': 2.588993554784333}
2025-04-25 12:44:12,806 - INFO - INFO: Training progress: {'loss': 0.6095, 'grad_norm': 2.19523286819458, 'learning_rate': 9.27359574563238e-07, 'epoch': 2.598909271194844}
2025-04-25 12:44:12,806 - INFO - Training progress: {'loss': 0.6095, 'grad_norm': 2.19523286819458, 'learning_rate': 9.27359574563238e-07, 'epoch': 2.598909271194844}
2025-04-25 12:44:12,806 - INFO - Training metrics: {'loss': 0.6095, 'grad_norm': 2.19523286819458, 'learning_rate': 9.27359574563238e-07, 'epoch': 2.598909271194844}
2025-04-25 12:47:18,437 - INFO - INFO: Training progress: {'loss': 0.6716, 'grad_norm': 2.7635397911071777, 'learning_rate': 8.826982960274244e-07, 'epoch': 2.6088249876053546}
2025-04-25 12:47:18,438 - INFO - Training progress: {'loss': 0.6716, 'grad_norm': 2.7635397911071777, 'learning_rate': 8.826982960274244e-07, 'epoch': 2.6088249876053546}
2025-04-25 12:47:18,438 - INFO - Training metrics: {'loss': 0.6716, 'grad_norm': 2.7635397911071777, 'learning_rate': 8.826982960274244e-07, 'epoch': 2.6088249876053546}
2025-04-25 12:50:26,380 - INFO - INFO: Training progress: {'loss': 0.627, 'grad_norm': 2.2752039432525635, 'learning_rate': 8.390894812684602e-07, 'epoch': 2.618740704015865}
2025-04-25 12:50:26,380 - INFO - Training progress: {'loss': 0.627, 'grad_norm': 2.2752039432525635, 'learning_rate': 8.390894812684602e-07, 'epoch': 2.618740704015865}
2025-04-25 12:50:26,381 - INFO - Training metrics: {'loss': 0.627, 'grad_norm': 2.2752039432525635, 'learning_rate': 8.390894812684602e-07, 'epoch': 2.618740704015865}
2025-04-25 12:53:34,364 - INFO - INFO: Training progress: {'loss': 0.7426, 'grad_norm': 2.9489872455596924, 'learning_rate': 7.965381643084069e-07, 'epoch': 2.628656420426376}
2025-04-25 12:53:34,364 - INFO - Training progress: {'loss': 0.7426, 'grad_norm': 2.9489872455596924, 'learning_rate': 7.965381643084069e-07, 'epoch': 2.628656420426376}
2025-04-25 12:53:34,364 - INFO - Training metrics: {'loss': 0.7426, 'grad_norm': 2.9489872455596924, 'learning_rate': 7.965381643084069e-07, 'epoch': 2.628656420426376}
2025-04-25 12:56:44,805 - INFO - INFO: Training progress: {'loss': 0.6701, 'grad_norm': 2.370171546936035, 'learning_rate': 7.550492570961243e-07, 'epoch': 2.6385721368368866}
2025-04-25 12:56:44,805 - INFO - Training progress: {'loss': 0.6701, 'grad_norm': 2.370171546936035, 'learning_rate': 7.550492570961243e-07, 'epoch': 2.6385721368368866}
2025-04-25 12:56:44,805 - INFO - Training metrics: {'loss': 0.6701, 'grad_norm': 2.370171546936035, 'learning_rate': 7.550492570961243e-07, 'epoch': 2.6385721368368866}
2025-04-25 12:59:57,351 - INFO - INFO: Training progress: {'loss': 0.5775, 'grad_norm': 1.657128095626831, 'learning_rate': 7.146275489402721e-07, 'epoch': 2.648487853247397}
2025-04-25 12:59:57,351 - INFO - Training progress: {'loss': 0.5775, 'grad_norm': 1.657128095626831, 'learning_rate': 7.146275489402721e-07, 'epoch': 2.648487853247397}
2025-04-25 12:59:57,351 - INFO - Training metrics: {'loss': 0.5775, 'grad_norm': 1.657128095626831, 'learning_rate': 7.146275489402721e-07, 'epoch': 2.648487853247397}
2025-04-25 13:03:01,185 - INFO - INFO: Training progress: {'loss': 0.7098, 'grad_norm': 3.0484976768493652, 'learning_rate': 6.752777059564431e-07, 'epoch': 2.658403569657908}
2025-04-25 13:03:07,672 - INFO - Training progress: {'loss': 0.7098, 'grad_norm': 3.0484976768493652, 'learning_rate': 6.752777059564431e-07, 'epoch': 2.658403569657908}
2025-04-25 13:03:07,672 - INFO - Training metrics: {'loss': 0.7098, 'grad_norm': 3.0484976768493652, 'learning_rate': 6.752777059564431e-07, 'epoch': 2.658403569657908}
2025-04-25 13:06:09,402 - INFO - INFO: Training progress: {'loss': 0.6264, 'grad_norm': 1.2185993194580078, 'learning_rate': 6.370042705285229e-07, 'epoch': 2.668319286068418}
2025-04-25 13:06:09,402 - INFO - Training progress: {'loss': 0.6264, 'grad_norm': 1.2185993194580078, 'learning_rate': 6.370042705285229e-07, 'epoch': 2.668319286068418}
2025-04-25 13:06:09,402 - INFO - Training metrics: {'loss': 0.6264, 'grad_norm': 1.2185993194580078, 'learning_rate': 6.370042705285229e-07, 'epoch': 2.668319286068418}
2025-04-25 13:09:09,630 - INFO - INFO: Training progress: {'loss': 0.7624, 'grad_norm': 2.284069776535034, 'learning_rate': 5.99811660784344e-07, 'epoch': 2.678235002478929}
2025-04-25 13:09:09,630 - INFO - Training progress: {'loss': 0.7624, 'grad_norm': 2.284069776535034, 'learning_rate': 5.99811660784344e-07, 'epoch': 2.678235002478929}
2025-04-25 13:09:09,630 - INFO - Training metrics: {'loss': 0.7624, 'grad_norm': 2.284069776535034, 'learning_rate': 5.99811660784344e-07, 'epoch': 2.678235002478929}
2025-04-25 13:12:08,877 - INFO - INFO: Training progress: {'loss': 0.6292, 'grad_norm': 3.289463520050049, 'learning_rate': 5.637041700856705e-07, 'epoch': 2.68815071888944}
2025-04-25 13:12:08,877 - INFO - Training progress: {'loss': 0.6292, 'grad_norm': 3.289463520050049, 'learning_rate': 5.637041700856705e-07, 'epoch': 2.68815071888944}
2025-04-25 13:12:08,877 - INFO - Training metrics: {'loss': 0.6292, 'grad_norm': 3.289463520050049, 'learning_rate': 5.637041700856705e-07, 'epoch': 2.68815071888944}
2025-04-25 13:15:07,954 - INFO - INFO: Training progress: {'loss': 0.6661, 'grad_norm': 3.715294361114502, 'learning_rate': 5.286859665325905e-07, 'epoch': 2.6980664352999506}
2025-04-25 13:15:07,954 - INFO - Training progress: {'loss': 0.6661, 'grad_norm': 3.715294361114502, 'learning_rate': 5.286859665325905e-07, 'epoch': 2.6980664352999506}
2025-04-25 13:15:07,954 - INFO - Training metrics: {'loss': 0.6661, 'grad_norm': 3.715294361114502, 'learning_rate': 5.286859665325905e-07, 'epoch': 2.6980664352999506}
2025-04-25 13:18:12,667 - INFO - INFO: Training progress: {'loss': 0.5544, 'grad_norm': 3.6735832691192627, 'learning_rate': 4.947610924823643e-07, 'epoch': 2.707982151710461}
2025-04-25 13:18:12,667 - INFO - Training progress: {'loss': 0.5544, 'grad_norm': 3.6735832691192627, 'learning_rate': 4.947610924823643e-07, 'epoch': 2.707982151710461}
2025-04-25 13:18:12,667 - INFO - Training metrics: {'loss': 0.5544, 'grad_norm': 3.6735832691192627, 'learning_rate': 4.947610924823643e-07, 'epoch': 2.707982151710461}
2025-04-25 13:21:17,661 - INFO - INFO: Training progress: {'loss': 0.7124, 'grad_norm': 2.938528537750244, 'learning_rate': 4.6193346408280216e-07, 'epoch': 2.717897868120972}
2025-04-25 13:21:17,661 - INFO - Training progress: {'loss': 0.7124, 'grad_norm': 2.938528537750244, 'learning_rate': 4.6193346408280216e-07, 'epoch': 2.717897868120972}
2025-04-25 13:21:17,661 - INFO - Training metrics: {'loss': 0.7124, 'grad_norm': 2.938528537750244, 'learning_rate': 4.6193346408280216e-07, 'epoch': 2.717897868120972}
2025-04-25 13:24:23,731 - INFO - INFO: Training progress: {'loss': 0.6569, 'grad_norm': 2.3323519229888916, 'learning_rate': 4.302068708201912e-07, 'epoch': 2.727813584531482}
2025-04-25 13:24:23,731 - INFO - Training progress: {'loss': 0.6569, 'grad_norm': 2.3323519229888916, 'learning_rate': 4.302068708201912e-07, 'epoch': 2.727813584531482}
2025-04-25 13:24:23,731 - INFO - Training metrics: {'loss': 0.6569, 'grad_norm': 2.3323519229888916, 'learning_rate': 4.302068708201912e-07, 'epoch': 2.727813584531482}
2025-04-25 13:27:22,997 - INFO - INFO: Training progress: {'loss': 0.6732, 'grad_norm': 3.6555097103118896, 'learning_rate': 3.9958497508185036e-07, 'epoch': 2.737729300941993}
2025-04-25 13:27:22,997 - INFO - Training progress: {'loss': 0.6732, 'grad_norm': 3.6555097103118896, 'learning_rate': 3.9958497508185036e-07, 'epoch': 2.737729300941993}
2025-04-25 13:27:22,997 - INFO - Training metrics: {'loss': 0.6732, 'grad_norm': 3.6555097103118896, 'learning_rate': 3.9958497508185036e-07, 'epoch': 2.737729300941993}
2025-04-25 13:30:23,361 - INFO - INFO: Training progress: {'loss': 0.644, 'grad_norm': 3.255669355392456, 'learning_rate': 3.7007131173336766e-07, 'epoch': 2.7476450173525038}
2025-04-25 13:30:23,362 - INFO - Training progress: {'loss': 0.644, 'grad_norm': 3.255669355392456, 'learning_rate': 3.7007131173336766e-07, 'epoch': 2.7476450173525038}
2025-04-25 13:30:23,362 - INFO - Training metrics: {'loss': 0.644, 'grad_norm': 3.255669355392456, 'learning_rate': 3.7007131173336766e-07, 'epoch': 2.7476450173525038}
2025-04-25 13:33:23,550 - INFO - INFO: Training progress: {'loss': 0.6308, 'grad_norm': 1.8438684940338135, 'learning_rate': 3.4166928771054653e-07, 'epoch': 2.7575607337630146}
2025-04-25 13:33:23,550 - INFO - Training progress: {'loss': 0.6308, 'grad_norm': 1.8438684940338135, 'learning_rate': 3.4166928771054653e-07, 'epoch': 2.7575607337630146}
2025-04-25 13:33:23,550 - INFO - Training metrics: {'loss': 0.6308, 'grad_norm': 1.8438684940338135, 'learning_rate': 3.4166928771054653e-07, 'epoch': 2.7575607337630146}
2025-04-25 13:36:29,818 - INFO - INFO: Training progress: {'loss': 0.7037, 'grad_norm': 2.253031015396118, 'learning_rate': 3.1438218162612057e-07, 'epoch': 2.767476450173525}
2025-04-25 13:36:29,818 - INFO - Training progress: {'loss': 0.7037, 'grad_norm': 2.253031015396118, 'learning_rate': 3.1438218162612057e-07, 'epoch': 2.767476450173525}
2025-04-25 13:36:29,818 - INFO - Training metrics: {'loss': 0.7037, 'grad_norm': 2.253031015396118, 'learning_rate': 3.1438218162612057e-07, 'epoch': 2.767476450173525}
2025-04-25 13:39:30,958 - INFO - INFO: Training progress: {'loss': 0.6859, 'grad_norm': 2.406634569168091, 'learning_rate': 2.882131433912883e-07, 'epoch': 2.7773921665840358}
2025-04-25 13:39:30,959 - INFO - Training progress: {'loss': 0.6859, 'grad_norm': 2.406634569168091, 'learning_rate': 2.882131433912883e-07, 'epoch': 2.7773921665840358}
2025-04-25 13:39:30,959 - INFO - Training metrics: {'loss': 0.6859, 'grad_norm': 2.406634569168091, 'learning_rate': 2.882131433912883e-07, 'epoch': 2.7773921665840358}
2025-04-25 13:56:51,428 - INFO - INFO: Training progress: {'eval_loss': 0.7431360483169556, 'eval_runtime': 1040.4678, 'eval_samples_per_second': 1.792, 'eval_steps_per_second': 1.792, 'epoch': 2.7773921665840358}
2025-04-25 13:56:51,428 - INFO - Training progress: {'eval_loss': 0.7431360483169556, 'eval_runtime': 1040.4678, 'eval_samples_per_second': 1.792, 'eval_steps_per_second': 1.792, 'epoch': 2.7773921665840358}
2025-04-25 13:56:51,428 - INFO - Training metrics: {'eval_loss': 0.7431360483169556, 'eval_runtime': 1040.4678, 'eval_samples_per_second': 1.792, 'eval_steps_per_second': 1.792, 'epoch': 2.7773921665840358}
2025-04-25 13:56:52,086 - INFO - INFO: Saving checkpoint at step 2800
2025-04-25 13:56:52,086 - INFO - Saving checkpoint at step 2800
2025-04-25 13:56:52,086 - INFO - Saving checkpoint at step 2800
2025-04-25 13:59:56,055 - INFO - INFO: Training progress: {'loss': 0.6287, 'grad_norm': 1.8931738138198853, 'learning_rate': 2.6316519385209627e-07, 'epoch': 2.787307882994546}
2025-04-25 13:59:56,056 - INFO - Training progress: {'loss': 0.6287, 'grad_norm': 1.8931738138198853, 'learning_rate': 2.6316519385209627e-07, 'epoch': 2.787307882994546}
2025-04-25 13:59:56,056 - INFO - Training metrics: {'loss': 0.6287, 'grad_norm': 1.8931738138198853, 'learning_rate': 2.6316519385209627e-07, 'epoch': 2.787307882994546}
2025-04-25 14:03:07,786 - INFO - INFO: Training progress: {'loss': 0.838, 'grad_norm': 2.2650504112243652, 'learning_rate': 2.392412244407294e-07, 'epoch': 2.797223599405057}
2025-04-25 14:03:07,786 - INFO - Training progress: {'loss': 0.838, 'grad_norm': 2.2650504112243652, 'learning_rate': 2.392412244407294e-07, 'epoch': 2.797223599405057}
2025-04-25 14:03:07,787 - INFO - Training metrics: {'loss': 0.838, 'grad_norm': 2.2650504112243652, 'learning_rate': 2.392412244407294e-07, 'epoch': 2.797223599405057}
2025-04-25 14:06:18,010 - INFO - INFO: Training progress: {'loss': 0.7476, 'grad_norm': 1.8760584592819214, 'learning_rate': 2.164439968417298e-07, 'epoch': 2.8071393158155677}
2025-04-25 14:06:18,011 - INFO - Training progress: {'loss': 0.7476, 'grad_norm': 1.8760584592819214, 'learning_rate': 2.164439968417298e-07, 'epoch': 2.8071393158155677}
2025-04-25 14:06:18,011 - INFO - Training metrics: {'loss': 0.7476, 'grad_norm': 1.8760584592819214, 'learning_rate': 2.164439968417298e-07, 'epoch': 2.8071393158155677}
2025-04-25 14:09:28,406 - INFO - INFO: Training progress: {'loss': 0.6995, 'grad_norm': 2.842531442642212, 'learning_rate': 1.9477614267320867e-07, 'epoch': 2.8170550322260786}
2025-04-25 14:09:28,406 - INFO - Training progress: {'loss': 0.6995, 'grad_norm': 2.842531442642212, 'learning_rate': 1.9477614267320867e-07, 'epoch': 2.8170550322260786}
2025-04-25 14:09:28,406 - INFO - Training metrics: {'loss': 0.6995, 'grad_norm': 2.842531442642212, 'learning_rate': 1.9477614267320867e-07, 'epoch': 2.8170550322260786}
2025-04-25 14:12:38,899 - INFO - INFO: Training progress: {'loss': 0.6887, 'grad_norm': 3.8392701148986816, 'learning_rate': 1.742401631830526e-07, 'epoch': 2.826970748636589}
2025-04-25 14:12:38,899 - INFO - Training progress: {'loss': 0.6887, 'grad_norm': 3.8392701148986816, 'learning_rate': 1.742401631830526e-07, 'epoch': 2.826970748636589}
2025-04-25 14:12:38,899 - INFO - Training metrics: {'loss': 0.6887, 'grad_norm': 3.8392701148986816, 'learning_rate': 1.742401631830526e-07, 'epoch': 2.826970748636589}
2025-04-25 14:15:49,382 - INFO - INFO: Training progress: {'loss': 0.7015, 'grad_norm': 3.3667306900024414, 'learning_rate': 1.5483842896019675e-07, 'epoch': 2.8368864650470997}
2025-04-25 14:15:49,382 - INFO - Training progress: {'loss': 0.7015, 'grad_norm': 3.3667306900024414, 'learning_rate': 1.5483842896019675e-07, 'epoch': 2.8368864650470997}
2025-04-25 14:15:49,382 - INFO - Training metrics: {'loss': 0.7015, 'grad_norm': 3.3667306900024414, 'learning_rate': 1.5483842896019675e-07, 'epoch': 2.8368864650470997}
2025-04-25 14:18:52,733 - INFO - INFO: Training progress: {'loss': 0.6845, 'grad_norm': 2.072711944580078, 'learning_rate': 1.365731796609715e-07, 'epoch': 2.84680218145761}
2025-04-25 14:18:52,733 - INFO - Training progress: {'loss': 0.6845, 'grad_norm': 2.072711944580078, 'learning_rate': 1.365731796609715e-07, 'epoch': 2.84680218145761}
2025-04-25 14:18:52,733 - INFO - Training metrics: {'loss': 0.6845, 'grad_norm': 2.072711944580078, 'learning_rate': 1.365731796609715e-07, 'epoch': 2.84680218145761}
2025-04-25 14:21:54,712 - INFO - INFO: Training progress: {'loss': 0.6393, 'grad_norm': 2.558776617050171, 'learning_rate': 1.1944652375056597e-07, 'epoch': 2.856717897868121}
2025-04-25 14:21:54,712 - INFO - Training progress: {'loss': 0.6393, 'grad_norm': 2.558776617050171, 'learning_rate': 1.1944652375056597e-07, 'epoch': 2.856717897868121}
2025-04-25 14:21:54,712 - INFO - Training metrics: {'loss': 0.6393, 'grad_norm': 2.558776617050171, 'learning_rate': 1.1944652375056597e-07, 'epoch': 2.856717897868121}
2025-04-25 14:24:56,125 - INFO - INFO: Training progress: {'loss': 0.7474, 'grad_norm': 2.118352174758911, 'learning_rate': 1.0346043825963603e-07, 'epoch': 2.8666336142786317}
2025-04-25 14:24:56,125 - INFO - Training progress: {'loss': 0.7474, 'grad_norm': 2.118352174758911, 'learning_rate': 1.0346043825963603e-07, 'epoch': 2.8666336142786317}
2025-04-25 14:24:56,125 - INFO - Training metrics: {'loss': 0.7474, 'grad_norm': 2.118352174758911, 'learning_rate': 1.0346043825963603e-07, 'epoch': 2.8666336142786317}
2025-04-25 14:27:56,855 - INFO - INFO: Training progress: {'loss': 0.6431, 'grad_norm': 2.3399479389190674, 'learning_rate': 8.861676855608237e-08, 'epoch': 2.8765493306891425}
2025-04-25 14:27:56,855 - INFO - Training progress: {'loss': 0.6431, 'grad_norm': 2.3399479389190674, 'learning_rate': 8.861676855608237e-08, 'epoch': 2.8765493306891425}
2025-04-25 14:27:56,855 - INFO - Training metrics: {'loss': 0.6431, 'grad_norm': 2.3399479389190674, 'learning_rate': 8.861676855608237e-08, 'epoch': 2.8765493306891425}
2025-04-25 14:31:11,207 - INFO - INFO: Training progress: {'loss': 0.755, 'grad_norm': 2.3940603733062744, 'learning_rate': 7.491722813203206e-08, 'epoch': 2.886465047099653}
2025-04-25 14:31:11,207 - INFO - Training progress: {'loss': 0.755, 'grad_norm': 2.3940603733062744, 'learning_rate': 7.491722813203206e-08, 'epoch': 2.886465047099653}
2025-04-25 14:31:11,207 - INFO - Training metrics: {'loss': 0.755, 'grad_norm': 2.3940603733062744, 'learning_rate': 7.491722813203206e-08, 'epoch': 2.886465047099653}
2025-04-25 14:34:17,480 - INFO - INFO: Training progress: {'loss': 0.6805, 'grad_norm': 1.8885364532470703, 'learning_rate': 6.236339840603677e-08, 'epoch': 2.8963807635101637}
2025-04-25 14:34:17,480 - INFO - Training progress: {'loss': 0.6805, 'grad_norm': 1.8885364532470703, 'learning_rate': 6.236339840603677e-08, 'epoch': 2.8963807635101637}
2025-04-25 14:34:17,480 - INFO - Training metrics: {'loss': 0.6805, 'grad_norm': 1.8885364532470703, 'learning_rate': 6.236339840603677e-08, 'epoch': 2.8963807635101637}
2025-04-25 14:37:18,417 - INFO - INFO: Training progress: {'loss': 0.6677, 'grad_norm': 2.170532464981079, 'learning_rate': 5.095672854051992e-08, 'epoch': 2.906296479920674}
2025-04-25 14:37:18,417 - INFO - Training progress: {'loss': 0.6677, 'grad_norm': 2.170532464981079, 'learning_rate': 5.095672854051992e-08, 'epoch': 2.906296479920674}
2025-04-25 14:37:18,417 - INFO - Training metrics: {'loss': 0.6677, 'grad_norm': 2.170532464981079, 'learning_rate': 5.095672854051992e-08, 'epoch': 2.906296479920674}
2025-04-25 14:40:19,191 - INFO - INFO: Training progress: {'loss': 0.8235, 'grad_norm': 1.8751102685928345, 'learning_rate': 4.069853527449596e-08, 'epoch': 2.916212196331185}
2025-04-25 14:40:19,191 - INFO - Training progress: {'loss': 0.8235, 'grad_norm': 1.8751102685928345, 'learning_rate': 4.069853527449596e-08, 'epoch': 2.916212196331185}
2025-04-25 14:40:19,191 - INFO - Training metrics: {'loss': 0.8235, 'grad_norm': 1.8751102685928345, 'learning_rate': 4.069853527449596e-08, 'epoch': 2.916212196331185}
2025-04-25 14:43:19,467 - INFO - INFO: Training progress: {'loss': 0.7357, 'grad_norm': 3.3346376419067383, 'learning_rate': 3.159000277156654e-08, 'epoch': 2.9261279127416957}
2025-04-25 14:43:19,467 - INFO - Training progress: {'loss': 0.7357, 'grad_norm': 3.3346376419067383, 'learning_rate': 3.159000277156654e-08, 'epoch': 2.9261279127416957}
2025-04-25 14:43:19,468 - INFO - Training metrics: {'loss': 0.7357, 'grad_norm': 3.3346376419067383, 'learning_rate': 3.159000277156654e-08, 'epoch': 2.9261279127416957}
2025-04-25 14:46:18,077 - INFO - INFO: Training progress: {'loss': 0.6611, 'grad_norm': 2.9147729873657227, 'learning_rate': 2.3632182483228628e-08, 'epoch': 2.9360436291522065}
2025-04-25 14:46:18,077 - INFO - Training progress: {'loss': 0.6611, 'grad_norm': 2.9147729873657227, 'learning_rate': 2.3632182483228628e-08, 'epoch': 2.9360436291522065}
2025-04-25 14:46:18,077 - INFO - Training metrics: {'loss': 0.6611, 'grad_norm': 2.9147729873657227, 'learning_rate': 2.3632182483228628e-08, 'epoch': 2.9360436291522065}
2025-04-25 14:49:20,878 - INFO - INFO: Training progress: {'loss': 0.7977, 'grad_norm': 2.176752805709839, 'learning_rate': 1.6825993027497213e-08, 'epoch': 2.945959345562717}
2025-04-25 14:49:20,878 - INFO - Training progress: {'loss': 0.7977, 'grad_norm': 2.176752805709839, 'learning_rate': 1.6825993027497213e-08, 'epoch': 2.945959345562717}
2025-04-25 14:49:20,879 - INFO - Training metrics: {'loss': 0.7977, 'grad_norm': 2.176752805709839, 'learning_rate': 1.6825993027497213e-08, 'epoch': 2.945959345562717}
2025-04-25 14:52:23,180 - INFO - INFO: Training progress: {'loss': 0.6878, 'grad_norm': 1.5809779167175293, 'learning_rate': 1.117222008286456e-08, 'epoch': 2.9558750619732277}
2025-04-25 14:52:23,180 - INFO - Training progress: {'loss': 0.6878, 'grad_norm': 1.5809779167175293, 'learning_rate': 1.117222008286456e-08, 'epoch': 2.9558750619732277}
2025-04-25 14:52:23,180 - INFO - Training metrics: {'loss': 0.6878, 'grad_norm': 1.5809779167175293, 'learning_rate': 1.117222008286456e-08, 'epoch': 2.9558750619732277}
2025-04-25 14:55:29,957 - INFO - INFO: Training progress: {'loss': 0.7304, 'grad_norm': 2.3451333045959473, 'learning_rate': 6.671516297606095e-09, 'epoch': 2.965790778383738}
2025-04-25 14:55:29,957 - INFO - Training progress: {'loss': 0.7304, 'grad_norm': 2.3451333045959473, 'learning_rate': 6.671516297606095e-09, 'epoch': 2.965790778383738}
2025-04-25 14:55:29,957 - INFO - Training metrics: {'loss': 0.7304, 'grad_norm': 2.3451333045959473, 'learning_rate': 6.671516297606095e-09, 'epoch': 2.965790778383738}
2025-04-25 14:58:32,726 - INFO - INFO: Training progress: {'loss': 0.7321, 'grad_norm': 4.514716148376465, 'learning_rate': 3.3244012144395545e-09, 'epoch': 2.975706494794249}
2025-04-25 14:58:32,728 - INFO - Training progress: {'loss': 0.7321, 'grad_norm': 4.514716148376465, 'learning_rate': 3.3244012144395545e-09, 'epoch': 2.975706494794249}
2025-04-25 14:58:32,728 - INFO - Training metrics: {'loss': 0.7321, 'grad_norm': 4.514716148376465, 'learning_rate': 3.3244012144395545e-09, 'epoch': 2.975706494794249}
2025-04-25 14:58:33,543 - INFO - INFO: Saving checkpoint at step 3000
2025-04-25 14:58:33,543 - INFO - Saving checkpoint at step 3000
2025-04-25 14:58:33,543 - INFO - Saving checkpoint at step 3000
2025-04-25 15:01:38,720 - INFO - INFO: Training progress: {'loss': 0.7264, 'grad_norm': 2.1714322566986084, 'learning_rate': 1.1312612105507382e-09, 'epoch': 2.9856222112047597}
2025-04-25 15:01:38,721 - INFO - Training progress: {'loss': 0.7264, 'grad_norm': 2.1714322566986084, 'learning_rate': 1.1312612105507382e-09, 'epoch': 2.9856222112047597}
2025-04-25 15:01:38,721 - INFO - Training metrics: {'loss': 0.7264, 'grad_norm': 2.1714322566986084, 'learning_rate': 1.1312612105507382e-09, 'epoch': 2.9856222112047597}
2025-04-25 15:04:43,912 - INFO - INFO: Training progress: {'loss': 0.7561, 'grad_norm': 2.6461291313171387, 'learning_rate': 9.234945299363418e-11, 'epoch': 2.99553792761527}
2025-04-25 15:04:43,912 - INFO - Training progress: {'loss': 0.7561, 'grad_norm': 2.6461291313171387, 'learning_rate': 9.234945299363418e-11, 'epoch': 2.99553792761527}
2025-04-25 15:04:43,912 - INFO - Training metrics: {'loss': 0.7561, 'grad_norm': 2.6461291313171387, 'learning_rate': 9.234945299363418e-11, 'epoch': 2.99553792761527}
2025-04-25 15:06:00,757 - INFO - INFO: Saving checkpoint at step 3024
2025-04-25 15:06:00,757 - INFO - Saving checkpoint at step 3024
2025-04-25 15:06:00,758 - INFO - Saving checkpoint at step 3024
2025-04-25 15:06:00,758 - INFO - INFO: Training progress: {'train_runtime': 8876.3551, 'train_samples_per_second': 2.727, 'train_steps_per_second': 0.341, 'total_flos': 3.286328826396672e+18, 'train_loss': 0.09757343991092904, 'epoch': 2.9995042141794745}
2025-04-25 15:06:00,758 - INFO - Training progress: {'train_runtime': 8876.3551, 'train_samples_per_second': 2.727, 'train_steps_per_second': 0.341, 'total_flos': 3.286328826396672e+18, 'train_loss': 0.09757343991092904, 'epoch': 2.9995042141794745}
2025-04-25 15:06:00,758 - INFO - Training metrics: {'train_runtime': 8876.3551, 'train_samples_per_second': 2.727, 'train_steps_per_second': 0.341, 'total_flos': 3.286328826396672e+18, 'train_loss': 0.09757343991092904, 'epoch': 2.9995042141794745}
2025-04-25 15:06:01,497 - INFO - INFO: Training complete, saving model to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\final_model
2025-04-25 15:06:01,497 - INFO - Training complete, saving model to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\final_model
2025-04-25 15:06:01,497 - INFO - Training complete, saving model to C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\final_model
2025-04-25 15:06:01,996 - INFO - INFO: CUDA cache cleared
2025-04-25 15:06:02,137 - INFO - INFO: Garbage collector freed 1759 objects
2025-04-25 15:06:02,138 - INFO - INFO: Training completed successfully! Model saved to: C:/Users/Paul/.cache/training_output/checkpoints_llama3_german_unsupervised_2\final_model
2025-04-25 15:06:02,138 - INFO - INFO: Training metrics: {'train_runtime': 8876.3551, 'train_samples_per_second': 2.727, 'train_steps_per_second': 0.341, 'total_flos': 3.286328826396672e+18, 'train_loss': 0.09757343991092904, 'epoch': 2.9995042141794745}
2025-04-25 15:06:02,138 - INFO - INFO: Final training metrics: {'train_runtime': 8876.3551, 'train_samples_per_second': 2.727, 'train_steps_per_second': 0.341, 'total_flos': 3.286328826396672e+18, 'train_loss': 0.09757343991092904, 'epoch': 2.9995042141794745}
2025-04-25 15:06:02,139 - INFO - Final training metrics: {'train_runtime': 8876.3551, 'train_samples_per_second': 2.727, 'train_steps_per_second': 0.341, 'total_flos': 3.286328826396672e+18, 'train_loss': 0.09757343991092904, 'epoch': 2.9995042141794745}
2025-04-25 15:06:02,139 - INFO - Final training metrics: {'train_runtime': 8876.3551, 'train_samples_per_second': 2.727, 'train_steps_per_second': 0.341, 'total_flos': 3.286328826396672e+18, 'train_loss': 0.09757343991092904, 'epoch': 2.9995042141794745}
2025-04-25 15:06:02,139 - INFO - INFO: Running final evaluation on test dataset...
2025-04-25 15:06:02,139 - INFO - Running final evaluation on test dataset...
2025-04-25 15:06:02,139 - INFO - Running final evaluation on test dataset...
2025-04-25 15:17:58,411 - INFO - INFO: Training progress: {'eval_loss': 0.765306830406189, 'eval_runtime': 716.2686, 'eval_samples_per_second': 1.812, 'eval_steps_per_second': 1.812, 'epoch': 2.9995042141794745}
2025-04-25 15:17:58,411 - INFO - Training progress: {'eval_loss': 0.765306830406189, 'eval_runtime': 716.2686, 'eval_samples_per_second': 1.812, 'eval_steps_per_second': 1.812, 'epoch': 2.9995042141794745}
2025-04-25 15:17:58,411 - INFO - Training metrics: {'eval_loss': 0.765306830406189, 'eval_runtime': 716.2686, 'eval_samples_per_second': 1.812, 'eval_steps_per_second': 1.812, 'epoch': 2.9995042141794745}
2025-04-25 15:17:58,441 - INFO - INFO: CUDA cache cleared
2025-04-25 15:17:58,597 - INFO - INFO: Garbage collector freed 9 objects
2025-04-25 15:17:58,597 - INFO - INFO: Final test metrics: {'eval_loss': 0.765306830406189, 'eval_runtime': 716.2686, 'eval_samples_per_second': 1.812, 'eval_steps_per_second': 1.812, 'epoch': 2.9995042141794745}
2025-04-25 15:17:58,598 - INFO - INFO: Final test metrics: {'eval_loss': 0.765306830406189, 'eval_runtime': 716.2686, 'eval_samples_per_second': 1.812, 'eval_steps_per_second': 1.812, 'epoch': 2.9995042141794745}
2025-04-25 15:17:58,598 - INFO - Final test metrics: {'eval_loss': 0.765306830406189, 'eval_runtime': 716.2686, 'eval_samples_per_second': 1.812, 'eval_steps_per_second': 1.812, 'epoch': 2.9995042141794745}
2025-04-25 15:17:58,598 - INFO - Final test metrics: {'eval_loss': 0.765306830406189, 'eval_runtime': 716.2686, 'eval_samples_per_second': 1.812, 'eval_steps_per_second': 1.812, 'epoch': 2.9995042141794745}
2025-04-25 15:17:58,598 - INFO - Training complete!
